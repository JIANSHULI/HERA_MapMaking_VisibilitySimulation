{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import simulate_visibilities.Bulm as Bulm\n",
    "import simulate_visibilities.simulate_visibilities as sv\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy.linalg as sla\n",
    "import time, ephem, sys, os, resource, datetime, warnings\n",
    "import aipy as ap\n",
    "import os\n",
    "#os.environ['QT_QPA_PLATFORM']='offscreen'\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import healpy as hp\n",
    "import healpy.rotator as hpr\n",
    "import healpy.pixelfunc as hpf\n",
    "import healpy.visufunc as hpv\n",
    "import scipy.interpolate as si\n",
    "import glob\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "\n",
    "from pyuvdata import UVData, UVCal, UVFITS\n",
    "import hera_cal as hc\n",
    "from hera_cal.data import DATA_PATH\n",
    "from collections import OrderedDict as odict\n",
    "from pyuvdata import utils as uvutils\n",
    "import copy\n",
    "import uvtools as uvt\n",
    "import linsolve\n",
    "from hera_cal.datacontainer import DataContainer\n",
    "from astropy.time import Time\n",
    "import omnical\n",
    "import omnical.calibration_omni as omni\n",
    "from memory_profiler import memory_usage as memuse\n",
    "from collections import OrderedDict as odict\n",
    "import pandas\n",
    "import aipy.miriad as apm\n",
    "import re\n",
    "import copy\n",
    "from hera_cal import utils, firstcal, cal_formats, redcal\n",
    "\n",
    "PI = np.pi\n",
    "TPI = PI * 2\n",
    "\n",
    "\n",
    "def pixelize(sky, nside_distribution, nside_standard, nside_start, thresh, final_index, thetas, phis, sizes):\n",
    "\t# thetas = []\n",
    "\t# phis = []\n",
    "\tfor inest in range(12 * nside_start ** 2):\n",
    "\t\tpixelize_helper(sky, nside_distribution, nside_standard, nside_start, inest, thresh, final_index, thetas, phis,\n",
    "\t\t\t\t\t\tsizes)\n",
    "\t\t# newt, newp = pixelize_helper(sky, nside_distribution, nside_standard, nside_start, inest, thresh, final_index, thetas, phis)\n",
    "\t\t# thetas += newt.tolist()\n",
    "\t\t# phis += newp.tolist()\n",
    "\t\t# return np.array(thetas), np.array(phis)\n",
    "\n",
    "\n",
    "def pixelize_helper(sky, nside_distribution, nside_standard, nside, inest, thresh, final_index, thetas, phis, sizes):\n",
    "\t# print \"visiting \", nside, inest\n",
    "\tstarti, endi = inest * nside_standard ** 2 / nside ** 2, (inest + 1) * nside_standard ** 2 / nside ** 2\n",
    "\t##local mean###if nside == nside_standard or np.std(sky[starti:endi])/np.mean(sky[starti:endi]) < thresh:\n",
    "\tif nside == nside_standard or np.std(sky[starti:endi]) < thresh:\n",
    "\t\tnside_distribution[starti:endi] = nside\n",
    "\t\tfinal_index[starti:endi] = len(thetas)  # range(len(thetas), len(thetas) + endi -starti)\n",
    "\t\t# return hp.pix2ang(nside, [inest], nest=True)\n",
    "\t\tnewt, newp = hp.pix2ang(nside, [inest], nest=True)\n",
    "\t\tthetas += newt.tolist()\n",
    "\t\tphis += newp.tolist()\n",
    "\t\tsizes += (np.ones_like(newt) * nside_standard ** 2 / nside ** 2).tolist()\n",
    "\t\t# sizes += (np.ones_like(newt) / nside**2).tolist()\n",
    "\n",
    "\telse:\n",
    "\t\t# thetas = []\n",
    "\t\t# phis = []\n",
    "\t\tfor jnest in range(inest * 4, (inest + 1) * 4):\n",
    "\t\t\tpixelize_helper(sky, nside_distribution, nside_standard, nside * 2, jnest, thresh, final_index, thetas,\n",
    "\t\t\t\t\t\t\tphis, sizes)\n",
    "\t\t\t# newt, newp = pixelize_helper(sky, nside_distribution, nside_standard, nside * 2, jnest, thresh)\n",
    "\t\t\t# thetas += newt.tolist()\n",
    "\t\t\t# phis += newp.tolist()\n",
    "\t\t\t# return np.array(thetas), np.array(phis)\n",
    "\n",
    "\n",
    "def dot(A, B, C, nchunk=10):\n",
    "\tif A.ndim != 2 or B.ndim != 2 or C.ndim != 2:\n",
    "\t\traise ValueError(\"A B C not all have 2 dims: %i %i %i\" % (str(A.ndim), str(B.ndim), str(C.ndim)))\n",
    "\n",
    "\tchunk = len(C) / nchunk\n",
    "\tfor i in range(nchunk):\n",
    "\t\tC[i * chunk:(i + 1) * chunk] = A[i * chunk:(i + 1) * chunk].dot(B)\n",
    "\tif chunk * nchunk < len(C):\n",
    "\t\tC[chunk * nchunk:] = A[chunk * nchunk:].dot(B)\n",
    "\n",
    "\n",
    "def ATNIA(A, Ni, C, nchunk=20):  # C=AtNiA\n",
    "\tif A.ndim != 2 or C.ndim != 2 or Ni.ndim != 1:\n",
    "\t\traise ValueError(\"A, AtNiA and Ni not all have correct dims: %i %i %i\"%(A.ndim, C.ndim, Ni.ndim))\n",
    "\n",
    "\texpected_time = 1.3e-11 * (A.shape[0]) * (A.shape[1])**2\n",
    "\tprint \"Estimated time for A %i by %i\"%(A.shape[0], A.shape[1]), expected_time, \"minutes\",\n",
    "\tsys.stdout.flush()\n",
    "\n",
    "\tchunk = len(C) / nchunk\n",
    "\tfor i in range(nchunk):\n",
    "\t\tltm = time.time()\n",
    "\t\tC[i * chunk:(i + 1) * chunk] = np.einsum('ji,jk->ik', A[:, i * chunk:(i + 1) * chunk] * Ni[:, None], A)\n",
    "\t\tif expected_time >= 1.:\n",
    "\t\t\tprint \"%i/%i: %.5fmins\"%(i, nchunk, (time.time() - ltm)/60.),\n",
    "\t\t\tsys.stdout.flush()\n",
    "\tif chunk * nchunk < len(C):\n",
    "\t\tC[chunk * nchunk:] = np.einsum('ji,jk->ik', A[:, chunk * nchunk:] * Ni[:, None], A)\n",
    "\n",
    "\n",
    "def solve_phase_degen(data_xx, data_yy, model_xx, model_yy, ubls, plot=False):#data should be time by ubl at single freq. data * phasegensolution = model\n",
    "\tif data_xx.shape != data_yy.shape or data_xx.shape != model_xx.shape or data_xx.shape != model_yy.shape or data_xx.shape[1] != ubls.shape[0]:\n",
    "\t\traise ValueError(\"Shapes mismatch: %s %s %s %s, ubl shape %s\"%(data_xx.shape, data_yy.shape, model_xx.shape, model_yy.shape, ubls.shape))\n",
    "\tA = np.zeros((len(ubls) * 2, 2))\n",
    "\tb = np.zeros(len(ubls) * 2)\n",
    "\n",
    "\tnrow = 0\n",
    "\tfor p, (data, model) in enumerate(zip([data_xx, data_yy], [model_xx, model_yy])):\n",
    "\t\tfor u, ubl in enumerate(ubls):\n",
    "\t\t\tamp_mask = (np.abs(data[:, u]) > (np.median(np.abs(data[:, u])) / 2.))\n",
    "\t\t\tA[nrow] = ubl[:2]\n",
    "\t\t\tb[nrow] = omni.medianAngle(np.angle(model[:, u] / data[:, u])[amp_mask])\n",
    "\t\t\tnrow += 1\n",
    "\tphase_cal = omni.solve_slope(np.array(A), np.array(b), 1)\n",
    "\tif plot:\n",
    "\t\tplt.hist((np.array(A).dot(phase_cal)-b + PI)%TPI-PI)\n",
    "\t\tplt.title('phase fitting error')\n",
    "\t\tplt.show()\n",
    "\n",
    "\t#sooolve\n",
    "\treturn phase_cal\n",
    "\n",
    "class LastUpdatedOrderedDict(odict):\n",
    "\t'Store items in the order the keys were last added'\n",
    "\n",
    "\tdef __setitem__(self, key, value):\n",
    "\t\tif key in self:\n",
    "\t\t\tdel self[key]\n",
    "\t\todict.__setitem__(self, key, value)\n",
    "\n",
    "def S_casa_v_t(v, t = 2015.5):\t\t\n",
    "\tS_0 = 2190.294 #S_casA_1GHz\n",
    "\talpha =  0.725\n",
    "\tbelta = 0.0148\n",
    "\ttau = 6.162*1.e-5\n",
    "\n",
    "\ta = -0.00633 #+-0.00024 year-1 \n",
    "\tb = 0.00039 #+-0.00008 year -1\n",
    "\tc = 1.509*1.e-7 #+-0.162*1.e-7 year-1\n",
    "\t\n",
    "\tv *= 1.e-3\n",
    "\t\n",
    "\t#print(v) # from MHz to GHz\n",
    "\t#print(t) # in decimal year\n",
    "\t\n",
    "\tS_casa_v = S_0 * v**(-alpha + belta * np.log(v)) * np.exp(-tau * v**(-2.1)) #S_0: 2015.5\n",
    "\td_speed_log_v = a + b * np.log(v) + c * v**(-2.1) #a,b,c: 2005.0\n",
    "\tS_casa_v_t = np.exp((t - 2015.5) * d_speed_log_v + np.log(S_casa_v))\n",
    "\t\n",
    "\t#print(d_speed_log_v)\n",
    "\t\n",
    "\treturn S_casa_v_t\n",
    "\t\n",
    "def S_cyga_v(v, t = 2005):\n",
    "\tS_cyga_v = 3.835 * 1.e5 * v**(-0.718) * np.exp(-0.342 * (21.713/v)**2.1)\n",
    "\t\n",
    "\treturn S_cyga_v\n",
    "\n",
    "def UVData2AbsCalDict(datanames, pol_select=None, pop_autos=True, return_meta=False, filetype='miriad',\n",
    "                      pick_data_ants=True):\n",
    "\t\"\"\"\n",
    "    turn a list of pyuvdata.UVData objects or a list of miriad or uvfits file paths\n",
    "    into the datacontainer dictionary form that AbsCal requires. This format is\n",
    "    keys as antennas-pair + polarization format, Ex. (1, 2, 'xx')\n",
    "    and values as 2D complex ndarrays with [0] axis indexing time and [1] axis frequency.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    datanames : list of either strings of data file paths or list of UVData instances\n",
    "                to concatenate into a single dictionary\n",
    "\n",
    "    pol_select : list of polarization strings to keep\n",
    "\n",
    "    pop_autos : boolean, if True: remove autocorrelations\n",
    "\n",
    "    return_meta : boolean, if True: also return antenna and unique frequency and LST arrays\n",
    "\n",
    "    filetype : string, filetype of data if datanames is a string, options=['miriad', 'uvfits']\n",
    "                can be ingored if datanames contains UVData objects.\n",
    "\n",
    "    pick_data_ants : boolean, if True and return_meta=True, return only antennas in data\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    if return_meta is True:\n",
    "        (data, flags, antpos, ants, freqs, times, lsts, pols)\n",
    "    else:\n",
    "        (data, flags)\n",
    "\n",
    "    data : dictionary containing baseline-pol complex visibility data\n",
    "    flags : dictionary containing data flags\n",
    "    antpos : dictionary containing antennas numbers as keys and position vectors\n",
    "    ants : ndarray containing unique antennas\n",
    "    freqs : ndarray containing frequency channels (Hz)\n",
    "    times : ndarray containing julian date bins of data\n",
    "    lsts : ndarray containing LST bins of data (radians)\n",
    "    pols : ndarray containing list of polarization index integers\n",
    "    \"\"\"\n",
    "\t# check datanames is not a list\n",
    "\tif type(datanames) is not list and type(datanames) is not np.ndarray:\n",
    "\t\tif type(datanames) is str:\n",
    "\t\t\t# assume datanames is a file path\n",
    "\t\t\tuvd = UVData()\n",
    "\t\t\tsuffix = os.path.splitext(datanames)[1]\n",
    "\t\t\tif filetype == 'uvfits' or suffix == '.uvfits':\n",
    "\t\t\t\tuvd.read_uvfits(datanames)\n",
    "\t\t\t\tuvd.unphase_to_drift()\n",
    "\t\t\telif filetype == 'miriad':\n",
    "\t\t\t\tuvd.read_miriad(datanames)\n",
    "\t\telse:\n",
    "\t\t\t# assume datanames is a UVData instance\n",
    "\t\t\tuvd = datanames\n",
    "\telse:\n",
    "\t\t# if datanames is a list, check data types of elements\n",
    "\t\tif type(datanames[0]) is str:\n",
    "\t\t\t# assume datanames contains file paths\n",
    "\t\t\tuvd = UVData()\n",
    "\t\t\tsuffix = os.path.splitext(datanames[0])[1]\n",
    "\t\t\tif filetype == 'uvfits' or suffix == '.uvfits':\n",
    "\t\t\t\tuvd.read_uvfits(datanames)\n",
    "\t\t\t\tuvd.unphase_to_drift()\n",
    "\t\t\telif filetype == 'miriad':\n",
    "\t\t\t\tuvd.read_miriad(datanames)\n",
    "\t\telse:\n",
    "\t\t\t# assume datanames contains UVData instances\n",
    "\t\t\tuvd = reduce(operator.add, datanames)\n",
    "\t\n",
    "\t# load data\n",
    "\td, f = firstcal.UVData_to_dict([uvd])\n",
    "\t\n",
    "\t# pop autos\n",
    "\tif pop_autos:\n",
    "\t\tfor i, k in enumerate(d.keys()):\n",
    "\t\t\tif k[0] == k[1]:\n",
    "\t\t\t\td.pop(k)\n",
    "\t\t\t\tf.pop(k)\n",
    "\t\n",
    "\t# turn into datacontainer\n",
    "\tdata, flags = DataContainer(d), DataContainer(f)\n",
    "\t\n",
    "\t# get meta\n",
    "\tif return_meta:\n",
    "\t\tfreqs = np.unique(uvd.freq_array)\n",
    "\t\ttimes = np.unique(uvd.time_array)\n",
    "\t\tlsts = np.unique(uvd.lst_array)\n",
    "\t\tantpos, ants = uvd.get_ENU_antpos(center=True, pick_data_ants=pick_data_ants)\n",
    "\t\tantpos = odict(zip(ants, antpos))\n",
    "\t\tpols = uvd.polarization_array\n",
    "\t\treturn data, flags, antpos, ants, freqs, times, lsts, pols\n",
    "\telse:\n",
    "\t\treturn data, flags\n",
    "\n",
    "\n",
    "def UVData2AbsCalDict_Auto(datanames, pol_select=None, pop_autos=True, return_meta=False, filetype='miriad',\n",
    "                      pick_data_ants=True):\n",
    "\t\"\"\"\n",
    "    turn a list of pyuvdata.UVData objects or a list of miriad or uvfits file paths\n",
    "    into the datacontainer dictionary form that AbsCal requires. This format is\n",
    "    keys as antennas-pair + polarization format, Ex. (1, 2, 'xx')\n",
    "    and values as 2D complex ndarrays with [0] axis indexing time and [1] axis frequency.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    datanames : list of either strings of data file paths or list of UVData instances\n",
    "                to concatenate into a single dictionary\n",
    "\n",
    "    pol_select : list of polarization strings to keep\n",
    "\n",
    "    pop_autos : boolean, if True: remove autocorrelations\n",
    "\n",
    "    return_meta : boolean, if True: also return antenna and unique frequency and LST arrays\n",
    "\n",
    "    filetype : string, filetype of data if datanames is a string, options=['miriad', 'uvfits']\n",
    "                can be ingored if datanames contains UVData objects.\n",
    "\n",
    "    pick_data_ants : boolean, if True and return_meta=True, return only antennas in data\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    if return_meta is True:\n",
    "        (data, flags, antpos, ants, freqs, times, lsts, pols)\n",
    "    else:\n",
    "        (data, flags)\n",
    "\n",
    "    data : dictionary containing baseline-pol complex visibility data\n",
    "    flags : dictionary containing data flags\n",
    "    antpos : dictionary containing antennas numbers as keys and position vectors\n",
    "    ants : ndarray containing unique antennas\n",
    "    freqs : ndarray containing frequency channels (Hz)\n",
    "    times : ndarray containing julian date bins of data\n",
    "    lsts : ndarray containing LST bins of data (radians)\n",
    "    pols : ndarray containing list of polarization index integers\n",
    "    \"\"\"\n",
    "\t# check datanames is not a list\n",
    "\tif type(datanames) is not list and type(datanames) is not np.ndarray:\n",
    "\t\tif type(datanames) is str:\n",
    "\t\t\t# assume datanames is a file path\n",
    "\t\t\tuvd = UVData()\n",
    "\t\t\tsuffix = os.path.splitext(datanames)[1]\n",
    "\t\t\tif filetype == 'uvfits' or suffix == '.uvfits':\n",
    "\t\t\t\tuvd.read_uvfits(datanames)\n",
    "\t\t\t\tuvd.unphase_to_drift()\n",
    "\t\t\telif filetype == 'miriad':\n",
    "\t\t\t\tuvd.read_miriad(datanames)\n",
    "\t\telse:\n",
    "\t\t\t# assume datanames is a UVData instance\n",
    "\t\t\tuvd = datanames\n",
    "\telse:\n",
    "\t\t# if datanames is a list, check data types of elements\n",
    "\t\tif type(datanames[0]) is str:\n",
    "\t\t\t# assume datanames contains file paths\n",
    "\t\t\tuvd = UVData()\n",
    "\t\t\tsuffix = os.path.splitext(datanames[0])[1]\n",
    "\t\t\tif filetype == 'uvfits' or suffix == '.uvfits':\n",
    "\t\t\t\tuvd.read_uvfits(datanames)\n",
    "\t\t\t\tuvd.unphase_to_drift()\n",
    "\t\t\telif filetype == 'miriad':\n",
    "\t\t\t\tuvd.read_miriad(datanames)\n",
    "\t\telse:\n",
    "\t\t\t# assume datanames contains UVData instances\n",
    "\t\t\tuvd = reduce(operator.add, datanames)\n",
    "\t\n",
    "\t# load data\n",
    "\td, f = firstcal.UVData_to_dict([uvd])\n",
    "\tautos = {}\n",
    "\tautos_flags = {}\n",
    "\t\n",
    "\t# pop autos\n",
    "\tif pop_autos:\n",
    "\t\tfor i, k in enumerate(d.keys()):\n",
    "\t\t\tif k[0] == k[1]:\n",
    "\t\t\t\tautos[k] = d[k]\n",
    "\t\t\t\tautos_flags[k] = f[k]\n",
    "\t\t\t\td.pop(k)\n",
    "\t\t\t\tf.pop(k)\n",
    "\t\n",
    "\t# turn into datacontainer\n",
    "\tdata, flags = DataContainer(d), DataContainer(f)\n",
    "\tautos_pro, autos_flags_pro = DataContainer(autos), DataContainer(autos_flags)\n",
    "\t\n",
    "\t# get meta\n",
    "\tif return_meta:\n",
    "\t\tfreqs = np.unique(uvd.freq_array)\n",
    "\t\ttimes = np.unique(uvd.time_array)\n",
    "\t\tlsts = np.unique(uvd.lst_array)\n",
    "\t\tantpos, ants = uvd.get_ENU_antpos(center=True, pick_data_ants=pick_data_ants)\n",
    "\t\tantpos = odict(zip(ants, antpos))\n",
    "\t\tpols = uvd.polarization_array\n",
    "\t\treturn data, flags, antpos, ants, freqs, times, lsts, pols, autos_pro, autos_flags_pro\n",
    "\telse:\n",
    "\t\treturn data, flags, autos_pro, autos_flags_pro\n",
    "\n",
    "INSTRUMENT = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hera47\n",
      "Run IPython\n"
     ]
    }
   ],
   "source": [
    "#####commandline inputs#####\n",
    "if len(sys.argv) == 1:\n",
    "\tINSTRUMENT = 'hera47'\n",
    "else:\n",
    "\tINSTRUMENT = sys.argv[1]#'miteor'#'mwa'#'hera-47''paper'\n",
    "\n",
    "INSTRUMENT = 'hera47' #'hera47'; 'miteor'\n",
    "print INSTRUMENT\n",
    "\n",
    "tag = '-ampcal-' #'-ampcal-' #sys.argv[2]; if use real uncalibrated data, set tag = '-ampcal-' for amplitude calibration.\n",
    "\n",
    "AtNiA_only = False\n",
    "if len(sys.argv) > 3 and sys.argv[3][:5] == 'atnia':\n",
    "\tAtNiA_only = True\n",
    "\tpixel_scheme_number = int(sys.argv[3][5:])\n",
    "\t\n",
    "simulation_opt = 1\n",
    "\n",
    "plotcoord = 'CG'\n",
    "baseline_safety_factor = 10.#max_ubl = 1.4*lambda/baseline_safety_factor\n",
    "crosstalk_type = 'autocorr'\n",
    "#pixel_directory = '/home/omniscope/data/GSM_data/absolute_calibrated_data/'\n",
    "\n",
    "plot_pixelization = True and not AtNiA_only\n",
    "plot_projection = True and not AtNiA_only\n",
    "plot_data_error = True and not AtNiA_only\n",
    "\n",
    "force_recompute = False\n",
    "force_recompute_AtNiAi_eig = False\n",
    "force_recompute_AtNiAi = False\n",
    "force_recompute_S = False\n",
    "force_recompute_SEi = False\n",
    "\n",
    "C = 299.792458\n",
    "kB = 1.3806488 * 1.e-23\n",
    "\n",
    "try:\n",
    "\t__file__\n",
    "except NameError:\n",
    "\t#script_dir = '/Users/JianshuLi/anaconda3/envs/Cosmology-Python27/lib/python2.7/site-packages/simulate_visibilities/scripts'\n",
    "\tscript_dir = os.path.join(DATA_PATH, '../../../HERA_MapMaking_VisibilitySimulation/scripts')\n",
    "\tpixel_directory = script_dir\n",
    "\tprint 'Run IPython'\n",
    "else:\n",
    "\tscript_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "\tpixel_directory = script_dir\n",
    "\tprint 'Run Python'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/JianshuLi/anaconda3/envs/Cosmology-Python27/lib/python2.7/site-packages/hera_cal-1.0-py2.7.egg/hera_cal/data'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sys.argv)\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 64 is out of bounds for axis 1 with size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c0cef459b975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    348\u001b[0m                                         \u001b[0mdata_ff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xx'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'yy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xx'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'yy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfindex_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#if i == 0 else uvd_yy.get_data((key[0], key[1]))[:, findex_list[i]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                                         \u001b[0mautocorr_data_mfreq_ff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautocorr_data_mfreq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfindex_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                                         \u001b[0mdflags_ff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xx'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'yy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdflags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xx'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'yy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfindex_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                         \u001b[0;31m# del data_ff[dflags[i].keys()[id_key]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 64 is out of bounds for axis 1 with size 64"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "################data file and load beam##############\n",
    "####################################################\n",
    "if INSTRUMENT == 'miteor':\n",
    "# \tSimulation = True\n",
    "# \tUse_SimulatedData = False\n",
    "# \tUse_Simulation_noise = False\n",
    "\t\n",
    "\tsys.stdout.flush()\n",
    "\tSimulation = True\n",
    "\tUse_SimulatedData = False\n",
    "\tUse_Simulation_noise = True\n",
    "\tFrom_File_Data = True\n",
    "\tKeep_Red = False\n",
    "\tAbsolute_Calibration = False\n",
    "\tAbsolute_Calibration_red = False\n",
    "\tAbsolute_Calibration_mfreq = False\n",
    "\tAbsolute_Calibration_dred = False\n",
    "\tAbsolute_Calibration_dred_mfreq = False\n",
    "\tPointSource_AbsCal = False\n",
    "\tAbsolute_Calibration_dred_mfreq_pscal = False\n",
    "\t\n",
    "\tUse_AbsCal = False  # Use Model calculated noise which is just fullsim autocorr calculated noise.\n",
    "\tUse_PsAbsCal = False  # higher priority over Use_AbsCal and Use_Fullsim_Noise. if comply_ps2mod_autocorr then become just fullsim autocorr calculated noise.\n",
    "\tcomply_ps2mod_autocorr = False\n",
    "\tUse_Fullsim_Noise = False  # Use fullsim autocorr calculated noise.\n",
    "\t\n",
    "\tReplace_Data = True\t\n",
    "\t\n",
    "\tseek_optimal_threshs = False and not AtNiA_only\n",
    "\tdynamic_precision = .2  # .1#ratio of dynamic pixelization error vs data std, in units of data, so not power\n",
    "\tthresh = 2  # .2#2.#.03125#\n",
    "\tvalid_pix_thresh = 1.e-4\n",
    "\tnside_start = 32\n",
    "\tnside_standard = 32  # Determine the resolution of GSM of sky\n",
    "\t\n",
    "\tpre_calibrate = True\n",
    "\ttag = '-ampcal-' if pre_calibrate else ''  # '-ampcal-' #sys.argv[2]; if use real uncalibrated data, set tag = '-ampcal-' for amplitude calibration.\n",
    "\tpre_ampcal = ('ampcal' in tag)\n",
    "\tpre_phscal = True\n",
    "\tpre_addcal = True\n",
    "\tfit_for_additive = False\n",
    "\tnside_beamweight = 16  # Determin shape of A matrix\n",
    "\t\n",
    "\tErase = True\n",
    "\t\n",
    "\tAdd_S_diag = False\n",
    "\tAdd_Rcond = True\n",
    "\tData_Deteriorate = False\n",
    "\t\n",
    "\tS_type = 'dyS_lowadduniform_lowI'  # 'dyS_lowadduniform_lowI'#'none'#'dyS_lowadduniform_Iuniform'  #'none'# dynamic S, addlimit:additive same level as max data; lowaddlimit: 10% of max data; lowadduniform: 10% of median max data; Iuniform median of all data\n",
    "\t# \tS_type = 'dyS_lowadduniform_min18I' if Add_S_diag else 'no_use' #'dyS_lowadduniform_minI', 'dyS_lowadduniform_I', 'dyS_lowadduniform_lowI', 'dyS_lowadduniform_lowI'#'none'#'dyS_lowadduniform_Iuniform'  #'none'# dynamic S, addlimit:additive same level as max data; lowaddlimit: 10% of max data; lowadduniform: 10% of median max data; Iuniform median of all data\n",
    "\trcond_list = 10. ** np.arange(-6., -0., 1.)\n",
    "\tif Data_Deteriorate:\n",
    "\t\tS_type += '-deteriorated-'\n",
    "\telse:\n",
    "\t\tpass\n",
    "\t\n",
    "\tIntegration_Time = 2.7  # seconds\n",
    "\tFrequency_Bin = 0.5 * 1.e6  # Hz\n",
    "    \n",
    "\tlat_degree = 45.2977\n",
    "\tlst_offset = 5.#lsts will be wrapped around [lst_offset, 24+lst_offset]\n",
    "    \n",
    "#\t# tag = \"q3AL_5_abscal\"  #\"q0AL_13_abscal\"  #\"q1AL_10_abscal\"'q3_abscalibrated'#\"q4AL_3_abscal\"# L stands for lenient in flagging\n",
    "\tif 'ampcal' in tag:\n",
    "\t\tdatatag = '_2016_01_20-ampcal'#'_seccasa.rad'#\n",
    "\t\tvartag = '_2016_01_20-ampcal'#''#\n",
    "\telse:\n",
    "\t\tdatatag = '_2016_01_20'#'_2016_01_20_avg_unpollock'#'_seccasa.rad'#\n",
    "\t\tvartag = '_2016_01_20'#'_2016_01_20_avg_unpollockx100'#''#\n",
    "#\tdatadir = '/home/omniscope/data/GSM_data/absolute_calibrated_data/'\n",
    "\tdatadir = script_dir + '/../Output/'\n",
    "\tantpairs = None\n",
    "\t# deal with beam: create a callable function of the form y(freq) in MHz and returns 2 by npix\n",
    "\t\n",
    "\t\n",
    "\t############################################ Load Beam and Visibility Data ###########################################\n",
    "\tflist = {}\n",
    "\tvis_freq_list = flist[0] = flist[1] = np.array([126.83333,127.6667,128.5000,129.3333,130.1667,131.0000,131.8333,132.6667,133.5000,134.3333,135.1667,136.0000,136.8333,137.6667,139.3333,140.0000,141.83333,142.6667,143.5000,144.3333,145.0000,145.1667,146.0000,146.6667,147.5000,148.3333,150.8333,151.6667,152.5000,153.3333,154.1667,155.0000,155.8333,156.0000,156.6667,156.8333,159.3333,161.8333,164.3333,166.8333,167.8333,170.3333,172.8333])\n",
    "\tfreq = vis_freq_selected = 150.8333 #MHz\n",
    "\t\n",
    "\tif tag == '-ampcal-':\n",
    "\t\ttag = '%s-%f'%(INSTRUMENT, freq) + tag\n",
    "\telse:\n",
    "\t\ttag = '%s-%f'%(INSTRUMENT, freq)\n",
    "\t\n",
    "\tbnside = 64 #Depend on beam pattern data\n",
    "\tfreqs = range(110, 200, 10)\n",
    "\tlocal_beam_unpol = si.interp1d(freqs, np.array([la.norm(np.loadtxt(\n",
    "\t\tscript_dir + '/../data/MITEoR/beam/%s.txt'%(p), skiprows=0).reshape(\n",
    "\t\t(len(freqs), 12 * bnside ** 2, 4)), axis=-1)**2 for p in ['x', 'y']]).transpose(1, 0, 2), axis=0)\n",
    "\tPlot_Beam = True\n",
    "\tif Plot_Beam:\n",
    "\t\tplt.figure(0)\n",
    "\t\t#ind = np.where(beam_freqs == freq)[0][0]\n",
    "\t\thp.mollview(10.0 * np.log10(local_beam_unpol(freq)[0,:]), title='HERA-Dipole Beam-East (%sMHz, bnside=%s)'%(freq, bnside),\n",
    "\t\t\t\tunit='dBi')\n",
    "\t#     hp.mollview(10.0 * np.log10(beam_E[ind,:]), title='HERA-Dipole Beam-East (%sMHz, bnside=%s)'%(beam_freqs[ind], bnside),\n",
    "\t#             unit='dBi')\n",
    "\t\tplt.savefig(script_dir + '/../Output/%s-dipole-Beam-east-%.2f-bnside-%s.pdf'%(INSTRUMENT, freq, bnside))\n",
    "\t\thp.mollview(10.0 * np.log10(local_beam_unpol(freq)[1,:]), title='HERA-Dipole Beam-North (%sMHz, bnside=%s)'%(freq, bnside),\n",
    "\t\t\t\tunit='dBi')\n",
    "\t#     hp.mollview(10.0 * np.log10(beam_N[ind,:]), title='HERA-Dipole Beam-North (%sMHz, bnside=%s)'%(beam_freqs[ind], bnside),\n",
    "\t#             unit='dBi')\n",
    "\t\tplt.savefig(script_dir + '/../Output/%s-dipole-Beam-north-%.2f-bnside-%s.pdf'%(INSTRUMENT, freq, bnside))\n",
    "\t\tplt.show(block=False)\n",
    "\t\t#plt.gcf().clear()\n",
    "\t\t\t#plt.clf()\n",
    "\t\t\t#plt.close()\n",
    "\t\t\t\n",
    "\ttime_vis_data = np.array([np.loadtxt(script_dir + '/../data/MITEoR/visibilities/%sMHz_%s%s_A.txt'%(vis_freq_selected,p,p)) for p in ['x','y']])\n",
    "\t\n",
    "\tvis_data = (time_vis_data[:,1:,1::3] + time_vis_data[:,1:,2::3] * 1j).astype('complex128')\n",
    "\tvar_data = time_vis_data[:,1:,3::3]\n",
    "\t\n",
    "\ttlist = time_vis_data[0,1:,0]\n",
    "\ttmasks = {}\n",
    "\tfor p in ['x', 'y']:\n",
    "\t\ttmasks[p] = np.ones_like(tlist).astype(bool)\n",
    "\n",
    "\ttmask = tmasks['x']&tmasks['y']\n",
    "\ttlist = lsts = tlist[tmask]\n",
    "\tnt = nt_used = len(tlist)\n",
    "\tjansky2kelvin = 1.e-26 * (C / freq) ** 2 / 2 / kB / (4 * PI / (12 * nside_standard ** 2))\n",
    "\tnUBL = int(len(time_vis_data[0,0,:])/3)\n",
    "\t\n",
    "\tubls = {}\n",
    "\tfor p in range(2):\n",
    "\t\tubls[['x','y'][p]] = time_vis_data[p,0,1:].reshape((nUBL,3))\t\t\n",
    "\tcommon_ubls = np.array([u for u in ubls['x'] if (u in ubls['y'] or -u in ubls['y'])])\n",
    "\t#manually filter UBLs\n",
    "\tused_common_ubls = common_ubls[la.norm(common_ubls, axis=-1) / (C / freq) <= 1.4 * nside_standard / baseline_safety_factor]#[np.argsort(la.norm(common_ubls, axis=-1))[10:]]     #remove shorted 10\n",
    "\tnUBL_used = len(used_common_ubls)\n",
    "\tubl_index = {}  # stored index in each pol's ubl for the common ubls\n",
    "\tfor p in ['x', 'y']:\n",
    "\t\tubl_index[p] = np.zeros(nUBL_used, dtype='int')\n",
    "\t\tfor i, u in enumerate(used_common_ubls):\n",
    "\t\t\tif u in ubls[p]:\n",
    "\t\t\t\tubl_index[p][i] = np.argmin(la.norm(ubls[p] - u, axis=-1)) + 1\n",
    "\t\t\telif -u in ubls[p]:\n",
    "\t\t\t\tubl_index[p][i] = - np.argmin(la.norm(ubls[p] + u, axis=-1)) - 1\n",
    "\t\t\telse:\n",
    "\t\t\t\traise Exception('Logical Error')\n",
    "                \n",
    "\tredundancy = used_redundancy = {}\n",
    "\tfor i in range(2):\n",
    "\t\tused_redundancy[i] = redundancy[i] = np.ones_like(ubl_index)\n",
    "        \n",
    "\tprint '>>>>>>Used nUBL = %i, nt = %i.'%(nUBL_used, nt_used)\n",
    "\tsys.stdout.flush()\t\n",
    "\t\n",
    "\t\n",
    "elif INSTRUMENT == 'hera47':\n",
    "\tSimulation = True\n",
    "\tUse_SimulatedData = True\n",
    "\tUse_Simulation_noise = True\n",
    "\tFrom_File_Data = True\n",
    "\tKeep_Red = False\n",
    "\tAbsolute_Calibration = False\n",
    "\tAbsolute_Calibration_red = False\n",
    "\tAbsolute_Calibration_mfreq = False\n",
    "\tAbsolute_Calibration_dred = False\n",
    "\tAbsolute_Calibration_dred_mfreq = False\n",
    "\tPointSource_AbsCal = False\n",
    "\tAbsolute_Calibration_dred_mfreq_pscal = False\n",
    "    \n",
    "\tUse_AbsCal = False # Use Model calculated noise which is just fullsim autocorr calculated noise.\n",
    "\tUse_PsAbsCal = False # higher priority over Use_AbsCal and Use_Fullsim_Noise. if comply_ps2mod_autocorr then become just fullsim autocorr calculated noise.\n",
    "\tcomply_ps2mod_autocorr = False\n",
    "\tUse_Fullsim_Noise = False # Use fullsim autocorr calculated noise.\n",
    "\t\n",
    "\tReplace_Data = True\n",
    "\t\n",
    "\tpre_calibrate = True\n",
    "\ttag = '-ampcal-' if pre_calibrate else '' #'-ampcal-' #sys.argv[2]; if use real uncalibrated data, set tag = '-ampcal-' for amplitude calibration.\n",
    "\tpre_ampcal = ('ampcal' in tag)\n",
    "\tpre_phscal = True\n",
    "\tpre_addcal = True\n",
    "\tfit_for_additive = False\n",
    "\t\n",
    "\tSmall_ModelData = True\n",
    "\tModel_Calibration = False\n",
    "    \n",
    "\tErase = True\n",
    "\t\n",
    "\tAdd_S_diag = False\n",
    "\tAdd_Rcond = True\n",
    "\tData_Deteriorate = False\n",
    "    \n",
    "\tTime_Expansion_Factor = 72. if Use_SimulatedData else 1.\n",
    "    \n",
    "\tsys.stdout.flush()\n",
    "\t\n",
    "\tlat_degree = -30.72153 #lon='21:25:41.9' lat='-30:43:17.5'\n",
    "\tlst_offset = 1.43#lsts will be wrapped around [lst_offset, 24+lst_offset]\n",
    "\n",
    "\tIntegration_Time = 11 # seconds\n",
    "\tFrequency_Bin = 1.625*1.e6 # Hz\n",
    "\n",
    "\tS_type = 'dyS_lowadduniform_min18I' if Add_S_diag else 'no_use' #'dyS_lowadduniform_minI', 'dyS_lowadduniform_I', 'dyS_lowadduniform_lowI', 'dyS_lowadduniform_lowI'#'none'#'dyS_lowadduniform_Iuniform'  #'none'# dynamic S, addlimit:additive same level as max data; lowaddlimit: 10% of max data; lowadduniform: 10% of median max data; Iuniform median of all data\n",
    "\trcond_list = 10.**np.arange(-15., -0., 1.)\n",
    "\tif Data_Deteriorate:\n",
    "\t\tS_type += '-deteriorated-'\n",
    "\telse:\n",
    "\t\tpass\n",
    "    \n",
    "\tseek_optimal_threshs = False and not AtNiA_only\n",
    "\tdynamic_precision = .2#.1#ratio of dynamic pixelization error vs data std, in units of data, so not power\n",
    "\tthresh = 2#.2#2.#.03125#\n",
    "\tvalid_pix_thresh = 1.e-4\n",
    "\tnside_start = 32\n",
    "\tnside_standard = 32 # resolution of sky\n",
    "\tnside_beamweight = 16 # A matrix shape\n",
    "\tbnside = 64 # beam pattern data resolution\n",
    "\t\n",
    "\t\n",
    "#\t# tag = \"q3AL_5_abscal\"  #\"q0AL_13_abscal\"  #\"q1AL_10_abscal\"'q3_abscalibrated'#\"q4AL_3_abscal\"# L stands for lenient in flagging\n",
    "\tif 'ampcal' in tag:\n",
    "\t\tdatatag = '_2018_'#'_seccasa.rad'#\n",
    "\t\tvartag = '_2018_'#''#\n",
    "\telse:\n",
    "\t\tdatatag = '_2018_ampcaled_'#'_2016_01_20_avg_unpollock'#'_seccasa.rad'#\n",
    "\t\tvartag = '_2018_ampcaled_'#'_2016_01_20_avg_unpollockx100'#''#\n",
    "\tdatadir = script_dir + '/../Output/'\n",
    "\tantpairs = None\n",
    "\t\n",
    "\t#######################################################################################################\n",
    "\t##################################### Load Visibility Data ###########################################\n",
    "\t# specify model file and load into UVData, load into dictionary\n",
    "\t\n",
    "\tmodel_fname = {}\n",
    "\tmodel = {}\n",
    "\tmflags = {}\n",
    "\tmantpos = {}\n",
    "\tmants = {}\n",
    "\tmodel_freqs = {}\n",
    "\tmodel_times = {}\n",
    "\tmodel_lsts = {}\n",
    "\tmodel_pols = {}\n",
    "\tmodel_autos = {}\n",
    "\tmodel_autos_flags = {}\n",
    "\t\n",
    "\tdata_fname = {}\n",
    "\tdata_fname_full = {}\n",
    "\tdflags = {}\n",
    "\tdata = {}\n",
    "\tantpos = {}\n",
    "\tants = {}\n",
    "\tdata_freqs = {}\n",
    "\tdata_times = {}\n",
    "\tdata_lsts = {}\n",
    "\tdata_pols = {}\n",
    "\tdata_autos = {}\n",
    "\tdata_autos_flags = {}\n",
    "\t\n",
    "\tfulldflags = {}\n",
    "\t\n",
    "\tdata_fnames = {}\n",
    "\tfiles_basses = {}\n",
    "\tfile_times = {}\n",
    "\t\n",
    "\tautocorr_data_mfreq = {}  # np.zeros((2, Ntimes, Nfreqs))\n",
    "\tautocorr_data = {}\n",
    "\tNfiles = min(1, len(glob.glob(\"{0}/zen.*.*.xx.HH.uvOR\".format(DATA_PATH + '/ObservingSession-1192201262/2458043/'))), len(glob.glob(\"{0}/zen.*.*.yy.HH.uvOR\".format(DATA_PATH + '/ObservingSession-1192201262/2458043/'))))\n",
    "\t\n",
    "\tflist = {}\n",
    "\tindex_freq = {}\n",
    "\t\n",
    "\ttry:\n",
    "\t\tdata_fnames[0] = xxfiles = sorted((glob.glob(\"{0}/zen.*.*.xx.HH.uvOR\".format(DATA_PATH + '/ObservingSession-1192201262/2458043/'))))[:Nfiles]\n",
    "\t\tdata_fnames[1] = yyfiles = sorted((glob.glob(\"{0}/zen.*.*.yy.HH.uvOR\".format(DATA_PATH + '/ObservingSession-1192201262/2458043/'))))[:Nfiles]\n",
    "\t\t\n",
    "\t\tfile_times[0] = xxfile_bases = map(os.path.basename, xxfiles)\n",
    "\t\tfile_times[1] = yyfile_bases = map(os.path.basename, yyfiles)\n",
    "\t\t\n",
    "\t\tfile_times[0] = xxfile_times = np.array(map(lambda x: '.'.join(os.path.basename(x).split('.')[1:3]), xxfiles), np.float)\n",
    "\t\tfile_times[1] = yyfile_times = np.array(map(lambda y: '.'.join(os.path.basename(y).split('.')[1:3]), yyfiles), np.float)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\t\n",
    "\tif Small_ModelData:\n",
    "\t\tif Model_Calibration:\n",
    "\t\t\t\n",
    "\t\t\t#model = mflags = mantpos = mant = model_freqs = model_times = model_lsts = model_pols = {}\n",
    "\t\t\tfor i in range(2):\n",
    "\t\t\t\tmodel_fname[i] = os.path.join(DATA_PATH, \"zen.2458042.12552.%s.HH.uvXA\" % ['xx', 'yy'][i])  # /Users/JianshuLi/Documents/Miracle/Research/Cosmology/21cm Cosmology/Algorithm-Data/Data/HERA-47/Observation-1192115507/2458042/zen.2458042.13298.xx.HH.uv\n",
    "\t\t\t\t# model_fname[1] = os.path.join(DATA_PATH, \"zen.2458042.12552.xx.HH.uvXA\") #/Users/JianshuLi/Documents/Miracle/Research/Cosmology/21cm Cosmology/Algorithm-Data/Data/HERA-47/Observation-1192114862/2458042/zen.2458042.12552.xx.HH.uv\n",
    "\t\t\t\tif i == 1:\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t# data_fname[1] = os.path.join(DATA_PATH, \"zen.2458043.12552.yy.HH.uvORA\") #zen.2457698.40355.yy.HH.uvcA\n",
    "\t\t\t\t\t\tif not os.path.isfile(model_fname[i]):\n",
    "\t\t\t\t\t\t\tmodel_fname[1] = os.path.join(DATA_PATH, \"zen.2458042.12552.xx.HH.uvXA\")\n",
    "\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\tpass\n",
    "\t\t\t\t(model[i], mflags[i], mantpos[i], mants[i], model_freqs[i], model_times[i], model_lsts[i], model_pols[i], model_autos[i], model_autos_flags[i]) = UVData2AbsCalDict_Auto(model_fname[i], return_meta=True)\n",
    "\t\t\n",
    "\t\t# specify data file and load into UVData, load into dictionary\n",
    "\t\tfor i in range(2):\n",
    "\t\t\tdata_fname[i] = os.path.join(DATA_PATH, \"zen.2458043.12552.%s.HH.uvORA\" % ['xx', 'yy'][i])  # zen.2457698.40355.xx.HH.uvcA\n",
    "\t\t\tif i == 1:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\t# data_fname[1] = os.path.join(DATA_PATH, \"zen.2458043.12552.yy.HH.uvORA\") #zen.2457698.40355.yy.HH.uvcA\n",
    "\t\t\t\t\tif not os.path.isfile(data_fname[i]):\n",
    "\t\t\t\t\t\tdata_fname[1] = os.path.join(DATA_PATH, \"zen.2458043.12552.xx.HH.uvORA\")\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tpass\n",
    "\t\t\tdata_fname_full[i] = os.path.join(DATA_PATH, 'ObservingSession-1192201262/2458043/zen.2458043.12552.%s.HH.uvOR' % ['xx', 'yy'][i])\n",
    "\t\t\t# (data[i], dflags[i], antpos[i], ants[i], data_freqs[i], data_times[i], data_lsts[i], data_pols[i]) = hc.abscal.UVData2AbsCalDict(data_fname[i], return_meta=True)\n",
    "\t\t\t(data[i], dflags[i], antpos[i], ants[i], data_freqs[i], data_times[i], data_lsts[i], data_pols[i], data_autos[i], data_autos_flags[i]) = UVData2AbsCalDict_Auto(data_fname[i], return_meta=True)\n",
    "\t\t\n",
    "\n",
    "\t\tfor i in range(2):\n",
    "\t\t\tflist[i] = np.array(data_freqs[i]) / 10 ** 6\n",
    "\t\t\ttry:\n",
    "\t\t\t\tindex_freq[i] = np.where(flist[i] == 150)[0][0]\n",
    "\t\t\t#\t\tindex_freq = 512\n",
    "\t\t\texcept:\n",
    "\t\t\t\tindex_freq[i] = len(flist[i]) / 2\n",
    "\t\t\n",
    "\t\tif Replace_Data:\n",
    "\t\t\t\n",
    "\t\t\tfindex_list = {}\n",
    "\t\t\tautocorr_data_mfreq_ff = {}\n",
    "\t\t\tdata_full = {}\n",
    "\t\t\tdflags_full = {}\n",
    "\t\t\tantpos_full = {}\n",
    "\t\t\tants_full= {}\n",
    "\t\t\tdata_freqs_full = {}\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\tfor i in range(2):\n",
    "\t\t\t\t(data_full[i], dflags_full[i], antpos_full[i], ants_full[i], data_freqs_full[i], data_times[i], data_lsts[i], data_pols[i], data_autos[i], data_autos_flags[i]) = UVData2AbsCalDict_Auto(data_fnames[i], return_meta=True)\n",
    "\t\t\t\tdata_freqs_full[i] = data_freqs_full[i] / 1.e6\n",
    "\t\t\t\tfindex_list[i] = np.array([np.where(data_freqs_full[i] == flist[i][j])[0][0] for j in range(len(flist[i]))])\n",
    "\t\t\t\t\n",
    "\t\t\t\tautocorr_data_mfreq[i] = np.mean(np.array([np.abs(data_autos[i][ants_full[i][k], ants_full[i][k], ['xx', 'yy'][i]]) for k in range(len(ants_full[i]))]), axis=0)\n",
    "\t\t\t\t#autocorr_data_mfreq[1] = np.mean(np.array([np.abs(uvd_yy.get_data((ants[k], ants[k]))) for k in range(Nants)]), axis=0)\n",
    "\t\t\t\t\n",
    "\t\t\tdata_ff = {}\n",
    "\t\t\tdflags_ff = {}\n",
    "\t\t\tfindex = np.where(data_freqs_full[0] == 150)\n",
    "\t\t\tfor i in range(2):\n",
    "\t\t\t\tdata_ff[i] = LastUpdatedOrderedDict()\n",
    "\t\t\t\tdflags_ff[i] = LastUpdatedOrderedDict()\n",
    "\t\t\t\tfor id_key, key in enumerate(dflags[i].keys()):\n",
    "\t\t\t\t\t# key[2] = 'xx' if i == 0 else 'yy'\n",
    "\t\t\t\t\tdata_ff[i][key[0], key[1], 'xx' if i == 0 else 'yy'] = data_full[i][key[0], key[1], 'xx' if i == 0 else 'yy'][:, findex_list[i]] #if i == 0 else uvd_yy.get_data((key[0], key[1]))[:, findex_list[i]]\n",
    "\t\t\t\t\tautocorr_data_mfreq_ff[i] = autocorr_data_mfreq[i][:, findex_list[i]]\n",
    "\t\t\t\t\tdflags_ff[i][key[0], key[1], 'xx' if i == 0 else 'yy'] = dflags[i][key[0], key[1], 'xx' if i == 0 else 'yy'][:, findex_list[i]]\n",
    "\t\t\t\t\t\n",
    "\t\t\t# del data_ff[dflags[i].keys()[id_key]]\n",
    "\t\n",
    "\t\t\tdata = copy.deepcopy(data_ff)\n",
    "\t\t\tdflags = copy.deepcopy(dflags_ff)\n",
    "\t\t\tautocorr_data_mfreq = copy.deepcopy(autocorr_data_mfreq_ff)\n",
    "\t\t\t\n",
    "\t\t\tdel (data_ff)\n",
    "\t\t\tdel (dflags_ff)\n",
    "\t\t\tdel (autocorr_data_mfreq_ff)\n",
    "\t\t\tdel (data_full)\n",
    "\t\t\tdel (dflags_full)\n",
    "\t\n",
    "\telse:\n",
    "\t\tif Model_Calibration:\n",
    "\t\t\t\n",
    "\t\t\tfor i in range(2):\n",
    "\t\t\t\tmodel_fname[i] = \"/Users/JianshuLi/Documents/Miracle/Research/Cosmology/21cm Cosmology/Algorithm-Data/Data/HERA-47/ObservingSession-1192115507/2458042/zen.2458042.12552.%s.HH.uv\"%['xx','yy'][i]#/Users/JianshuLi/Documents/Miracle/Research/Cosmology/21cm Cosmology/Algorithm-Data/Data/HERA-47/Observation-1192115507/2458042/zen.2458042.13298.xx.HH.uv\n",
    "\t\t\t\t#model_fname[i] = os.path.join(DATA_PATH, 'Observation-1192114862/2458042/zen.2458042.12552.%s.HH.uv' % ['xx', 'yy'][i])\n",
    "\t\t\t\t# model_fname[1] = os.path.join(DATA_PATH, \"zen.2458042.12552.xx.HH.uvXA\") #/Users/JianshuLi/Documents/Miracle/Research/Cosmology/21cm Cosmology/Algorithm-Data/Data/HERA-47/Observation-1192114862/2458042/zen.2458042.12552.xx.HH.uv\n",
    "\t\t\t\t#\t\t\t\t(model_dred[i], mflags_dred[i], mantpos_dred[i], mants_dred[i], model_freqs_dred[i], model_times_dred[i], model_lsts_dred[i],\n",
    "\t\t\t\t#\t\t\t\t model_pols_dred[i]) = hc.abscal.UVData2AbsCalDict(model_fname_dred[i], return_meta=True)\n",
    "\t\t\t\t# (model[i], mflags[i], mantpos[i], mants[i], model_freqs[i], model_times[i], model_lsts[i], model_pols[i]) = hc.abscal.UVData2AbsCalDict(model_fname[i], return_meta=True)\n",
    "\t\t\t\t(model[i], mflags[i], mantpos[i], mants[i], model_freqs[i], model_times[i], model_lsts[i], model_pols[i], model_autos[i], model_autos_flags[i]) = UVData2AbsCalDict_Auto(model_fname[i], return_meta=True)\n",
    "\t\t\n",
    "\t\t# specify data file and load into UVData, load into dictionary\n",
    "\t\t\n",
    "\t\tfor i in range(2):\n",
    "\t\t\t#data_fname[i] = os.path.join(DATA_PATH, 'Observation-1192201262/2458043/zen.2458043.12552.%s.HH.uvOR' % ['xx', 'yy'][i])\n",
    "\t\t\t# data_fname[i] = '/Users/JianshuLi/Documents/Miracle/Research/Cosmology/21cm Cosmology/Algorithm-Data/Data/HERA-47/Observation-1192287662/2458043/zen.2458043.12552.%s.HH.uvOR'%['xx', 'yy'][i]\n",
    "\t\t\t# (data[i], dflags[i], antpos[i], ants[i], data_freqs[i], data_times[i], data_lsts[i], data_pols[i]) = hc.abscal.UVData2AbsCalDict(data_fname[i], return_meta=True)\n",
    "\t\t\t(data[i], dflags[i], antpos[i], ants[i], data_freqs[i], data_times[i], data_lsts[i], data_pols[i], data_autos[i], data_autos_flags[i]) = UVData2AbsCalDict_Auto(data_fnames[i], return_meta=True)\n",
    "\t\t\t# data_freqs[i] = data_freqs[i] / 1.e6\n",
    "\t\t\tautocorr_data_mfreq[i] = np.mean(np.array([np.abs(data_autos[i][ants[i][k], ants[i][k], ['xx', 'yy'][i]]) for k in range(len(ants[i]))]), axis=0)\n",
    "\t\t\n",
    "\t\tfor i in range(2):\n",
    "\t\t\tflist[i] = np.array(data_freqs[i]) / 10 ** 6\n",
    "\t\t\ttry:\n",
    "\t\t\t\tindex_freq[i] = np.where(flist[i] == 150)[0][0]\n",
    "\t\t\t#\t\tindex_freq = 512\n",
    "\t\t\texcept:\n",
    "\t\t\t\tindex_freq[i] = len(flist[i]) / 2\n",
    "\t\n",
    "\tif Data_Deteriorate:\n",
    "\t\tautocorr_data_mfreq[0] = np.random.uniform(0, np.max(autocorr_data_mfreq[0]), autocorr_data_mfreq[0].shape)\n",
    "\t\tautocorr_data_mfreq[1] = np.random.uniform(0, np.max(autocorr_data_mfreq[1]), autocorr_data_mfreq[1].shape)\n",
    "\telse:\n",
    "\t\tpass\n",
    "\t\n",
    "\tfor i in range(2):\n",
    "\t\tautocorr_data[i] = autocorr_data_mfreq[i][:, index_freq[i]]\n",
    "\t\n",
    "\t################# Select Frequency ####################\n",
    "\t# flist = {}\n",
    "\t# index_freq = {}\n",
    "\tantloc = {}\n",
    "\tdflags_sf = {}  # single frequency\n",
    "\t# for i in range(2):\n",
    "\t# \tflist[i] = np.array(data_freqs[i]) / 10 ** 6\n",
    "\t# \ttry:\n",
    "\t# \t\tindex_freq[i] = np.where(flist[i] == 150)[0][0]\n",
    "\t# \t#\t\tindex_freq = 512\n",
    "\t# \texcept:\n",
    "\t# \t\tindex_freq[i] = len(flist[i]) / 2\n",
    "\t\n",
    "\tfor i in range(2):\n",
    "\t\tdflags_sf[i] = LastUpdatedOrderedDict()\n",
    "\t\tfor key in dflags[i].keys():\n",
    "\t\t\tdflags_sf[i][key] = dflags[i][key][:, index_freq[i]]\n",
    "\t\n",
    "\t# ant locations\n",
    "\tfor i in range(2):\n",
    "\t\tantloc[i] = np.array(map(lambda k: antpos[i][k], ants[i]))\n",
    "\t#\tantloc_yy = np.array(map(lambda k: antpos_yy[k], ants_yy))\n",
    "\t\n",
    "\t# plot sub-array HERA layout\n",
    "\tfor j in range(2):\n",
    "\t\tplt.figure(100000 + 5 * j, figsize=(6, 6))\n",
    "\t\tplt.grid()\n",
    "\t\tplt.scatter(antloc[j][:, 0], antloc[j][:, 1], s=3000)\n",
    "\t\t_ = [plt.text(antloc[j][i, 0] - 1, antloc[j][i, 1], str(ants[j][i]), fontsize=14, color='w') for i in range(len(antloc[j]))]\n",
    "\t\tplt.title('%s-polarization selected subarray' % ['xx', 'yy'][j])\n",
    "\t\tplt.xlim(-30, 30)\n",
    "\t\tplt.ylim(-30, 30)\n",
    "\t\tplt.show(block=False)\n",
    "\t# plt.cla()\n",
    "\t\n",
    "\t############################## Autocorrelation #################################\n",
    "\tMore_Details = False\n",
    "\tif More_Details:\n",
    "\t\txxfile = data_fname[0] if not Small_ModelData else data_fname_full[0]\n",
    "\t\tyyfile = data_fname[1] if not Small_ModelData else data_fname_full[1]\n",
    "\t\t\n",
    "\t\t# Load data for autocorrelation calculating\n",
    "\t\tuvd_xx = UVData()\n",
    "\t\tuvd_xx.read_miriad(xxfile)\n",
    "\t\tuvd_xx.ants = np.unique(np.concatenate([uvd_xx.ant_1_array, uvd_xx.ant_2_array]))\n",
    "\t\tuvd_yy = UVData()\n",
    "\t\tuvd_yy.read_miriad(yyfile)\n",
    "\t\tuvd_yy.ants = np.unique(np.concatenate([uvd_yy.ant_1_array, uvd_yy.ant_2_array]))\n",
    "\t\t\n",
    "\t\t# Get metadata\n",
    "\t\tfreqs = uvd_xx.freq_array.squeeze() / 1e6\n",
    "\t\ttimes = uvd_xx.time_array.reshape(uvd_xx.Ntimes, uvd_xx.Nbls)[:, 0]\n",
    "\t\tjd_start = np.floor(times.min())\n",
    "\t\tNfreqs = len(freqs)\n",
    "\t\tNtimes = len(times)\n",
    "\t\t\n",
    "\t\t# get redundant info\n",
    "\t\taa = hc.utils.get_aa_from_uv(uvd_xx)\n",
    "\t\tinfo = hc.omni.aa_to_info(aa)\n",
    "\t\tred_bls = np.array(info.get_reds())\n",
    "\t\tants = sorted(np.unique(np.concatenate(red_bls)))\n",
    "\t\tNants = len(ants)\n",
    "\t\tNside = int(np.ceil(np.sqrt(Nants)))\n",
    "\t\tYside = int(np.ceil(float(Nants) / Nside))\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tplot_data_autocorr = False\n",
    "\t\t\tif plot_data_autocorr:  # at specific frequency\n",
    "\t\t\t\t### plot autos\n",
    "\t\t\t\tt_index = 0\n",
    "\t\t\t\tjd = times[t_index]\n",
    "\t\t\t\tutc = Time(jd, format='jd').datetime\n",
    "\t\t\t\t\n",
    "\t\t\t\txlim = (-50, Nfreqs + 50)\n",
    "\t\t\t\tylim = (-10, 30)\n",
    "\t\t\t\t\n",
    "\t\t\t\tfig, axes = plt.subplots(Yside, Nside, figsize=(14, 14), dpi=75)\n",
    "\t\t\t\tfig.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "\t\t\t\tfig.suptitle(\"JD = {0}, time = {1} UTC\".format(jd, utc), fontsize=14)\n",
    "\t\t\t\tfig.tight_layout(rect=(0, 0, 1, 0.95))\n",
    "\t\t\t\t\n",
    "\t\t\t\tk = 0\n",
    "\t\t\t\tfor i in range(Yside):\n",
    "\t\t\t\t\tfor j in range(Nside):\n",
    "\t\t\t\t\t\tax = axes[i, j]\n",
    "\t\t\t\t\t\tax.set_xlim(xlim)\n",
    "\t\t\t\t\t\tax.set_ylim(ylim)\n",
    "\t\t\t\t\t\tif k < Nants:\n",
    "\t\t\t\t\t\t\tpx, = ax.plot(10 * np.log10(np.abs(uvd_xx.get_data((ants[k], ants[k]))[t_index])), color='steelblue', alpha=0.75, linewidth=3)\n",
    "\t\t\t\t\t\t\tpy, = ax.plot(10 * np.log10(np.abs(uvd_yy.get_data((ants[k], ants[k]))[t_index])), color='darkorange', alpha=0.75, linewidth=3)\n",
    "\t\t\t\t\t\t\tax.grid(True, which='both')\n",
    "\t\t\t\t\t\t\tax.set_title(str(ants[k]), fontsize=14)\n",
    "\t\t\t\t\t\t\tif k == 0:\n",
    "\t\t\t\t\t\t\t\tax.legend([px, py], ['East', 'North'], fontsize=12)\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tax.axis('off')\n",
    "\t\t\t\t\t\tif j != 0:\n",
    "\t\t\t\t\t\t\tax.set_yticklabels([])\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t[t.set_fontsize(12) for t in ax.get_yticklabels()]\n",
    "\t\t\t\t\t\t\tax.set_ylabel(r'$10\\cdot\\log_{10}$ amplitude', fontsize=14)\n",
    "\t\t\t\t\t\tif i != Yside - 1:\n",
    "\t\t\t\t\t\t\tax.set_xticklabels([])\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t[t.set_fontsize(12) for t in ax.get_xticklabels()]\n",
    "\t\t\t\t\t\t\tax.set_xlabel('freq channel', fontsize=14)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tk += 1\n",
    "\t\t\t\tplt.show(block=False)\n",
    "\t\t\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t\t\n",
    "\t\tautocorr_data_mfreq = {}  # np.zeros((2, Ntimes, Nfreqs))\n",
    "\t\tautocorr_data_mfreq[0] = np.mean(np.array([np.abs(uvd_xx.get_data((ants[k], ants[k]))) for k in range(Nants)]), axis=0)\n",
    "\t\tautocorr_data_mfreq[1] = np.mean(np.array([np.abs(uvd_yy.get_data((ants[k], ants[k]))) for k in range(Nants)]), axis=0)\n",
    "\t\tif Data_Deteriorate:\n",
    "\t\t\tautocorr_data_mfreq[0] = np.random.uniform(0, np.max(autocorr_data_mfreq[0]), autocorr_data_mfreq[0].shape)\n",
    "\t\t\tautocorr_data_mfreq[1] = np.random.uniform(0, np.max(autocorr_data_mfreq[1]), autocorr_data_mfreq[1].shape)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\t\t\n",
    "\t\tautocorr_data = {}\n",
    "\t\tfor i in range(2):\n",
    "\t\t\tautocorr_data[i] = autocorr_data_mfreq[i][:, index_freq[i]]\n",
    "\t\t\n",
    "\t\tif Replace_Data and Small_ModelData:\n",
    "\t\t\tfindex = np.where(freqs == 150)\n",
    "\t\t\tfindex_list = {}\n",
    "\t\t\tautocorr_data_mfreq_ff = {}\n",
    "\t\t\tfor i in range(2):\n",
    "\t\t\t\tfindex_list[i] = np.array([np.where(freqs == flist[i][j])[0][0] for j in range(len(flist[i]))])\n",
    "\t\t\t\n",
    "\t\t\tdata_ff = {}\n",
    "\t\t\tdflags_ff = {}\n",
    "\t\t\tfor i in range(2):\n",
    "\t\t\t\tdata_ff[i] = LastUpdatedOrderedDict()\n",
    "\t\t\t\tdflags_ff[i] = LastUpdatedOrderedDict()\n",
    "\t\t\t\tfor id_key, key in enumerate(dflags[i].keys()):\n",
    "\t\t\t\t\t# key[2] = 'xx' if i == 0 else 'yy'\n",
    "\t\t\t\t\tdata_ff[i][key[0], key[1], 'xx' if i == 0 else 'yy'] = uvd_xx.get_data((key[0], key[1]))[:, findex_list[i]] if i == 0 else uvd_yy.get_data((key[0], key[1]))[:, findex_list[i]]\n",
    "\t\t\t\t\tautocorr_data_mfreq_ff[i] = autocorr_data_mfreq[i][:, findex_list[i]]\n",
    "\t\t\t\t\tdflags_ff[i][key[0], key[1], 'xx' if i == 0 else 'yy'] = dflags[i][key]\n",
    "\t\t\t# del data_ff[dflags[i].keys()[id_key]]\n",
    "\t\t\t\n",
    "\t\t\tdata = copy.deepcopy(data_ff)\n",
    "\t\t\tdflags = copy.deepcopy(dflags_ff)\n",
    "\t\t\tautocorr_data_mfreq = copy.deepcopy(autocorr_data_mfreq_ff)\n",
    "\t\t\t\n",
    "\t\t\tdel (data_ff)\n",
    "\t\t\tdel (dflags_ff)\n",
    "\t\t\tdel (autocorr_data_mfreq_ff)\n",
    "\t\t# del(autocorr_data_mfreq)\n",
    "\t\t\n",
    "\t\tdel (uvd_xx)\n",
    "\t\tdel (uvd_yy)\n",
    "\t\tdel (aa)\n",
    "\t\tdel (info)\n",
    "\t\n",
    "\t#\tplt.figure(100005, figsize=(6,6))\n",
    "\t#\tplt.grid()\n",
    "\t#\tplt.scatter(antloc_yy[:, 0], antloc_yy[:, 1], s=3000)\n",
    "\t#\t_ = [plt.text(antloc_yy[i, 0]-1, antloc_yy[i, 1], str(ants_yy[i]), fontsize=14, color='w') for i in range(len(antloc_yy))]\n",
    "\t#\tplt.title('yy polarization selected subarray')\n",
    "\t#\tplt.xlim(-30, 30)\n",
    "\t#\tplt.ylim(-30, 30)\n",
    "\t#\tplt.show(block=False)\n",
    "\t\n",
    "\t######################################### Calculate Baseline Coordinates #############################################\n",
    "\t# bls = odict([(x, antpos[x[0]] - antpos[x[1]]) for x in model.keys()])\n",
    "\tbls = [[], []]\n",
    "\tfor i in range(2):\n",
    "\t\tbls[i] = odict([(x, antpos[i][x[0]] - antpos[i][x[1]]) for x in data[i].keys()])\n",
    "\t\t# bls[1] = odict([(y, antpos_yy[y[0]] - antpos_yy[y[1]]) for y in data_yy.keys()])\n",
    "\t\tbls = np.array(bls)\n",
    "\t\n",
    "\tbsl_coord = [[], []]\n",
    "\tbsl_coord_x = bsl_coord[0] = np.array([bls[0][index] for index in bls[0].keys()])\n",
    "\tbsl_coord_y = bsl_coord[1] = np.array([bls[1][index] for index in bls[1].keys()])\n",
    "\t# bsl_coord_x=bsl_coord_y=bsl_coord\n",
    "\tbsl_coord = np.array(bsl_coord)\n",
    "\t\n",
    "\t################################################### Visibility ########################################################\n",
    "\tvis_data_mfreq = {}\n",
    "\t# vis_data_Omni_mfreq = np.array([data_omni[bslkeys] for bslkeys in data_omni.keys()], dtype='complex128').transpose((2,1,0)) if Model_Calibration else None\n",
    "\tfor i in range(2):\n",
    "\t\tvis_data_mfreq[i] = np.array([data[i][bslkeys] for bslkeys in data[i].keys()], dtype='complex128').transpose((2, 1, 0))\n",
    "\t\tif Data_Deteriorate:\n",
    "\t\t\t#vis_data_mfreq[i] *= np.random.normal(1, 3, vis_data_mfreq[i].shape) * np.exp(np.random.normal(1, 3, vis_data_mfreq[i].shape) + np.random.normal(1, 3, vis_data_mfreq[i].shape) * 1.j)\n",
    "\t\t\tvis_data_mfreq[i] = np.random.uniform(-np.max(np.abs(vis_data_mfreq[i])), np.max(np.abs(vis_data_mfreq[i])), vis_data_mfreq[i].shape) * np.exp(np.random.uniform(-1, 1, vis_data_mfreq[i].shape) + np.random.uniform(-1, 1, vis_data_mfreq[i].shape) * 1.j)\n",
    "\t\telse:\n",
    "\t\t\tpass\n",
    "\t\t\t\t\n",
    "\t#\tvis_data_mfreq = np.array([data_yy[bslkeys] for bslkeys in data_yy.keys()], dtype='complex128').transpose((2,1,0))\n",
    "\t\n",
    "\t#\tvis_data_mfreq = np.zeros((2,vis_data_xx_mfreq.shape[0], vis_data_xx_mfreq.shape[1], vis_data_xx_mfreq.shape[2]), dtype='complex128')\n",
    "\t#\tvis_data_mfreq[0] = vis_data_xx_mfreq\n",
    "\t#\tvis_data_mfreq[1] = vis_data_yy_mfreq\n",
    "\t\n",
    "\tvis_freq_selected = freq = flist[0][index_freq[0]]  # MHz For Omni:  0:100, 16:125, 32:150, 48:175;;; For Model:  512:150MHz   Choose xx as reference\n",
    "\t# vis_data = np.zeros((2,vis_data_mfreq.shape[2], vis_data_xx_mfreq.shape[3]), dtype='complex128')\n",
    "\tvis_data = {}\n",
    "\tfor i in range(2):\n",
    "\t\tvis_data[i] = vis_data_mfreq[i][index_freq[i], :, :]  # [pol][ freq, time, bl]\n",
    "\t\n",
    "\t# del(vis_data_mfreq)\n",
    "\t\n",
    "\t####################################################################################################################################################\n",
    "\t################################################ Unique Base Lines and Remove Redundancy ###########################################################\n",
    "\t\n",
    "#\tnp.array(omnical.arrayinfo.compute_reds(antloc)) # Alternate way to compute.\n",
    "\tUbl_list_raw = [[],[]]\n",
    "\tUbl_list = [[],[]]\n",
    "\tant_pos = [[],[]]\n",
    "\t\n",
    "\tNubl_raw = np.zeros(2, dtype=int)\n",
    "\ttimes_raw = np.zeros(2, dtype=int)\n",
    "\ttimes_raw_list = [[],[]]\n",
    "\tredundancy = [[],[]]\n",
    "\tbsl_coord_dred = [[],[]]\n",
    "\tvis_data_dred = [[],[]]\n",
    "\tvis_data_dred_mfreq = [[],[]]\n",
    "\t\n",
    "\tfor i in range(2):\n",
    "\t\tUbl_list_raw[i] = np.array(omnical.arrayinfo.compute_reds_total(antloc[i])) ## Note that a new function has been added into omnical.arrayinfo as \"compute_reds_total\" which include all ubls not only redundant ones.\n",
    "\t#Ubl_list_raw[1] = np.array(omnical.arrayinfo.compute_reds_total(antloc_yy)) ## Note that a new function has been added into omnical.arrayinfo as \"compute_reds_total\" which include all ubls not only redundant ones.\n",
    "\t\tant_pos[i] = antpos[i]\n",
    "\t#ant_pos[1] = antpos_yy\n",
    "\tfor i in range(2):\n",
    "\t\tfor i_ubl in range(len(Ubl_list_raw[i])):\n",
    "\t\t\tlist_bsl = []\n",
    "\t\t\tfor i_ubl_pair in range(len(Ubl_list_raw[0][i_ubl])):\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tlist_bsl.append(bls[i].keys().index((ant_pos[i].keys()[Ubl_list_raw[i][i_ubl][i_ubl_pair][0]], ant_pos[i].keys()[Ubl_list_raw[i][i_ubl][i_ubl_pair][1]], '%s'%['xx','yy'][i])))\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tlist_bsl.append(bls[i].keys().index((ant_pos[i].keys()[Ubl_list_raw[i][i_ubl][i_ubl_pair][0]], ant_pos[i].keys()[Ubl_list_raw[i][i_ubl][i_ubl_pair][1]], '%s'%['xx','yy'][1-i])))\n",
    "\t\t\tUbl_list[i].append(list_bsl)\n",
    "\t\n",
    "\tfor i in range(2):\t\t\n",
    "\t\tNubl_raw[i] = len(Ubl_list[i])\n",
    "\t\ttimes_raw[i] = len(data_times[i])\n",
    "\t\ttimes_raw_list[i] = data_times[i]\n",
    "\t\tbsl_coord_dred[i] = np.zeros((Nubl_raw[i], 3))\n",
    "\t\tvis_data_dred[i] = np.zeros((times_raw[i], Nubl_raw[i]), dtype='complex128')\n",
    "\t\tvis_data_dred_mfreq[i] = np.zeros((len(flist[i]), times_raw[i], Nubl_raw[i]), dtype='complex128')\n",
    "\t\n",
    "\ttry:\n",
    "\t\tvar_data_dred = [[],[]]\n",
    "\t\tvar_data_dred[0] = np.zeros((times_raw[0], Nubl_raw[0]), dtype='complex128')\n",
    "\t\tvar_data_dred[1] = np.zeros((times_raw[1], Nubl_raw[1]), dtype='complex128')\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\t\t\n",
    "\t\n",
    "\t########################### Average on Redundant baselines #############################\n",
    "\t#data_dred = {}\n",
    "\tdflags_dred = {}\n",
    "\t\t\n",
    "\tfor i in range(2):\n",
    "\t\t#data_dred[i] = {}\n",
    "\t\t#dflags_dred[i] = {}\n",
    "\t\tdflags_dred[i] = LastUpdatedOrderedDict()\n",
    "\t\tpol = ['xx', 'yy'][i]\n",
    "\t\t\n",
    "\t\tfor i_ubl in range(Nubl_raw[0]):\n",
    "\t\t\tvis_data_dred[i][:, i_ubl] = np.mean(vis_data[i].transpose()[Ubl_list[i][i_ubl]].transpose(), axis=1)\n",
    "\t\t\tbsl_coord_dred[i][i_ubl] = np.mean(bsl_coord[i][Ubl_list[i][i_ubl]], axis=0)\n",
    "\t\t\t#if Absolute_Calibration_dred:\n",
    "\t\t\tdflags_dred[i][dflags_sf[i].keys()[Ubl_list[i][i_ubl][0]]] = dflags_sf[i][dflags_sf[i].keys()[Ubl_list[i][i_ubl][0]]]\n",
    "#\t\t\t\tif i == 0:\n",
    "#\t\t\t\t\t#data_dred[i][dflags.keys()[Ubl_list[i][i_ubl][0]]] = vis_data_dred[i][:, i_ubl]\n",
    "#\t\t\t\t\tdflags_dred[i][dflags.keys()[Ubl_list[i][i_ubl][0]]] = dflags[dflags.keys()[Ubl_list[i][i_ubl][0]]]\n",
    "#\t\t\t\telse:\n",
    "#\t\t\t\t\t#data_dred[i][dflags_yy.keys()[Ubl_list[i][i_ubl][0]]] = vis_data_dred[i][:, i_ubl]\n",
    "#\t\t\t\t\tdflags_dred[i][dflags_yy.keys()[Ubl_list[i][i_ubl][0]]] = dflags_yy[dflags_yy.keys()[Ubl_list[i][i_ubl][0]]]\n",
    "\t\t\tredundancy[i].append(len(Ubl_list[i][i_ubl]))\n",
    "\t\t\ttry:\n",
    "\t\t\t\tvar_data_dred[i][:, i_ubl] = np.mean(var_data[i].transpose()[Ubl_list[i][i_ubl]].transpose(), axis=1)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tpass\n",
    "\t\t\t\t\n",
    "\t\t\t\t\n",
    "\t#vis_data_dred_mfreq = [[],[]]\n",
    "\tdflags_dred_mfreq = {}\n",
    "\t\t\n",
    "\tfor i in range(2):\n",
    "\t\t#data_dred_mfreq[i] = {}\n",
    "\t\t#dflags_dred_mfreq[i] = {}\n",
    "\t\tdflags_dred_mfreq[i] = LastUpdatedOrderedDict()\n",
    "\t\tpol = ['xx', 'yy'][i]\n",
    "\t\t\n",
    "\t\tfor i_ubl in range(Nubl_raw[0]):\n",
    "\t\t\tvis_data_dred_mfreq[i][:, :, i_ubl] = np.mean(vis_data_mfreq[i][ :, :, Ubl_list[i][i_ubl]], axis=-1)\n",
    "\t\t\t#bsl_coord_dred[i][i_ubl] = np.mean(bsl_coord[i][Ubl_list[i][i_ubl]], axis=0)\n",
    "\t\t\t#if Absolute_Calibration_dred_mfreq:\n",
    "\t\t\tdflags_dred_mfreq[i][dflags[i].keys()[Ubl_list[i][i_ubl][0]]] = dflags[i][dflags[i].keys()[Ubl_list[i][i_ubl][0]]]\n",
    "#\t\t\t\tif i == 0:\n",
    "#\t\t\t\t\t#data_dred[i][dflags.keys()[Ubl_list[i][i_ubl][0]]] = vis_data_dred[i][:, i_ubl]\n",
    "#\t\t\t\t\tdflags_dred[i][dflags.keys()[Ubl_list[i][i_ubl][0]]] = dflags[dflags.keys()[Ubl_list[i][i_ubl][0]]]\n",
    "#\t\t\t\telse:\n",
    "#\t\t\t\t\t#data_dred[i][dflags_yy.keys()[Ubl_list[i][i_ubl][0]]] = vis_data_dred[i][:, i_ubl]\n",
    "#\t\t\t\t\tdflags_dred[i][dflags_yy.keys()[Ubl_list[i][i_ubl][0]]] = dflags_yy[dflags_yy.keys()[Ubl_list[i][i_ubl][0]]]\n",
    "\t\t\t#redundancy[i].append(len(Ubl_list[i][i_ubl]))\n",
    "\t\t\ttry:\n",
    "\t\t\t\tvar_data_dred[i][:, i_ubl] = np.mean(var_data[i][ :, :, Ubl_list[i][i_ubl]], axis=-1)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tpass\n",
    "\t\t\n",
    "\n",
    "\t#wgts_dred = copy.deepcopy(dflags_dred)\n",
    "\t\t\n",
    "\t\n",
    "\tDel = True\n",
    "\tif Del and not Small_ModelData:\n",
    "\t\ttry:\n",
    "\t\t\t#del(red_bls)\n",
    "\t\t\t#del(autocorr_data_mfreq)\n",
    "\t\t\t#del(vis_data_mfreq)\n",
    "\t\t\tdel(var_data_mfreq)\n",
    "\t\t\t\t\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t\t\t\n",
    "\t\ttry:\n",
    "\t\t\tif not Keep_Red:\n",
    "\t\t\t\tdel(bsl_coord)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t\n",
    "\tsys.stdout.flush()\n",
    "\t\n",
    "\t\n",
    "\t############################### t and f ##########################\n",
    "\t# Using one of the two polarization, which should basically be same from choosing files\n",
    "\ttlist_JD = np.array(data_times[0])\n",
    "\tJD2SI_time = Time(data_times[0], format='jd').datetime\n",
    "\ttlist = np.zeros(len(data_times[0]))\n",
    "\tnt = len(tlist)\n",
    "\tnf = len(flist[0])\n",
    "\tfor i in range(len(data_times[0])):\n",
    "\t\ttlist[i] = si_t = (JD2SI_time[i].hour*3600. + JD2SI_time[i].minute*60. + JD2SI_time[i].second)/3600.\n",
    "\t#\ttlist[i] = '%.2f' %si_t\n",
    "\t\n",
    "\tif tag == '-ampcal-':\n",
    "\t\ttag = '%s-%f'%(INSTRUMENT, freq) + tag\n",
    "\telse:\n",
    "\t\ttag = '%s-%f'%(INSTRUMENT, freq)\n",
    "\ttmasks = {}\n",
    "\tfor p in ['x', 'y']:\n",
    "\t\ttmasks[p] = np.ones_like(tlist).astype(bool)\n",
    "# \t\ttmasks[p] = np.zeros_like(tlist).astype(bool)\n",
    "# \t\ttmasks[p][[nt/2, nt/2+1]] = True\n",
    "\n",
    "\tLST_Renorm = 0.179446946/(data_lsts[0][-1] - data_lsts[0][0])\n",
    "\t# for i in range(2):\n",
    "\t# \tdata_lsts[i] = data_lsts[i] * LST_Renorm\n",
    "\t\n",
    "\ttmask = tmasks['x'] & tmasks['y']\n",
    "\tif Time_Expansion_Factor == 1.:\n",
    "\t\ttlist = tlist[tmask]\n",
    "\t\tlsts = data_lsts[0][tmask] * LST_Renorm\n",
    "\telse:\n",
    "\t\ttlist = np.arange(tlist[0], tlist[0] + (tlist[-1] - tlist[0]) * (Time_Expansion_Factor + 1), (tlist[-1] - tlist[0]) * Time_Expansion_Factor/(len(tlist)-1))[tmask]\n",
    "\t\tlsts = data_lsts[0] * LST_Renorm\n",
    "\t\tlsts = np.arange(lsts[0], lsts[0] + (lsts[-1] - lsts[0]) * (Time_Expansion_Factor + 1), (lsts[-1] - lsts[0]) * Time_Expansion_Factor/(len(lsts)-1))[tmask]\n",
    "\tnt_used = len(tlist)\n",
    "\tnf_used = len(flist[0])\n",
    "\tjansky2kelvin = 1.e-26 * (C / freq) ** 2 / 2 / kB / (4 * PI / (12 * nside_standard ** 2))\n",
    "\tjansky2kelvin_mfreq = {}\n",
    "\tfor j in range(2):\n",
    "\t\tjansky2kelvin_mfreq[j] = np.array([1.e-26 * (C / flist[j][i]) ** 2 / 2 / kB / (4 * PI / (12 * nside_standard ** 2)) for i in range(len(flist[j]))])\n",
    "\t\n",
    "\t############################## Common UBL ###########################\n",
    "\tubls = {}\n",
    "\tbls_red = {}\n",
    "\t#freq = 150\n",
    "#\tnside_standard = 32\n",
    "\tbaseline_safety_factor = 3.\n",
    "\t\n",
    "\tnBL_red = len(bsl_coord_x)\n",
    "\tfor p in ['x', 'y']:\n",
    "\t\t#ubl_filename = datadir + tag + '_%s%s_%i_%i.ubl' % (p, p, nUBL, 3)\n",
    "\t\tbls_red[p] = globals()['bsl_coord_' + p]\n",
    "\tcommon_bls_red = np.array([u for u in bls_red['x'] if (u in bls_red['y'] or -u in bls_red['y'])])\n",
    "\t\n",
    "\tused_common_bls_red = common_bls_red[la.norm(common_bls_red, axis=-1) / (C / freq) <= 1.4 * nside_standard / baseline_safety_factor]#[np.argsort(la.norm(common_ubls, axis=-1))[10:]]     #remove shorted 10\n",
    "\tnBL_red_used = len(used_common_bls_red)\n",
    "\t\n",
    "\tif Keep_Red:\n",
    "\t\tnUBL = len(bsl_coord_x)\n",
    "\t\tfor p in ['x', 'y']:\n",
    "\t\t\t#ubl_filename = datadir + tag + '_%s%s_%i_%i.ubl' % (p, p, nUBL, 3)\n",
    "\t\t\tubls[p] = globals()['bsl_coord_' + p]\n",
    "\t\tcommon_ubls = np.array([u for u in ubls['x'] if (u in ubls['y'] or -u in ubls['y'])])\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tnUBL = len(bsl_coord_dred[0])\n",
    "\t\tnUBL_yy = len(bsl_coord_dred[1])\n",
    "\t\tfor i in range(2):\n",
    "\t\t\tp = ['x', 'y'][i]\n",
    "\t\t\tubls[p] = bsl_coord_dred[i]\n",
    "\t\tcommon_ubls = np.array([u for u in ubls['x'] if (u in ubls['y'] or -u in ubls['y'])])\n",
    "\t\t\n",
    "\t#common_ubls = np.array([u for u in ubls['x'] if (u in ubls['y'] or -u in ubls['y'])])\n",
    "\t#manually filter UBLs\n",
    "\tused_common_ubls = common_ubls[la.norm(common_ubls, axis=-1) / (C / freq) <= 1.4 * nside_standard / baseline_safety_factor]#[np.argsort(la.norm(common_ubls, axis=-1))[10:]]     #remove shorted 10\n",
    "\tnUBL_used = len(used_common_ubls)\n",
    "\tubl_index = {}  # stored index in each pol's ubl for the common ubls\n",
    "\tused_redundancy = {}\n",
    "\tfor p in ['x', 'y']:\n",
    "\t\tubl_index[p] = np.zeros(nUBL_used, dtype='int')\n",
    "\t\tfor i, u in enumerate(used_common_ubls):\n",
    "\t\t\tif u in ubls[p]:\n",
    "\t\t\t\tubl_index[p][i] = np.argmin(la.norm(ubls[p] - u, axis=-1)) + 1\n",
    "\t\t\telif -u in ubls[p]:\n",
    "\t\t\t\tubl_index[p][i] = - np.argmin(la.norm(ubls[p] + u, axis=-1)) - 1\n",
    "\t\t\telse:\n",
    "\t\t\t\traise Exception('Logical Error')\n",
    "                \n",
    "\tused_redundancy[0] = np.array(redundancy[0])[ubl_index['x']-1]\n",
    "\tused_redundancy[1] = np.array(redundancy[0])[ubl_index['y']-1]\n",
    "    \n",
    "\tprint '>>>>>>Used nUBL = %i, nt = %i.'%(nUBL_used, nt_used)\n",
    "\tsys.stdout.flush()\n",
    "\t\n",
    "\t######################### Beam Pattern #############################\n",
    "\t\n",
    "\tfilename = script_dir + '/../data/HERA-47/Beam-Dipole/healpix_beam.fits'\n",
    "\tbeam_E = fits.getdata(filename, extname='BEAM_E').T #E is east corresponding to X polarization\n",
    "\tbeam_nside = hp.npix2nside(beam_E.shape[1])\n",
    "\tbeam_freqs = fits.getdata(filename, extname='FREQS')\n",
    "\n",
    "\tprint('Frequencies: ')\n",
    "\tprint(beam_freqs)\n",
    "\t\n",
    "\t# select only 100-200 MHz data\n",
    "#\tfreq_select = np.where((freqs >= 100) & (freqs <=200))[0]\n",
    "#\tbeams = beams[:, freq_select]\n",
    "#\tfreqs = freqs[freq_select]\n",
    "#\tNfreqs = len(freqs)\n",
    "\n",
    "\t# take East pol and rotate to get North pol\n",
    "\tNfreqs = len(beam_freqs)\n",
    "\tbeam_theta, beam_phi = hp.pix2ang(64, np.arange(64**2 * 12))\n",
    "\t#R = hp.Rotator(rot=[0,0,-np.pi/2], deg=False)\n",
    "\tR = hp.Rotator(rot=[-np.pi/2,0,0], deg=False)\n",
    "\tbeam_theta2, beam_phi2 = R(beam_theta, beam_phi)\n",
    "\tbeam_N = np.array(map(lambda x: hp.get_interp_val(x, beam_theta2, beam_phi2), beam_E))\n",
    "\tbeam_EN = np.array([beam_E, beam_N])\n",
    "\tbeam_EN.resize(2, Nfreqs, 49152)\n",
    "\t\n",
    "#\t# normalize each frequency to max of 1\n",
    "#\tfor i in range(beam_EN.shape[-2]):\n",
    "#\t\tbeam_EN[:, i, :] /= beam_EN[:, i, :].max()\n",
    "\t\n",
    "\tlocal_beam_unpol = si.interp1d(beam_freqs, beam_EN.transpose(1, 0, 2), axis=0)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tlist)\n",
    "print(lsts)\n",
    "print(data_lsts[0])\n",
    "print(data_times[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print INSTRUMENT\n",
    "print tag\n",
    "#tag = 'ampcal'\n",
    "if INSTRUMENT == 'hera47':\n",
    "    print Nants\n",
    "    print Small_ModelData\n",
    "    print data_fname\n",
    "    print antloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tlist = np.arange(tlist[0], tlist[0] + (tlist[-1] - tlist[0]) * (Time_Expansion_Factor + 1), (tlist[-1] - tlist[0]) * Time_Expansion_Factor/len(tlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INSTRUMENT == 'hera47':\n",
    "    print bsl_coord\n",
    "    print red_bls\n",
    "    print len(red_bls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Plot_Beam = True\n",
    "if Plot_Beam:\n",
    "    plt.figure(0)\n",
    "    #ind = np.where(beam_freqs == freq)[0][0]\n",
    "    hp.mollview(10.0 * np.log10(local_beam_unpol(freq)[0,:]), title='HERA-Dipole Beam-East (%sMHz, bnside=%s)'%(freq, bnside),\n",
    "            unit='dBi')\n",
    "#     hp.mollview(10.0 * np.log10(beam_E[ind,:]), title='HERA-Dipole Beam-East (%sMHz, bnside=%s)'%(beam_freqs[ind], bnside),\n",
    "#             unit='dBi')\n",
    "    plt.savefig(script_dir + '/../Output/%s-dipole-Beam-east-%.2f-bnside-%s.pdf'%(INSTRUMENT, freq, bnside))\n",
    "    hp.mollview(10.0 * np.log10(local_beam_unpol(freq)[1,:]), title='HERA-Dipole Beam-North (%sMHz, bnside=%s)'%(freq, bnside),\n",
    "            unit='dBi')\n",
    "#     hp.mollview(10.0 * np.log10(beam_N[ind,:]), title='HERA-Dipole Beam-North (%sMHz, bnside=%s)'%(beam_freqs[ind], bnside),\n",
    "#             unit='dBi')\n",
    "    plt.savefig(script_dir + '/../Output/%s-dipole-Beam-north-%.2f-bnside-%s.pdf'%(INSTRUMENT, freq, bnside))\n",
    "    plt.show(block=False)\n",
    "    #plt.gcf().clear()\n",
    "        #plt.clf()\n",
    "        #plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print local_beam_unpol(150)[0:]\n",
    "print local_beam_unpol(150)[0:].sum()\n",
    "print local_beam_unpol(150)[0:].min()\n",
    "print local_beam_unpol(150)[0:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot_Beam = True\n",
    "if Plot_Beam:\n",
    "    plt.figure(0)\n",
    "    #ind = np.where(beam_freqs == freq)[0][0]\n",
    "    hp.mollview(10.0 * np.log10(local_beam_unpol(freq)[0,:]), coord='CG', title='HERA-Dipole Beam-East (%sMHz, bnside=%s)'%(freq, bnside),\n",
    "            unit='dBi')\n",
    "#     hp.mollview(10.0 * np.log10(beam_E[ind,:]), title='HERA-Dipole Beam-East (%sMHz, bnside=%s)'%(beam_freqs[ind], bnside),\n",
    "#             unit='dBi')\n",
    "    plt.savefig(script_dir + '/../Output/%s-dipole-Beam-east-%.2f-bnside-%s.pdf'%(INSTRUMENT, freq, bnside))\n",
    "    hp.mollview(10.0 * np.log10(local_beam_unpol(freq)[1,:]), coord='CG', title='HERA-Dipole Beam-North (%sMHz, bnside=%s)'%(freq, bnside),\n",
    "            unit='dBi')\n",
    "#     hp.mollview(10.0 * np.log10(beam_N[ind,:]), title='HERA-Dipole Beam-North (%sMHz, bnside=%s)'%(beam_freqs[ind], bnside),\n",
    "#             unit='dBi')\n",
    "    plt.savefig(script_dir + '/../Output/%s-dipole-Beam-north-%.2f-bnside-%s.pdf'%(INSTRUMENT, freq, bnside))\n",
    "    plt.show(block=False)\n",
    "    #plt.gcf().clear()\n",
    "        #plt.clf()\n",
    "        #plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "####set up vs and beam\n",
    "################\n",
    "vs = sv.Visibility_Simulator()\n",
    "vs.initial_zenith = np.array([0, lat_degree * PI / 180])  # self.zenithequ\n",
    "beam_heal_hor_x = local_beam_unpol(freq)[0]\n",
    "beam_heal_hor_y = local_beam_unpol(freq)[1]\n",
    "beam_heal_equ_x = sv.rotate_healpixmap(beam_heal_hor_x, 0, PI / 2 - vs.initial_zenith[1], vs.initial_zenith[0])\n",
    "beam_heal_equ_y = sv.rotate_healpixmap(beam_heal_hor_y, 0, PI / 2 - vs.initial_zenith[1], vs.initial_zenith[0])\n",
    "\n",
    "if Absolute_Calibration_dred_mfreq or PointSource_AbsCal:\n",
    "\tbeam_heal_hor_x_mfreq = np.array([local_beam_unpol(flist[0][i])[0] for i in range(nf_used)])\n",
    "\tbeam_heal_hor_y_mfreq = np.array([local_beam_unpol(flist[1][i])[1] for i in range(nf_used)])\n",
    "\tbeam_heal_equ_x_mfreq = np.array([sv.rotate_healpixmap(beam_heal_hor_x_mfreq[i], 0, PI / 2 - vs.initial_zenith[1], vs.initial_zenith[0]) for i in range(nf_used)])\n",
    "\tbeam_heal_equ_y_mfreq = np.array([sv.rotate_healpixmap(beam_heal_hor_y_mfreq[i], 0, PI / 2 - vs.initial_zenith[1], vs.initial_zenith[0]) for i in range(nf_used)])\n",
    "\n",
    "\n",
    "Plot_Beam = True\n",
    "if Plot_Beam:\n",
    "\tplt.figure(10)\n",
    "\t#ind = np.where(beam_freqs == freq)[0][0]\n",
    "\thp.mollview(10.0 * np.log10(beam_heal_equ_x), title='HERA-Dipole Beam-East (%sMHz, bnside=%s)'%(freq, bnside),\n",
    "\t\t\tunit='dBi')\n",
    "\tplt.savefig(script_dir + '/../Output/%s-equ-dipole-Beam-east-%.2f-bnside-%s.pdf'%(INSTRUMENT, freq, bnside))\n",
    "\thp.mollview(10.0 * np.log10(beam_heal_equ_y), title='HERA-Dipole Beam-North (%sMHz, bnside=%s)'%(freq, bnside),\n",
    "\t\t\tunit='dBi')\n",
    "\tplt.savefig(script_dir + '/../Output/%s-equ-dipole-Beam-north-%.2f-bnside-%s.pdf'%(INSTRUMENT, freq, bnside))\n",
    "\tplt.show(block=False)\n",
    "\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Plot_Beam:\n",
    "\tplt.figure(0)\n",
    "# \tind = np.where(beam_freqs == freq)[0][0]\n",
    "\thp.mollview(10.0 * np.log10(beam_heal_equ_x), coord='CG', title='HERA-Dipole Beam-East (%sMHz, bnside=%s)'%(freq, bnside),\n",
    "\t\t\tunit='dBi')\n",
    "\t#plt.savefig(script_dir + '/../Output/%s-equ-dipole-Beam-east-CG-%.2f-bnside-%s.pdf'%(INSTRUMENT, beam_freqs[ind], bnside))\n",
    "\thp.mollview(10.0 * np.log10(beam_heal_equ_y), coord='CG', title='HERA-Dipole Beam-North (%sMHz, bnside=%s)'%(freq, bnside),\n",
    "\t\t\tunit='dBi')\n",
    "\t#plt.savefig(script_dir + '/../Output/%s-equ-dipole-Beam-north-CG-%.2f-bnside-%s.pdf'%(INSTRUMENT, beam_freqs[ind], bnside))\n",
    "\tplt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################### Delete some Input Data ##############################\n",
    "Del=True\n",
    "if Del:\n",
    "\t#del(data)\n",
    "\t#del(data_yy)\n",
    "\ttry:\n",
    "\t\t#del(model)\n",
    "\t\t#del(model_yy)\n",
    "\t\tdel(data_omni)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "####initial A to compute beam weight\n",
    "#####################\n",
    "A_version = 1.0\n",
    "A = {}\n",
    "for p in ['x', 'y']:\n",
    "\tpol = p + p\n",
    "\t# ubl file\n",
    "\t#// ubl_filename = datadir + tag + '_%s%s_%i_%i.ubl' % (p, p, nUBL, 3)\n",
    "\t#ubls = np.array([[0,0,0]])\n",
    "\t#//np.fromfile(ubl_filename, dtype='float32').reshape((nUBL, 3))\n",
    "\tprint \"%i UBLs to include, longest baseline is %i wavelengths for Pol: %s\" % (len(ubls[p]), np.max(np.linalg.norm(ubls[p], axis=1)) / (C / freq), pol)\n",
    "\tprint \"%i Used-Common-UBLs to include, longest baseline is %i wavelengths for Pol: %s\" % (len(used_common_ubls), np.max(np.linalg.norm(used_common_ubls, axis=1)) / (C / freq), pol)\n",
    "\n",
    "\t# beam\n",
    "\tif p == 'x':\n",
    "\t\tbeam_heal_equ = beam_heal_equ_x\n",
    "\telif p == 'y':\n",
    "\t\tbeam_heal_equ = beam_heal_equ_x\n",
    "\tprint \"Computing sky weighting A matrix for %s pol...\" % p\n",
    "\tsys.stdout.flush()\n",
    "\n",
    "\tA[p] = np.zeros((nt_used * len(used_common_ubls), 12 * nside_beamweight ** 2), dtype='complex128')\n",
    "\n",
    "\ttimer = time.time()\n",
    "\tfor i in np.arange(12 * nside_beamweight ** 2):\n",
    "\t\tdec, ra = hpf.pix2ang(nside_beamweight, i)  # gives theta phi\n",
    "\t\tdec = PI / 2 - dec\n",
    "\t\tprint \"\\r%.1f%% completed\" % (100. * float(i) / (12. * nside_beamweight ** 2)),\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tif abs(dec - lat_degree * PI / 180) <= PI / 2:\n",
    "\t\t\tA[p][:, i] = vs.calculate_pointsource_visibility(ra, dec, used_common_ubls, freq, beam_heal_equ=beam_heal_equ, tlist=lsts).flatten()\n",
    "\n",
    "\tprint \"%f minutes used\" % (float(time.time() - timer) / 60.)\n",
    "\tsys.stdout.flush()\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "###beam weights using an equal pixel A matrix######\n",
    "#################################################\n",
    "print \"Computing beam weight...\",\n",
    "sys.stdout.flush()\n",
    "beam_weight = ((la.norm(A['x'], axis=0) ** 2 + la.norm(A['y'], axis=0) ** 2) ** .5)[hpf.nest2ring(nside_beamweight, range(12 * nside_beamweight ** 2))]\n",
    "beam_weight = beam_weight / np.mean(beam_weight)\n",
    "thetas_standard, phis_standard = hpf.pix2ang(nside_standard, range(hpf.nside2npix(nside_standard)), nest=True)\n",
    "beam_weight = hpf.get_interp_val(beam_weight, thetas_standard, phis_standard, nest=True) #np.array([beam_weight for i in range(nside_standard ** 2 / nside_beamweight ** 2)]).transpose().flatten()\n",
    "print \"done.\"\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#####################GSM###########################\n",
    "#############################################\n",
    "pca1 = hp.fitsfunc.read_map(script_dir + '/../data/gsm1.fits' + str(nside_standard))\n",
    "pca2 = hp.fitsfunc.read_map(script_dir + '/../data/gsm2.fits' + str(nside_standard))\n",
    "pca3 = hp.fitsfunc.read_map(script_dir + '/../data/gsm3.fits' + str(nside_standard))\n",
    "components = np.loadtxt(script_dir + '/../data/components.dat')\n",
    "scale_loglog = si.interp1d(np.log(components[:, 0]), np.log(components[:, 1]))\n",
    "w1 = si.interp1d(components[:, 0], components[:, 2])\n",
    "w2 = si.interp1d(components[:, 0], components[:, 3])\n",
    "w3 = si.interp1d(components[:, 0], components[:, 4])\n",
    "gsm_standard = np.exp(scale_loglog(np.log(freq))) * (w1(freq) * pca1 + w2(freq) * pca2 + w3(freq) * pca3)\n",
    "if Absolute_Calibration_dred_mfreq or PointSource_AbsCal:\n",
    "\tgsm_standard_mfreq = np.array([np.exp(scale_loglog(np.log(flist[0][i]))) * (w1(flist[0][i]) * pca1 + w2(flist[0][i]) * pca2 + w3(flist[0][i]) * pca3) for i in range(nf_used)])\n",
    "\n",
    "# rotate sky map and converts to nest\n",
    "equatorial_GSM_standard = np.zeros(12 * nside_standard ** 2, 'float')\n",
    "print \"Rotating GSM_standard and converts to nest...\",\n",
    "\n",
    "if INSTRUMENT == 'miteor':\n",
    "\tDecimalYear = 2013.58 #2013, 7, 31, 16, 47, 59, 999998)\n",
    "\tJulianEpoch = 2013.58\n",
    "elif INSTRUMENT == 'hera47':\n",
    "\tDecimalYear = Time(data_times[0][0], format='jd').decimalyear + (np.mean(Time(data_times[0], format='jd').decimalyear) - Time(data_times[0][0], format='jd').decimalyear) * Time_Expansion_Factor\n",
    "\tJulianEpoch = Time(data_times[0][0], format='jd').jyear + (np.mean(Time(data_times[0], format='jd').jyear) - Time(data_times[0][0], format='jd').jyear) * Time_Expansion_Factor  # np.mean(Time(data_times[0], format='jd').jyear)\n",
    "\n",
    "sys.stdout.flush()\n",
    "equ_to_gal_matrix = hp.rotator.Rotator(coord='cg').mat.dot(sv.epoch_transmatrix(2000, stdtime=JulianEpoch))\n",
    "ang0, ang1 = hp.rotator.rotateDirection(equ_to_gal_matrix,\n",
    "\t\t\t\t\thpf.pix2ang(nside_standard, range(12 * nside_standard ** 2), nest=True))\n",
    "equatorial_GSM_standard = hpf.get_interp_val(gsm_standard, ang0, ang1)\n",
    "if Absolute_Calibration_dred_mfreq or PointSource_AbsCal:\n",
    "\tequatorial_GSM_standard_mfreq = np.array([hpf.get_interp_val(gsm_standard_mfreq[i], ang0, ang1) for i in range(nf_used)])\n",
    "print \"done.\"\n",
    "\n",
    "Del=True\n",
    "if Del:\n",
    "\tdel(pca1)\n",
    "\tdel(pca2)\n",
    "\tdel(pca3)\n",
    "\tdel(w1)\n",
    "\tdel(w2)\n",
    "\tdel(w3)\n",
    "\tdel(components)\n",
    "\tdel(scale_loglog)\n",
    "\tdel(gsm_standard)\n",
    "\ttry:\n",
    "\t\tdel(gsm_standard_mfreq)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time(2458044.66691, format='jd').datetime # 2458044.12551; 2458044.66691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "####simulate visibilities using non dynamic pixelization###\n",
    "##########################################\n",
    "full_sim_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_texp%s.simvis'%(INSTRUMENT, freq, nUBL_used+1, nt_used, nside_standard, bnside, Time_Expansion_Factor)\n",
    "sim_vis_xx_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_texp%s_vis_sim_xx.simvis'%(INSTRUMENT, freq, nUBL_used+1, nt_used, nside_standard, bnside, Time_Expansion_Factor)\n",
    "sim_vis_yy_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_texp%s_vis_sim_yy.simvis'%(INSTRUMENT, freq, nUBL_used+1, nt_used, nside_standard, bnside, Time_Expansion_Factor)\n",
    "if simulation_opt == 1:\n",
    "\t\n",
    "\tif os.path.isfile(full_sim_filename):\n",
    "\t\tfullsim_vis = np.fromfile(full_sim_filename, dtype='complex128').reshape((2, nUBL_used+1, nt_used))\n",
    "\t\tfullsim_vis[0][:-1,:].astype('complex128').tofile(sim_vis_xx_filename)\n",
    "\t\tfullsim_vis[1][:-1,:].astype('complex128').tofile(sim_vis_yy_filename)\n",
    "\t\t\n",
    "\telse:\n",
    "\n",
    "\t\tfullsim_vis = np.zeros((2, nUBL_used + 1, nt_used), dtype='complex128')#since its going to accumulate along the pixels it needs to start with complex128. significant error if start with complex64\n",
    "\t\tfull_sim_ubls = np.concatenate((used_common_ubls, [[0, 0, 0]]), axis=0)#tag along auto corr\n",
    "\t\tfull_thetas, full_phis = hpf.pix2ang(nside_standard, range(hpf.nside2npix(nside_standard)), nest=True)\n",
    "\t\tfull_decs = PI / 2 - full_thetas\n",
    "\t\tfull_ras = full_phis\n",
    "\t\tfull_sim_mask = hpf.get_interp_val(beam_weight, full_thetas, full_phis, nest=True) > 0\n",
    "\t\t# fullsim_vis_DBG = np.zeros((2, len(used_common_ubls), nt_used, np.sum(full_sim_mask)), dtype='complex128')\n",
    "\n",
    "\t\tprint \"Simulating visibilities, %s, expected time %.1f min\"%(datetime.datetime.now(), 14.6 * (nUBL_used / 78.) * (nt_used / 193.) * (np.sum(full_sim_mask) / 1.4e5)),\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tmasked_equ_GSM = equatorial_GSM_standard[full_sim_mask]\n",
    "\t\ttimer = time.time()\n",
    "\t\tfor p, beam_heal_equ in enumerate([beam_heal_equ_x, beam_heal_equ_y]):\n",
    "\t\t\tfor i, (ra, dec) in enumerate(zip(full_ras[full_sim_mask], full_decs[full_sim_mask])):\n",
    "\t\t\t\tres = vs.calculate_pointsource_visibility(ra, dec, full_sim_ubls, freq, beam_heal_equ=beam_heal_equ, tlist=lsts) / 2\n",
    "\t\t\t\tfullsim_vis[p] += masked_equ_GSM[i] * res\n",
    "\t\t\t\t# fullsim_vis_DBG[p, ..., i] = res[:-1]\n",
    "\t\t\t\t#autocorr = ~16*la.norm, ~80*np.std, ~1.e-5*np.corrrelate\n",
    "\t\tprint \"simulated visibilities in %.1f minutes.\"%((time.time() - timer) / 60.)\n",
    "\t\tfullsim_vis.astype('complex128').tofile(full_sim_filename)\n",
    "\t\tfullsim_vis[0][:-1,:].astype('complex128').tofile(sim_vis_xx_filename)\n",
    "\t\tfullsim_vis[1][:-1,:].astype('complex128').tofile(sim_vis_yy_filename)\n",
    "\t\t\n",
    "\tautocorr_vis = np.abs(fullsim_vis[:, -1])\n",
    "\tif crosstalk_type == 'autocorr':\n",
    "\t\tautocorr_vis_normalized = np.array([autocorr_vis[p] / (la.norm(autocorr_vis[p]) / la.norm(np.ones_like(autocorr_vis[p]))) for p in range(2)])\n",
    "\telse:\n",
    "\t\tautocorr_vis_normalized = np.ones((2, nt_used))\n",
    "\tfullsim_vis = fullsim_vis[:, :-1].transpose((1, 0, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullsim_vis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print autocorr_vis.mean()\n",
    "print(np.abs(fullsim_vis[0,0]).mean())\n",
    "print(np.abs(fullsim_vis[0,0]).max())\n",
    "print(np.abs(fullsim_vis[0,0]).min())\n",
    "print(np.abs(fullsim_vis[0,0]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_data_error:\n",
    "\t#plt.clf()\n",
    "\tplt.figure(30)\n",
    "\tplt.plot(autocorr_vis_normalized.transpose())\n",
    "\tplt.title('Autocorr_vis_normalized(%s-dipole-data_error-fullvis-north-%.2f-bnside-%s-nside_standard-%s-texp%s)'%(INSTRUMENT, freq, bnside, nside_standard, Time_Expansion_Factor))\n",
    "\tplt.ylim([0, 2])\n",
    "\tplt.savefig(script_dir + '/../Output/%s-dipole-data_error-fullvis-north-%.2f-bnside-%s-nside_standard-%s-texp%s.pdf'%(INSTRUMENT, freq, bnside, nside_standard, Time_Expansion_Factor))\n",
    "\tplt.show(block=False)\n",
    "\t#plt.gcf().clear()\n",
    "\t#plt.clf()\n",
    "\t#plt.close()\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################### Absolute Calibration on Omnicaled Data #############################################\n",
    "if Absolute_Calibration_red:\n",
    "\tfull_redabs_sim_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_texp%s_redabs.simvis'%(INSTRUMENT, freq, nBL_red_used+1, nt_used, nside_standard, bnside, Time_Expansion_Factor)\n",
    "\tredabs_sim_vis_xx_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_texp%s_vis_redabs_sim_xx.simvis'%(INSTRUMENT, freq, nBL_red_used+1, nt_used, nside_standard, bnside, Time_Expansion_Factor)\n",
    "\tredabs_sim_vis_yy_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_texp%s_vis_redabs_sim_yy.simvis'%(INSTRUMENT, freq, nBL_red_used+1, nt_used, nside_standard, bnside, Time_Expansion_Factor)\n",
    "\t\t\n",
    "\tif os.path.isfile(full_redabs_sim_filename):\n",
    "\t\tfullsim_vis_red = np.fromfile(full_redabs_sim_filename, dtype='complex128').reshape((2, nBL_red_used+1, nt_used))\n",
    "\t\tfullsim_vis_red[0][:-1,:].astype('complex128').tofile(redabs_sim_vis_xx_filename)\n",
    "\t\tfullsim_vis_red[1][:-1,:].astype('complex128').tofile(redabs_sim_vis_yy_filename)\n",
    "\t\t\n",
    "\telse:\n",
    "\n",
    "\t\tfullsim_vis_red = np.zeros((2, nBL_red_used + 1, nt_used), dtype='complex128')#since its going to accumulate along the pixels it needs to start with complex128. significant error if start with complex64\n",
    "\t\tfull_sim_bls_red = np.concatenate((used_common_bls_red, [[0, 0, 0]]), axis=0)#tag along auto corr\n",
    "\t\tfull_thetas, full_phis = hpf.pix2ang(nside_standard, range(hpf.nside2npix(nside_standard)), nest=True)\n",
    "\t\tfull_decs = PI / 2 - full_thetas\n",
    "\t\tfull_ras = full_phis\n",
    "\t\tfull_sim_mask = hpf.get_interp_val(beam_weight, full_thetas, full_phis, nest=True) > 0\n",
    "\t\t# fullsim_vis_DBG = np.zeros((2, len(used_common_ubls), nt_used, np.sum(full_sim_mask)), dtype='complex128')\n",
    "\n",
    "\t\tprint \"Simulating redundant visibilities, %s, expected time %.1f min\"%(datetime.datetime.now(), 14.6 * (nBL_red_used / 78.) * (nt_used / 193.) * (np.sum(full_sim_mask) / 1.4e5)),\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tmasked_equ_GSM = equatorial_GSM_standard[full_sim_mask]\n",
    "\t\ttimer = time.time()\n",
    "\t\tfor p, beam_heal_equ in enumerate([beam_heal_equ_x, beam_heal_equ_y]):\n",
    "\t\t\tfor i, (ra, dec) in enumerate(zip(full_ras[full_sim_mask], full_decs[full_sim_mask])):\n",
    "\t\t\t\tres_red = vs.calculate_pointsource_visibility(ra, dec, full_sim_bls_red, freq, beam_heal_equ=beam_heal_equ, tlist=lsts) / 2\n",
    "\t\t\t\tfullsim_vis_red[p] += masked_equ_GSM[i] * res_red\n",
    "\t\t\t\t# fullsim_vis_DBG[p, ..., i] = res[:-1]\n",
    "\t\t\t\t#autocorr = ~16*la.norm, ~80*np.std, ~1.e-5*np.corrrelate\n",
    "\t\tprint \"simulated redundant visibilities in %.1f minutes.\"%((time.time() - timer) / 60.)\n",
    "\t\tfullsim_vis_red.astype('complex128').tofile(full_redabs_sim_filename)\n",
    "\t\tfullsim_vis_red[0][:-1,:].astype('complex128').tofile(redabs_sim_vis_xx_filename)\n",
    "\t\tfullsim_vis_red[1][:-1,:].astype('complex128').tofile(redabs_sim_vis_yy_filename)\n",
    "\t\t\n",
    "\tautocorr_vis_red = np.abs(fullsim_vis_red[:, -1])\n",
    "\tif crosstalk_type == 'autocorr':\n",
    "\t\tautocorr_vis_red_normalized = np.array([autocorr_vis_red[p] / (la.norm(autocorr_vis_red[p]) / la.norm(np.ones_like(autocorr_vis_red[p]))) for p in range(2)])\n",
    "\telse:\n",
    "\t\tautocorr_vis_red_normalized = np.ones((2, nt_used))\n",
    "\tfullsim_vis_red = fullsim_vis_red[:, :-1].transpose((1, 0, 2)) \n",
    "\n",
    "\tif plot_data_error:\n",
    "\t\t#plt.clf()\n",
    "\t\tplt.figure(3000000)\n",
    "\t\tplt.plot(autocorr_vis_red_normalized.transpose())\n",
    "\t\tplt.title('Autocorr_vis_normalized(%s-dipole-data_error-fullvis_red-north-%.2f-bnside-%s-nside_standard-%s-texp-%s)' % (INSTRUMENT, freq, bnside, nside_standard, Time_Expansion_Factor))\n",
    "\t\tplt.ylim([0, 2])\n",
    "\t\tplt.savefig(script_dir + '/../Output/%s-dipole-data_error-fullvis_red-north-%.2f-bnside-%s-nside_standard-%s-texp-%s.pdf' % (INSTRUMENT, freq, bnside, nside_standard, Time_Expansion_Factor))\n",
    "\t\tplt.show(block=False)\n",
    "\t\t#plt.gcf().clear()\n",
    "\t\t#plt.clf()\n",
    "\t\t#plt.close()\n",
    "\tsys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if Absolute_Calibration_dred_mfreq: # Used 9.4 min. 64*9*60*12280\n",
    "\tfull_sim_filename_mfreq = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_texp%s_mfreq%s-%s-%s.simvis'%(INSTRUMENT, nUBL_used+1, nt_used, nside_standard, bnside, Time_Expansion_Factor, np.min(flist[0]), np.max(flist[0]), len(flist[0]))\n",
    "\tsim_vis_xx_filename_mfreq = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_texp%s_vis_sim_xx_mfreq%s-%s-%s.simvis'%(INSTRUMENT, nUBL_used+1, nt_used, nside_standard, bnside, Time_Expansion_Factor, np.min(flist[0]), np.max(flist[0]), len(flist[0]))\n",
    "\tsim_vis_yy_filename_mfreq = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_texp%s_vis_sim_yy_mfreq%s-%s-%s.simvis'%(INSTRUMENT, nUBL_used+1, nt_used, nside_standard, bnside, Time_Expansion_Factor, np.min(flist[0]), np.max(flist[0]), len(flist[1]))\n",
    "\tif simulation_opt == 1:\n",
    "\t\t\n",
    "\t\tif os.path.isfile(full_sim_filename_mfreq):\n",
    "\t\t\tfullsim_vis_mfreq = np.fromfile(full_sim_filename_mfreq, dtype='complex128').reshape((2, nUBL_used+1, nt_used, nf_used))\n",
    "\t\t\tfullsim_vis_mfreq[0][:-1].astype('complex128').tofile(sim_vis_xx_filename_mfreq)\n",
    "\t\t\tfullsim_vis_mfreq[1][:-1].astype('complex128').tofile(sim_vis_yy_filename_mfreq)\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\n",
    "\t\t\tfullsim_vis_mfreq = np.zeros((2, nUBL_used + 1, nt_used, nf_used), dtype='complex128')#since its going to accumulate along the pixels it needs to start with complex128. significant error if start with complex64\n",
    "\t\t\tfull_sim_ubls = np.concatenate((used_common_ubls, [[0, 0, 0]]), axis=0)#tag along auto corr\n",
    "\t\t\tfull_thetas, full_phis = hpf.pix2ang(nside_standard, range(hpf.nside2npix(nside_standard)), nest=True)\n",
    "\t\t\tfull_decs = PI / 2 - full_thetas\n",
    "\t\t\tfull_ras = full_phis\n",
    "\t\t\tfull_sim_mask = hpf.get_interp_val(beam_weight, full_thetas, full_phis, nest=True) > 0\n",
    "\t\t\t# fullsim_vis_DBG = np.zeros((2, len(used_common_ubls), nt_used, np.sum(full_sim_mask)), dtype='complex128')\n",
    "\n",
    "\t\t\tprint \"Simulating visibilities, %s, expected time %.1f min\"%(datetime.datetime.now(), 14.6 * nf_used * (nUBL_used / 78.) * (nt_used / 193.) * (np.sum(full_sim_mask) / 1.4e5)),\n",
    "\t\t\tsys.stdout.flush()\n",
    "\t\t\tmasked_equ_GSM_mfreq = equatorial_GSM_standard_mfreq[:, full_sim_mask]\n",
    "\t\t\ttimer = time.time()\n",
    "\t\t\tfor id_f, f in enumerate(flist[0]):\n",
    "\t\t\t\tfor p, beam_heal_equ in enumerate([beam_heal_equ_x_mfreq[id_f], beam_heal_equ_y_mfreq[id_f]]):\n",
    "\t\t\t\t\tfor i, (ra, dec) in enumerate(zip(full_ras[full_sim_mask], full_decs[full_sim_mask])):\n",
    "\t\t\t\t\t\tres = vs.calculate_pointsource_visibility(ra, dec, full_sim_ubls, f, beam_heal_equ=beam_heal_equ, tlist=lsts) / 2\n",
    "\t\t\t\t\t\tfullsim_vis_mfreq[p, :, :, id_f] += masked_equ_GSM_mfreq[id_f, i] * res\n",
    "\t\t\t\t\t\t# fullsim_vis_DBG[p, ..., i] = res[:-1]\n",
    "\t\t\t\t\t\t#autocorr = ~16*la.norm, ~80*np.std, ~1.e-5*np.corrrelate\n",
    "\t\t\tprint \"simulated visibilities in %.1f minutes.\"%((time.time() - timer) / 60.)\n",
    "\t\t\tfullsim_vis_mfreq.astype('complex128').tofile(full_sim_filename_mfreq)\n",
    "\t\t\tfullsim_vis_mfreq[0][:-1, :, :].astype('complex128').tofile(sim_vis_xx_filename_mfreq)\n",
    "\t\t\tfullsim_vis_mfreq[1][:-1, :, :].astype('complex128').tofile(sim_vis_yy_filename_mfreq)\n",
    "\t\t\t\n",
    "\t\tautocorr_vis_mfreq = np.abs(fullsim_vis_mfreq[:, -1])\n",
    "#\t\tif crosstalk_type == 'autocorr':\n",
    "#\t\t\tautocorr_vis_normalized = np.array([autocorr_vis[p] / (la.norm(autocorr_vis[p]) / la.norm(np.ones_like(autocorr_vis[p]))) for p in range(2)])\n",
    "#\t\telse:\n",
    "#\t\t\tautocorr_vis_normalized = np.ones((2, nt_used))\n",
    "\t\tfullsim_vis_mfreq = fullsim_vis_mfreq[:, :-1].transpose((1, 0, 2, 3)) # (uBL, Pol, Times, Freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if INSTRUMENT == 'hera47':\n",
    "    model_sf = {}\n",
    "    model_dred = {}\n",
    "    model_dred_mfreq = {}\n",
    "    data = {}\n",
    "    data_sf = {}\n",
    "    data_dred = {}\n",
    "    data_dred_mfreq = {}\n",
    "    data_dred_mfreq_pscal = {}\n",
    "    interp_flags_dred_mfreq ={}\n",
    "    interp_flags_dred_mfreq_pscal ={}\n",
    "    AC = {}\n",
    "    AC_sf = {}\n",
    "    AC_dred = {}\n",
    "    AC_dred_mfreq = {}\n",
    "    AC_dred_mfreq_pscal = {}\n",
    "    freq_to_cal = [freq]\n",
    "    fulldflags = {}\n",
    "    auto_select_dred_mfreq = {}\n",
    "    auto_select_dred_mfreq_pscal = {}\n",
    "\n",
    "    #\ttry:\n",
    "    #\t\tcdata = copy.deepcopy(data)\n",
    "    #\texcept:\n",
    "    #\t\tpass\n",
    "\n",
    "    try:\n",
    "        cdflags_sf = copy.deepcopy(dflags_sf)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        cdflags_dred = copy.deepcopy(dflags_dred)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        cdflags = copy.deepcopy(dflags)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        cdflags_dred_mfreq = copy.deepcopy(dflags_dred_mfreq)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #cwgts = copy.deepcopy(wgts)\n",
    "    #cwgts_dred = copy.deepcopy(wgts_dred)\n",
    "\n",
    "    bl_select = 0\n",
    "    bl = dflags.keys()[bl_select] #dflags and dflags_yy #[(24, 53, 'xx')\n",
    "    fig = {}\n",
    "    axes = {}\n",
    "    fig_data = {}\n",
    "    axes_data = {}\n",
    "\n",
    "    bl_dred_select = 0\n",
    "    bl_dred = dflags_dred[0].keys()[bl_dred_select] #if Absolute_Calibration_dred else None #[(25, 37, 'xx')\n",
    "    fig2 = {}\n",
    "    axes2 = {}\n",
    "    fig2_data = {}\n",
    "    axes2_data = {}\n",
    "\n",
    "    bl_dred_mfreq_select = 8\n",
    "    bl_dred_mfreq = [dflags_dred_mfreq[0].keys()[bl_dred_mfreq_select], dflags_dred_mfreq[1].keys()[bl_dred_mfreq_select]]  #[(25, 37, 'xx'), (25, 37, 'yy')]\n",
    "    fig3 = {}\n",
    "    axes3 = {}\n",
    "    fig3_data = {}\n",
    "    axes3_data = {}\n",
    "    fig3_data_abscorr = {} \n",
    "    axes3_data_abscorr = {}\n",
    "\n",
    "    bl_dred_mfreq_pscal_select = 8\n",
    "    bl_dred_mfreq_pscal = [dflags_dred_mfreq[0].keys()[bl_dred_mfreq_pscal_select], dflags_dred_mfreq[1].keys()[bl_dred_mfreq_pscal_select]]  #[(25, 37, 'xx'), (25, 37, 'yy')]\n",
    "    fig4 = {}\n",
    "    axes4 = {}\n",
    "    fig4_data = {}\n",
    "    axes4_data = {}\n",
    "    fig4_data_abscorr = {} \n",
    "    axes4_data_abscorr = {}\n",
    "\n",
    "    delay_corr_data = {}\n",
    "    delay_corr_data_sf = {}\n",
    "    delay_corr_data_dred = {}\n",
    "    delay_corr_data_dred_mfreq = {}\n",
    "    delay_corr_data_dred_mfreq_pscal = {}\n",
    "    DAC = {}\n",
    "    DAC_sf = {}\n",
    "    DAC_dred = {}\n",
    "    DAC_dred_mfreq = {}\n",
    "    DAC_dred_mfreq_pscal = {}\n",
    "    dly_phs_corr_data = {}\n",
    "    dly_phs_corr_data_sf = {}\n",
    "    dly_phs_corr_data_dred = {}\n",
    "    dly_phs_corr_data_dred_mfreq = {}\n",
    "    dly_phs_corr_data_dred_mfreq_pscal = {}\n",
    "    DPAC = {}\n",
    "    DPAC_sf = {}\n",
    "    DPAC_dred = {}\n",
    "    DPAC_dred_mfreq = {}\n",
    "    DPAC_dred_mfreq_pscal = {}\n",
    "    abs_corr_data = {}\n",
    "    abs_corr_data_sf = {}\n",
    "    abs_corr_data_dred = {}\n",
    "    abs_corr_data_dred_mfreq = {}\n",
    "    abs_corr_data_dred_mfreq_pscal = {}\n",
    "\n",
    "    vis_data_dred_mfreq_abscal = [[], []]\n",
    "    vis_data_dred_mfreq_pscal_abscal = [[], []]\n",
    "    autocorr_data_dred_mfreq_abscal = [[], []]\n",
    "    autocorr_data_dred_mfreq_pscal_abscal = [[], []]\n",
    "    vis_data_dred_abscal = [[], []]\n",
    "    vis_data_dred_pscal_abscal = [[], []]\n",
    "    autocorr_data_dred_abscal = [[], []]\n",
    "    autocorr_data_dred_pscal_abscal = [[], []]\n",
    "\n",
    "    add_Autobsl = False # Whether we add (0,0,0) to calculate autocorr or not.\n",
    "\n",
    "    #\t\tmodel = (copy.deepcopy(data)).astype('complex128')\n",
    "    #\t\tmodel_yy = copy.deepcopy(data_yy).astype('complex128')\n",
    "    for i in range(2):\n",
    "        model_sf[i] = LastUpdatedOrderedDict()\n",
    "        model_sf[i] = LastUpdatedOrderedDict()\n",
    "        model_dred[i] = LastUpdatedOrderedDict()\n",
    "        model_dred_mfreq[i] = LastUpdatedOrderedDict()\n",
    "        #data[i] = LastUpdatedOrderedDict()\n",
    "        data_sf[i] = LastUpdatedOrderedDict()\n",
    "        data_dred[i] = LastUpdatedOrderedDict()\n",
    "        data_dred_mfreq[i] = LastUpdatedOrderedDict()\n",
    "        pol = ['xx', 'yy'][i]\n",
    "\n",
    "        #fulldflags[i] = hc.abscal.UVData2AbsCalDict(data_fname_full[i], return_meta=True)[1] # assume autocorr no RFI flagged.\n",
    "\n",
    "        if Absolute_Calibration_red:\n",
    "            keys = dflags_sf[i].keys() # if i == 0 else dflags_yy.keys()\n",
    "            for key_index, key in enumerate(keys):\n",
    "                model_sf[i][key] = fullsim_vis_red[key_index, i, :]\n",
    "                data_sf[i][key] = vis_data[i][:, key_index]\n",
    "            model_sf[i][keys[0][0], keys[0][0], keys[0][2]] = autocorr_vis_red[i] # not lose generality, choose the autocorrelation of first antenna in the first UBL as visibility in last line for autocorrelation calibraiton.\n",
    "            data_sf[i][keys[0][0], keys[0][0], keys[0][2]] = autocorr_data[i]\n",
    "            cdflags_sf[i][keys[0][0], keys[0][0], keys[0][2]] = np.array([False]*len(autocorr_data[i]))\n",
    "            print(keys)\n",
    "            print(keys[0][0])\n",
    "\n",
    "\n",
    "        if Absolute_Calibration_dred:\n",
    "            for key_index_dred, key_dred in enumerate(dflags_dred[i].keys()):\n",
    "                model_dred[i][key_dred] = fullsim_vis[key_index_dred, i, :]\n",
    "                data_dred[i][key_dred] = vis_data_dred[i][:, key_index_dred]\n",
    "            model_dred[i][dflags_dred[i].keys()[0][0], dflags_dred[i].keys()[0][0], dflags_dred[i].keys()[0][2]] = autocorr_vis[i] # not lose generality, choose the first anntena in the first UBL for autocorrelation calibraiton.\n",
    "            data_dred[i][dflags_dred[i].keys()[0][0], dflags_dred[i].keys()[0][0], dflags_dred[i].keys()[0][2]] = autocorr_data[i] # add the autocorrelation of first antenna in the first UBL as the last line in visibility.\n",
    "            cdflags_dred[i][dflags_dred[i].keys()[0][0], dflags_dred[i].keys()[0][0], dflags_dred[i].keys()[0][2]] = np.array([False]*len(autocorr_data[i]))\n",
    "            print(dflags_dred[i].keys())\n",
    "            print(dflags_dred[i].keys()[0][0])\n",
    "\n",
    "\n",
    "    #\t\tif Absolute_Calibration_dred_mfreq:\n",
    "    #\t\t\tkeys = dflags_dred_mfreq[i].keys()\n",
    "    #\t\t\tfor key_index, key in enumerate(keys):\n",
    "    #\t\t\t\tmodel[i][key] = fullsim_vis_mfreq[key_index_dred, i]\n",
    "    #\t\t\t\t#data_dred_mfreq[i][key] = vis_data_dred_mfreq[i][:, :, key_index].transpose() #[pol][freq,time,ubl_index].transpose()\n",
    "    #\t\t\tmodel[i][dflags_dred[i].keys()[0][0], dflags_dred[i].keys()[0][0], dflags_dred[i].keys()[0][2]] = autocorr_vis_mfreq[i] # not lose generality, choose the first anntena in the first UBL for autocorrelation calibraiton.\n",
    "    #\t\t\tcdata[i][dflags[i].keys()[0][0], dflags[i].keys()[0][0], dflags[i].keys()[0][2]] = autocorr_data_mfreq[i] # add the autocorrelation of first antenna in the first UBL as the last line in visibility.\n",
    "    #\t\t\tcdflags[i][keys[0][0], keys[0][0], keys[0][2]] = np.array([[False]*autocorr_data_mfreq[i].shape[1]]*autocorr_data_mfreq[i].shape[0])\n",
    "    #\t\t\tprint(dflags[i].keys())\n",
    "    #\t\t\tprint(dflags[i].keys()[0][0])\n",
    "    #\t\t\t\n",
    "\n",
    "        if Absolute_Calibration_dred_mfreq:\n",
    "            keys = dflags_dred_mfreq[i].keys()\n",
    "            for key_index, key in enumerate(keys):\n",
    "                model_dred_mfreq[i][key] = fullsim_vis_mfreq[key_index, i]\n",
    "                #data_dred_mfreq[i][key] = np.real(vis_data_dred_mfreq[i][:, :, key_index].transpose()) + np.abs(np.imag(vis_data_dred_mfreq[i][:, :, key_index].transpose()))*1j #[pol][freq,time,ubl_index].transpose()\n",
    "                data_dred_mfreq[i][key] = vis_data_dred_mfreq[i][:, :, key_index].transpose() #[pol][freq,time,ubl_index].transpose()\n",
    "            if add_Autobsl:\n",
    "                model_dred_mfreq[i][keys[0][0], keys[0][0], keys[0][2]] = autocorr_vis_mfreq[i] # not lose generality, choose the first anntena in the first UBL for autocorrelation calibraiton.\n",
    "                data_dred_mfreq[i][keys[0][0], keys[0][0], keys[0][2]] = autocorr_data_mfreq[i] # add the autocorrelation of first antenna in the first UBL as the last line in visibility.\n",
    "                cdflags_dred_mfreq[i][keys[0][0], keys[0][0], keys[0][2]] = np.array([[False]*autocorr_data_mfreq[i].shape[1]]*autocorr_data_mfreq[i].shape[0])\n",
    "                auto_select_dred_mfreq[i] = (keys[0][0], keys[0][0], keys[0][2])\n",
    "            print(dflags_dred_mfreq[i].keys())\n",
    "            print(dflags_dred_mfreq[i].keys()[0][0])\n",
    "\n",
    "\n",
    "    ###### make wgts #######\t\n",
    "    for i in range(2):\n",
    "        if i == 0:\n",
    "            wgts_sf = copy.deepcopy(cdflags_sf)\n",
    "        for k in wgts_sf[i].keys():\n",
    "            wgts_sf[i][k] = (~wgts_sf[i][k]).astype(np.float)\n",
    "\n",
    "        if i == 0:\n",
    "            wgts_dred = copy.deepcopy(cdflags_dred)\n",
    "        for k in wgts_dred[i].keys():\n",
    "            wgts_dred[i][k] = (~wgts_dred[i][k]).astype(np.float)\n",
    "\n",
    "    #\t\tif i == 0:\n",
    "    #\t\t\twgts = copy.deepcopy(cdflags)\n",
    "    #\t\tfor k in wgts[i].keys():\n",
    "    #\t\t\twgts[i][k] = (~wgts[i][k]).astype(np.float)\n",
    "\n",
    "        if i == 0:\n",
    "            wgts_dred_mfreq = copy.deepcopy(cdflags_dred_mfreq)\n",
    "        for k in wgts_dred_mfreq[i].keys():\n",
    "            wgts_dred_mfreq[i][k] = (~wgts_dred_mfreq[i][k]).astype(np.float)\n",
    "\n",
    "\n",
    "    re_cal_times = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "\tpol = ['xx', 'yy'][i]\n",
    "\tre_cal = 0\n",
    "\t\n",
    "\tif Absolute_Calibration_dred_mfreq:\n",
    "\t\tfor re_cal in range(re_cal_times): # number of times of absolute calibration\n",
    "\t\t\tif re_cal == 0:\n",
    "\t\t\t\tmodel_dred_mfreq[i], interp_flags_dred_mfreq[i] = hc.abscal.interp2d_vis(model_dred_mfreq[i], lsts, flist[i], lsts, flist[i])\n",
    "\t\t\t\t# instantiate class\n",
    "\t\t\t\tAC_dred_mfreq[i] = hc.abscal.AbsCal(model_dred_mfreq[i], data_dred_mfreq[i], antpos=antpos[i], wgts=wgts_dred_mfreq[i], freqs=flist[i])\n",
    "\t\t\t\t# kernel is median filter kernel, chosen to produce time-smooth output delays for this particular dataset\n",
    "\t\t\t\tAC_dred_mfreq[i].delay_lincal(kernel=(1, 11), medfilt=True, time_avg=True, solve_offsets=True)\n",
    "\t\t\telse:\n",
    "\t\t\t\t#model_dred_mfreq[i], interp_flags_dred_mfreq[i] = hc.abscal.interp2d_vis(model_dred_mfreq[i], lsts, flist[i], lsts, flist[i])\n",
    "\t\t\t\t# instantiate class\n",
    "\t\t\t\tAC_dred_mfreq[i] = hc.abscal.AbsCal(model_dred_mfreq[i], abs_corr_data_dred_mfreq[i], antpos=antpos[i], wgts=wgts_dred_mfreq[i], freqs=flist[i])\n",
    "\t\t\t\t# kernel is median filter kernel, chosen to produce time-smooth output delays for this particular dataset\n",
    "\t\t\t\tAC_dred_mfreq[i].delay_lincal(kernel=(1, 3), medfilt=True, time_avg=True, solve_offsets=True)\n",
    "\t\t\t# apply to data\n",
    "\t\t\tdelay_corr_data_dred_mfreq[i] = hc.abscal.apply_gains(AC_dred_mfreq[i].data, (AC_dred_mfreq[i].ant_dly_gain))\n",
    "\t\t\t# instantiate class\n",
    "\t\t\tDAC_dred_mfreq[i] = hc.abscal.AbsCal(model_dred_mfreq[i], delay_corr_data_dred_mfreq[i], antpos=antpos[i], wgts=wgts_dred_mfreq[i], freqs=flist[i])\n",
    "\t\t\t# avg phase solver\n",
    "\t\t\tDAC_dred_mfreq[i].phs_logcal(avg=True)\n",
    "\t\t\t# apply to data\n",
    "\t\t\tdly_phs_corr_data_dred_mfreq[i] = hc.abscal.apply_gains(DAC_dred_mfreq[i].data, (DAC_dred_mfreq[i].ant_phi_gain))\n",
    "\t\t\t# instantiate class\n",
    "\t\t\tDPAC_dred_mfreq[i] = hc.abscal.AbsCal(model_dred_mfreq[i], dly_phs_corr_data_dred_mfreq[i], antpos=antpos[i], wgts=wgts_dred_mfreq[i], freqs=flist[i])\n",
    "\t\t\t# run amp linsolve\n",
    "\t\t\tDPAC_dred_mfreq[i].abs_amp_logcal()\n",
    "\t\t\t# run phs linsolve\n",
    "\t\t\tDPAC_dred_mfreq[i].TT_phs_logcal(zero_psi=False, four_pol=False)\n",
    "\t\t\t# apply to data\n",
    "\t\t\tabs_corr_data_dred_mfreq[i] = hc.abscal.apply_gains(DPAC_dred_mfreq[i].data, \n",
    "\t\t\t\t\t\t\t\t\t(DPAC_dred_mfreq[i].abs_psi_gain, DPAC_dred_mfreq[i].TT_Phi_gain, DPAC_dred_mfreq[i].abs_eta_gain), gain_convention='multiply')\n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\tvis_data_dred_mfreq_abscal[i] = np.zeros_like(vis_data_dred_mfreq[i], dtype='complex128')\n",
    "\t\tfor key_id, key in enumerate(dflags_dred_mfreq[i].keys()):\n",
    "\t\t\tvis_data_dred_mfreq_abscal[i][:, :, key_id] = abs_corr_data_dred_mfreq[i][key].transpose()\n",
    "\t\t\t#vis_data_dred_mfreq_abscal[i][:, :, key_id] = np.real(abs_corr_data_dred_mfreq[i][key].transpose()) + np.abs(np.imag(abs_corr_data_dred_mfreq[i][key].transpose()))*1j\n",
    "\t\tif add_Autobsl:\n",
    "\t\t\tautocorr_data_dred_mfreq_abscal[i] = abs_corr_data_dred_mfreq[i][auto_select_dred_mfreq[i]]\n",
    "\t\telse:\n",
    "\t\t\tautocorr_data_dred_mfreq_abscal[i] = autocorr_vis_mfreq[i]\n",
    "\t\t\t\n",
    "\t\tvis_data_dred_abscal[i] = vis_data_dred_mfreq_abscal[i][index_freq[i], :, :]\n",
    "\t\tif add_Autobsl: \n",
    "\t\t\tautocorr_data_dred_abscal[i] = autocorr_data_dred_mfreq_abscal[i][:, index_freq[i]]\n",
    "\t\telse:\n",
    "\t\t\tautocorr_data_dred_abscal[i] = autocorr_vis_mfreq[i][:, index_freq[i]]\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "\tpol = ['xx', 'yy'][i]\n",
    "\t\n",
    "\tif Absolute_Calibration_dred_mfreq:\t\t\t\t\t\t\t\t\n",
    "\t\tplt.figure(80000000+10*i)\n",
    "\t\tfig3[i], axes3[i] = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\t\tplt.sca(axes3[i][0])\n",
    "\t\tuvt.plot.waterfall(AC_dred_mfreq[i].model[bl_dred_mfreq[i]], mode='log', mx=6, drng=4)\n",
    "\t\tplt.colorbar()\n",
    "\t\tplt.title(pol + ' model AMP {}'.format(bl_dred_mfreq[i]))\n",
    "\t\tplt.sca(axes3[i][1])\n",
    "\t\tuvt.plot.waterfall(AC_dred_mfreq[i].model[bl_dred_mfreq[i]], mode='phs', mx=np.pi, drng=2*np.pi)\n",
    "\t\tplt.colorbar()\n",
    "\t\tplt.title(pol + ' model PHS {}'.format(bl_dred_mfreq[i]))\n",
    "\t\tplt.show(block=False)\t\t\t\n",
    "\t\t#plt.cla()\n",
    "\t\t\t\n",
    "\t\tplt.figure(90000000+10*i)\n",
    "\t\tfig3_data[i], axes3_data[i] = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\t\tplt.sca(axes3_data[i][0])\n",
    "\t\tuvt.plot.waterfall(data_dred_mfreq[i][bl_dred_mfreq[i]], mode='log', mx=1, drng=2)\n",
    "\t\tplt.colorbar()\n",
    "\t\tplt.title(pol + ' data AMP {}'.format(bl_dred_mfreq[i]))\n",
    "\t\tplt.sca(axes3_data[i][1])\n",
    "\t\tuvt.plot.waterfall(data_dred_mfreq[i][bl_dred_mfreq[i]], mode='phs', mx=np.pi, drng=2*np.pi)\n",
    "\t\tplt.colorbar()\n",
    "\t\tplt.title(pol + ' data PHS {}'.format(bl_dred_mfreq[i]))\n",
    "\t\tplt.show(block=False)\n",
    "\t\t#plt.cla()\t\t\n",
    "\t\t\t\n",
    "\t\t####################### after ABS Calibration #########################\t\n",
    "\t\tplt.figure(8000000+10*i)\n",
    "\t\tfig3_data_abscorr[i], axes3_data_abscorr[i] = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\t\tplt.sca(axes3_data_abscorr[i][0])\n",
    "\t\tuvt.plot.waterfall(abs_corr_data_dred_mfreq[i][bl_dred_mfreq[i]], mode='log', mx=6, drng=4)\n",
    "\t\tplt.colorbar()\n",
    "\t\tplt.title(pol + ' abs_caled data AMP {}'.format(bl_dred_mfreq[i]))\n",
    "\t\tplt.sca(axes3_data_abscorr[i][1])\n",
    "\t\tuvt.plot.waterfall(abs_corr_data_dred_mfreq[i][bl_dred_mfreq[i]], mode='phs', mx=np.pi, drng=2*np.pi)\n",
    "\t\tplt.colorbar()\n",
    "\t\tplt.title(pol + ' abs_caled data PHS {}'.format(bl_dred_mfreq[i]))\n",
    "\t\tplt.show(block=False)\n",
    "\t\t#plt.cla()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\t\n",
    "\tif Absolute_Calibration_dred:\n",
    "\t\t# instantiate class\n",
    "\t\t#AC_dred[i] = hc.abscal.AbsCal(model_dred[i], data_dred[i], antpos=antpos[i], wgts=wgts_dred[i], freqs=freq_to_cal)\n",
    "\t\t# kernel is median filter kernel, chosen to produce time-smooth output delays for this particular dataset\n",
    "\t\tAC_dred[i].delay_lincal(kernel=(1, 3), medfilt=True, time_avg=True, solve_offsets=True)\n",
    "\t\t# apply to data\n",
    "\t\tdelay_corr_data_dred[i] = hc.abscal.apply_gains(AC_dred[i].data, (AC_dred[i].ant_dly_gain))\n",
    "\t\t# instantiate class\n",
    "\t\tDAC_dred[i] = hc.abscal.AbsCal(model_dred[i], data_dred[i], antpos=antpos[i], wgts=wgts_dred[i], freqs=freq_to_cal)\n",
    "\t\t# avg phase solver\n",
    "\t\tDAC_dred[i].phs_logcal(avg=True)\n",
    "\t\t# apply to data\n",
    "\t\tdly_phs_corr_data_dred[i] = hc.abscal.apply_gains(DAC_dred[i].data, (DAC_dred[i].ant_phi_gain))\n",
    "\t\t# instantiate class\n",
    "\t\tDPAC_dred[i] = hc.abscal.AbsCal(model_dred[i], dly_phs_corr_data_dred[i], antpos=antpos[i], wgts=wgts_dred[i], freqs=freq_to_cal)\n",
    "\t\t# run amp linsolve\n",
    "\t\tDPAC_dred[i].abs_amp_logcal()\n",
    "\t\t# run phs linsolve\n",
    "\t\tDPAC_dred[i].TT_phs_logcal(zero_psi=False, four_pol=False)\n",
    "\t\t# apply to data\n",
    "\t\tabs_corr_data_dred[i] = hc.abscal.apply_gains(DPAC_dred[i].data, \n",
    "\t\t\t\t\t\t\t\t(DPAC_dred[i].abs_psi_gain, DPAC_dred[i].TT_Phi_gain, DPAC_dred[i].abs_eta_gain), gain_convention='multiply')\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tplt.figure(60000000+10*i)\n",
    "\t\tfig2[i], axes2[i] = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\t\tif len(freq_to_cal) >= 2:\n",
    "\t\t\tplt.sca(axes2[i][0])\n",
    "\t\t\tuvt.plot.waterfall(AC_dred[i].model[bl_dred], mode='log', mx=4, drng=2)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' model AMP {}'.format(bl_dred))\n",
    "\t\t\tplt.sca(axes2[i][1])\n",
    "\t\t\tuvt.plot.waterfall(AC_dred[i].model[bl_dred], mode='phs', mx=np.pi, drng=2*np.pi)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' model PHS {}'.format(bl_dred))\n",
    "\t\t\tplt.show(block=False)\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tplt.sca(axes2[i][0])\n",
    "\t\t\tplt.plot(np.real(AC_dred[i].model[bl_dred]))\n",
    "\t\t\tplt.title(pol + ' model Real {}'.format(bl_dred))\n",
    "\t\t\tplt.sca(axes2[i][1])\n",
    "\t\t\tplt.plot(np.imag(AC_dred[i].model[bl_dred]))\n",
    "\t\t\tplt.title(pol + ' model Imag {}'.format(bl_dred))\n",
    "\t\t\tplt.show(block=False)\n",
    "\t\t#plt.cla()\n",
    "\t\t\t\n",
    "\t\tplt.figure(70000000+10*i)\n",
    "\t\tfig2_data[i], axes2_data[i] = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\t\tif len(freq_to_cal) >= 2:\n",
    "\t\t\tplt.sca(axes2_data[i][0])\n",
    "\t\t\tuvt.plot.waterfall(AC_dred[i].data[bl_dred], mode='log', mx=4, drng=2)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' data AMP {}'.format(bl_dred))\n",
    "\t\t\tplt.sca(axes2_data[i][1])\n",
    "\t\t\tuvt.plot.waterfall(AC_dred[i].data[bl_dred], mode='phs', mx=np.pi, drng=2*np.pi)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' data PHS {}'.format(bl_dred))\n",
    "\t\t\tplt.show(block=False)\n",
    "\t\telse:\n",
    "\t\t\tplt.sca(axes2_data[i][0])\n",
    "\t\t\tplt.plot(np.real(AC_dred[i].data[bl_dred]))\n",
    "\t\t\tplt.title(pol + ' data Real {}'.format(bl_dred))\n",
    "\t\t\tplt.sca(axes2_data[i][1])\n",
    "\t\t\tplt.plot(np.imag(AC_dred[i].data[bl_dred]))\n",
    "\t\t\tplt.title(pol + ' data Imag {}'.format(bl_dred))\n",
    "\t\t\tplt.show(block=False)\n",
    "\t\t#plt.cla()\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t####################### after ABS Calibration #########################\t\n",
    "\t\tplt.figure(7000000+10*i)\n",
    "\t\tfig2_data[i], axes2_data[i] = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\t\tif len(freq_to_cal) >= 2:\n",
    "\t\t\tplt.sca(axes2_data[i][0])\n",
    "\t\t\tuvt.plot.waterfall(abs_corr_data_dred[i][bl_dred], mode='log', mx=4, drng=2)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' data AMP {}'.format(bl_dred))\n",
    "\t\t\tplt.sca(axes2_data[i][1])\n",
    "\t\t\tuvt.plot.waterfall(abs_corr_data_dred[i][bl_dred], mode='phs', mx=np.pi, drng=2*np.pi)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' data PHS {}'.format(bl_dred))\n",
    "\t\t\tplt.show(block=False)\n",
    "\t\telse:\n",
    "\t\t\tplt.sca(axes2_data[i][0])\n",
    "\t\t\tplt.plot(np.real(abs_corr_data_dred[i][bl_dred]))\n",
    "\t\t\tplt.title(pol + ' data Real {}'.format(bl_dred))\n",
    "\t\t\tplt.sca(axes2_data[i][1])\n",
    "\t\t\tplt.plot(np.imag(abs_corr_data_dred[i][bl_dred]))\n",
    "\t\t\tplt.title(pol + ' data Imag {}'.format(bl_dred))\n",
    "\t\t\tplt.show(block=False)\n",
    "\t\t#plt.cla()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4 != 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################# Noise and Vis Data Loading ##################\n",
    "if len(tlist) >= 2 and INSTRUMENT == 'hera47' and Time_Expansion_Factor != 1.:\n",
    "\tTime_seperation_real = np.array([3600. * np.abs(tlist[i + 1] - tlist[i]) for i in range(len(tlist) - 1)])  # in second\n",
    "elif INSTRUMENT == 'hera47':\n",
    "\tTime_seperation_real = 11 # second\n",
    "elif INSTRUMENT == 'miteor':\n",
    "\tTime_seperation_real = 2.7 # second\n",
    "\t\n",
    "if len(flist) >=2 and INSTRUMENT == 'hera47' and Time_Expansion_Factor != 1.:\n",
    "\tFrequency_gap_real = np.array([1.e6*np.abs(flist[0][i+1]-flist[0][i]) for i in range(len(flist[0])-1)]) # Hz\n",
    "elif INSTRUMENT == 'hera47':\n",
    "\tFrequency_gap_real = 1.625 * 1.e6 #Hz\n",
    "elif INSTRUMENT == 'miteor':\n",
    "\tFrequency_gap_real = 0.5 * 1.e6 #Hz\n",
    "\n",
    "\n",
    "Integration_Time = np.mean(Time_seperation_real)\n",
    "Frequency_Bin = np.mean(Frequency_gap_real)\n",
    "\n",
    "Calculate_SimulationData_Noise = True\n",
    "Calculate_Data_Noise = True\n",
    "\n",
    "scale_noise = True\n",
    "#Use_AbsCal = False\n",
    "\n",
    "noise = {}\n",
    "noise_data = {}\n",
    "if Calculate_SimulationData_Noise:\n",
    "\tif Keep_Red:\t\n",
    "\t\tnoise['x'] = np.array([np.random.normal(0, autocorr_vis_red[0][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL_used) for t_index in range(len(autocorr_vis[0]))],dtype='complex128').flatten()\n",
    "\t\tnoise['y'] = np.array([np.random.normal(0, autocorr_vis_red[1][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL_used) for t_index in range(len(autocorr_vis[1]))],dtype='complex128').flatten()\n",
    "\telse:\n",
    "\t\tnoise['x'] = np.array([(np.random.normal(0, autocorr_vis[0][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL_used) / np.array(redundancy[0])**0.5) for t_index in range(len(autocorr_vis[0]))],dtype='complex128').flatten()\n",
    "\t\tnoise['y'] = np.array([(np.random.normal(0, autocorr_vis[1][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL_used) / np.array(redundancy[1])**0.5) for t_index in range(len(autocorr_vis[1]))],dtype='complex128').flatten()\n",
    "\t\n",
    "#\tN_acu = {}\n",
    "#\tN_acu['x'] = np.outer(noise['x'], noise['x'].T)\n",
    "#\tN_acu['y'] = np.outer(noise['y'], noise['y'].T)\n",
    "\tN = {}\n",
    "\tN['x'] = noise['x'] * noise['x']\n",
    "\tN['y'] = noise['y'] * noise['y']\n",
    "\t\n",
    "\tsim_var_xx_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_var_sim_xx.simvis'%(INSTRUMENT, freq, nUBL_used+1, nt_used, nside_standard, bnside)\n",
    "\tsim_var_yy_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_var_sim_yy.simvis'%(INSTRUMENT, freq, nUBL_used+1, nt_used, nside_standard, bnside)\n",
    "\tN['x'].astype('complex128').tofile(sim_var_xx_filename)\n",
    "\tN['y'].astype('complex128').tofile(sim_var_yy_filename)\n",
    "\t\n",
    "\tDel = True\n",
    "\tif Del:\n",
    "\t\tdel(noise)\n",
    "\t\tdel(N)\n",
    "\n",
    "if Calculate_Data_Noise:\n",
    "\tif INSTRUMENT == 'miteor':\n",
    "\t\tnoise_data['x'] = (var_data[0].flatten())**0.5\n",
    "\t\tnoise_data['y'] = (var_data[1].flatten())**0.5\n",
    "\t\t\n",
    "\telif INSTRUMENT == 'hera47':\n",
    "\t\tif Keep_Red:\n",
    "\t\t\tnoise_data['x'] = np.array([np.random.normal(0,autocorr_data[0][t_index]/(Integration_Time*Frequency_Bin)**0.5,nUBL_used) for t_index in range(len(autocorr_data[0]))],dtype='complex128').flatten() # Not Absolute Calibrated\n",
    "\t\t\tnoise_data['y'] = np.array([np.random.normal(0,autocorr_data[1][t_index]/(Integration_Time*Frequency_Bin)**0.5,nUBL_used) for t_index in range(len(autocorr_data[1]))],dtype='complex128').flatten()\n",
    "\t\telse:\n",
    "\t\t\tif scale_noise:\n",
    "\t\t\t\tif Use_AbsCal:\n",
    "\t\t\t\t\tnoise_data['x'] = np.array([(np.random.normal(0, autocorr_data_dred_abscal[0][t_index]/(Integration_Time*Frequency_Bin) **0.5, nUBL_used) / np.array(redundancy[0])**0.5) for t_index in range(len(autocorr_data_dred_abscal[0]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "\t\t\t\t\tnoise_data['y'] = np.array([(np.random.normal(0, autocorr_data_dred_abscal[1][t_index]/(Integration_Time*Frequency_Bin) **0.5, nUBL_used) / np.array(redundancy[1])**0.5) for t_index in range(len(autocorr_data_dred_abscal[1]))],dtype='complex128').flatten()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnoise_data['x'] = np.array([(np.random.normal(0, autocorr_data[0][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL_used) / np.array(redundancy[0])**0.5) for t_index in range(len(autocorr_data[0]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "\t\t\t\t\tnoise_data['y'] = np.array([(np.random.normal(0, autocorr_data[1][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL_used) / np.array(redundancy[1])**0.5) for t_index in range(len(autocorr_data[1]))],dtype='complex128').flatten()\n",
    "\t\t\telse:\n",
    "\t\t\t\tif Use_AbsCal:\n",
    "\t\t\t\t\tnoise_data['x'] = np.array([(np.random.normal(0, autocorr_data_dred_abscal[0][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL_used) ) for t_index in range(len(autocorr_data_dred_abscal[0]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "\t\t\t\t\tnoise_data['y'] = np.array([(np.random.normal(0, autocorr_data_dred_abscal[1][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL_used) ) for t_index in range(len(autocorr_data_dred_abscal[1]))],dtype='complex128').flatten()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnoise_data['x'] = np.array([(np.random.normal(0, autocorr_data[0][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL_used) ) for t_index in range(len(autocorr_data[0]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "\t\t\t\t\tnoise_data['y'] = np.array([(np.random.normal(0, autocorr_data[1][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL_used) ) for t_index in range(len(autocorr_data[1]))],dtype='complex128').flatten()\n",
    "\t\t\t\t\t\t\n",
    "#\tN_data_acu = {}\n",
    "#\tN_data_acu['x'] = np.outer(noise_data['x'], noise_data['x'].T)\n",
    "#\tN_data_acu['y'] = np.outer(noise_data['y'], noise_data['y'].T)\n",
    "\tN_data = {}\n",
    "\tN_data['x'] = noise_data['x'] * noise_data['x']\n",
    "\tN_data['y'] = noise_data['y'] * noise_data['y']\n",
    "\t\n",
    "\tStore_Data_Noise = True\n",
    "\n",
    "\tif Store_Data_Noise:\n",
    "\t\tdata_var_xx_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_var_data_xx.simvis'%(INSTRUMENT, freq, nUBL_used+1, nt_used, nside_standard, bnside)\n",
    "\t\tdata_var_yy_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_var_data_yy.simvis'%(INSTRUMENT, freq, nUBL_used+1, nt_used, nside_standard, bnside)\n",
    "\t\tN_data['x'].astype('complex128').tofile(data_var_xx_filename)\n",
    "\t\tN_data['y'].astype('complex128').tofile(data_var_yy_filename)\n",
    "\t\n",
    "\tDel = True\n",
    "\tif Del:\n",
    "\t\tdel(noise_data)\n",
    "\t\t#del(N_data)\n",
    "#\t\ttry:\n",
    "#\t\t\tdel(autocorr_data)\n",
    "#\t\texcept:\n",
    "#\t\t\tpass\n",
    "\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "southern_points = {'hyd':{'ra': '09:18:05.7', 'dec': '-12:05:44'},\n",
    "'cen':{'ra': '13:25:27.6', 'dec': '-43:01:09'},\n",
    "'cyg':{'ra': '19:59:28.3', 'dec': '40:44:02'},\n",
    "'pic':{'ra': '05:19:49.7', 'dec': '-45:46:44'},\n",
    "'vir':{'ra': '12:30:49.4', 'dec': '12:23:28'},\n",
    "'for':{'ra': '03:22:41.7', 'dec': '-37:12:30'},\n",
    "'sag':{'ra': '17:45:40.045', 'dec': '-29:0:27.9'},\n",
    "'cas':{'ra': '23:23:26', 'dec': '58:48:00'},\n",
    "'crab':{'ra': '5:34:31.97', 'dec': '22:00:52.1'}}\n",
    "southern_points.keys()\n",
    "for source in southern_points.keys():\n",
    "\tsouthern_points[source]['body'] = ephem.FixedBody()\n",
    "\tsouthern_points[source]['body']._ra = southern_points[source]['ra']\n",
    "\tsouthern_points[source]['body']._dec = southern_points[source]['dec']\n",
    "\n",
    "full_thetas, full_phis = hpf.pix2ang(nside_standard, range(hpf.nside2npix(nside_standard)), nest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_raw_gsm_ps = {}\n",
    "flux_gsm_ps = {}\n",
    "flux_raw_dis_gsm_ps = {}\n",
    "flux_dis_gsm_ps = {}\n",
    "pix_index_gsm_ps = {}\n",
    "pix_raw_index_gsm_ps = {}\n",
    "pix_max_index_gsm_ps = {}\n",
    "pt_sources = southern_points.keys()\n",
    "for source in pt_sources:\n",
    "    flux_raw_gsm_ps[source] = 0\n",
    "    flux_gsm_ps[source] = 0\n",
    "    flux_raw_dis_gsm_ps[source] = []\n",
    "    flux_dis_gsm_ps[source] = []\n",
    "    pix_raw_index_gsm_ps[source] = []\n",
    "    pix_index_gsm_ps[source] = []\n",
    "    #pix_max_index_gsm_ps[source] = []\n",
    "    for i in range(len(equatorial_GSM_standard)):\n",
    "        if la.norm(np.array([full_phis[i] - southern_points[source]['body']._ra, \n",
    "                               (PI / 2 - full_thetas[i]) - southern_points[source]['body']._dec])) <= 0.1:\n",
    "            flux_raw_gsm_ps[source] += equatorial_GSM_standard[i]\n",
    "            flux_raw_dis_gsm_ps[source].append(equatorial_GSM_standard[i])\n",
    "            pix_raw_index_gsm_ps[source].append(i)\n",
    "            \n",
    "    pix_max_index_gsm_ps[source] = pix_raw_index_gsm_ps[source][flux_raw_dis_gsm_ps[source].index(np.array(flux_raw_dis_gsm_ps[source]).max())]\n",
    "    for j in range(len(flux_raw_dis_gsm_ps[source])):\n",
    "        if flux_raw_dis_gsm_ps[source][j] >= 0.4 * equatorial_GSM_standard[pix_max_index_gsm_ps[source]]:\n",
    "            flux_gsm_ps[source] += equatorial_GSM_standard[pix_raw_index_gsm_ps[source][j]]\n",
    "            flux_dis_gsm_ps[source].append(equatorial_GSM_standard[pix_raw_index_gsm_ps[source][j]])\n",
    "            pix_index_gsm_ps[source].append(pix_raw_index_gsm_ps[source][j])\n",
    "            \n",
    "    print('total flux of %s'%source, flux_gsm_ps[source])\n",
    "    print('total raw flux of %s'%source, flux_raw_gsm_ps[source])\n",
    "    print('maximum pix flux of %s'%source, equatorial_GSM_standard[pix_max_index_gsm_ps[source]])\n",
    "    print('pix-index with maximum flux of %s'%source, pix_max_index_gsm_ps[source])\n",
    "    print('raw-pix-indexes of %s'%source, pix_raw_index_gsm_ps[source])\n",
    "    print('pix-indexes of %s'%source, pix_index_gsm_ps[source])\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "####simulate cas and cyg\n",
    "#######################\n",
    "southern_points = {'hyd':{'ra': '09:18:05.7', 'dec': '-12:05:44'},\n",
    "'cen':{'ra': '13:25:27.6', 'dec': '-43:01:09'},\n",
    "'cyg':{'ra': '19:59:28.3', 'dec': '40:44:02'},\n",
    "'pic':{'ra': '05:19:49.7', 'dec': '-45:46:44'},\n",
    "'vir':{'ra': '12:30:49.4', 'dec': '12:23:28'},\n",
    "'for':{'ra': '03:22:41.7', 'dec': '-37:12:30'},\n",
    "'sag':{'ra': '17:45:40.045', 'dec': '-29:0:27.9'},\n",
    "'cas':{'ra': '23:23:26', 'dec': '58:48:00'},\n",
    "'crab':{'ra': '5:34:31.97', 'dec': '22:00:52.1'}}\n",
    "\n",
    "\n",
    "for source in southern_points.keys():\n",
    "\tsouthern_points[source]['body'] = ephem.FixedBody()\n",
    "\tsouthern_points[source]['body']._ra = southern_points[source]['ra']\n",
    "\tsouthern_points[source]['body']._dec = southern_points[source]['dec']\n",
    "\n",
    "flux_func = {}\n",
    "#flux_func['cas'] = si.interp1d(np.loadtxt('/home/omniscope/data/point_source_flux/casA2013.5out')[:,1], np.loadtxt('/home/omniscope/data/point_source_flux/casA2013.5out')[:,2])\n",
    "#flux_func['cyg'] = si.interp1d(np.loadtxt('/home/omniscope/data/point_source_flux/cygA2006out')[:,1], np.loadtxt('/home/omniscope/data/point_source_flux/cygA2006out')[:,2])\n",
    "flux_func['cas'] = si.interp1d(flist[0], np.array([S_casa_v_t(flist[0][i], DecimalYear) for i in range(len(flist[0]))]))\n",
    "flux_func['cyg'] = si.interp1d(flist[0], np.array([S_cyga_v(flist[0][i], DecimalYear) for i in range(len(flist[0]))]))\n",
    "\n",
    "full_thetas, full_phis = hpf.pix2ang(nside_standard, range(hpf.nside2npix(nside_standard)), nest=True)\n",
    "\n",
    "# pt_sources = ['cyg', 'cas']\n",
    "pt_sources = southern_points.keys()\n",
    "pt_vis = np.zeros((len(pt_sources), 2, nUBL_used, nt_used), dtype='complex128')\n",
    "if INSTRUMENT == 'miteor':\n",
    "\tprint \"Simulating cyg casvisibilities, %s, expected time %.1f min\"%(datetime.datetime.now(), 14.6 * (nUBL_used / 78.) * (nt_used / 193.) * (2. / 1.4e5)),\n",
    "\tsys.stdout.flush()\n",
    "\ttimer = time.time()\n",
    "\tfor p, beam_heal_equ in enumerate([beam_heal_equ_x, beam_heal_equ_y]):\n",
    "\t\tfor i, source in enumerate(pt_sources):\n",
    "\t\t\tra = southern_points[source]['body']._ra\n",
    "\t\t\tdec = southern_points[source]['body']._dec\n",
    "# \t\t\tpt_vis[i, p] = jansky2kelvin * flux_func[source](freq) * vs.calculate_pointsource_visibility(ra, dec, used_common_ubls, freq, beam_heal_equ=beam_heal_equ, tlist=lsts) / 2\n",
    "\t\t\tpt_vis[i, p] = flux_gsm_ps[source] * vs.calculate_pointsource_visibility(ra, dec, used_common_ubls, freq, beam_heal_equ=beam_heal_equ, tlist=lsts) / 2\n",
    "elif INSTRUMENT == 'hera47':\n",
    "\tprint \"Simulating cyg casvisibilities, %s, expected time %.1f min\"%(datetime.datetime.now(), 14.6 * (nUBL_used / 78.) * (nt_used / 193.) * (2. / 1.4e5)),\n",
    "\tsys.stdout.flush()\n",
    "\ttimer = time.time()\n",
    "\tfor p, beam_heal_equ in enumerate([beam_heal_equ_x, beam_heal_equ_y]):\n",
    "\t\tfor i, source in enumerate(pt_sources):\n",
    "\t\t\tra = southern_points[source]['body']._ra\n",
    "\t\t\tdec = southern_points[source]['body']._dec\n",
    "# \t\t\tpt_vis[i, p] = jansky2kelvin * flux_func[source](freq) * vs.calculate_pointsource_visibility(ra, dec, used_common_ubls, freq, beam_heal_equ=beam_heal_equ, tlist=lsts) / 2\n",
    "\t\t\tpt_vis[i, p] = flux_gsm_ps[source] * vs.calculate_pointsource_visibility(ra, dec, used_common_ubls, freq, beam_heal_equ=beam_heal_equ, tlist=lsts) / 2\n",
    "\n",
    "\n",
    "\n",
    "if PointSource_AbsCal:\n",
    "\tvis_freq = {}\n",
    "\t\n",
    "\tautocorr_data_dred_mfreq_pscal = {}\n",
    "\tvis_data_dred_mfreq_pscal = {}\n",
    "\t\n",
    "\tfor j, p in enumerate(['x', 'y']):\n",
    "\t\tpol = p+p\n",
    "\t\tvis_data_dred_mfreq_pscal[j] = np.zeros_like(vis_data_dred_mfreq[j])\n",
    "\t\tautocorr_data_dred_mfreq_pscal[j] = np.zeros_like(autocorr_data_mfreq[j])\n",
    "\t\n",
    "\tfor id_f in range(len(flist[0])):\n",
    "\t\tvis_freq[0] = flist[0][id_f]\n",
    "\t\tvis_freq[1] = flist[1][id_f]\n",
    "\t\t#cal_lst_range = np.array([5, 6]) / TPI * 24.\n",
    "\t\tcal_lst_range = np.array([tlist[nt_used/3], tlist[-nt_used/3]])\n",
    "\t\tcalibrate_ubl_length = 2600 / np.mean([vis_freq[0], vis_freq[1]]) #10.67\n",
    "\t\t#cal_time_mask = tmask\t #(tlist>cal_lst_range[0]) & (tlist<cal_lst_range[1])#a True/False mask on all good data to get good data in cal time range\n",
    "\t\tcal_time_mask = (tlist>=cal_lst_range[0]) & (tlist<=cal_lst_range[1])\n",
    "\t\t#cal_ubl_mask = np.linalg.norm(ubls[p], axis=1) >= calibrate_ubl_length\n",
    "\t\t\n",
    "\t\tprint('%i times used'%len(lsts[cal_time_mask]))       \n",
    "\t\t\n",
    "\t\tflux_raw_gsm_ps = {}\n",
    "\t\tflux_gsm_ps = {}\n",
    "\t\tflux_raw_dis_gsm_ps = {}\n",
    "\t\tflux_dis_gsm_ps = {}\n",
    "\t\tpix_index_gsm_ps = {}\n",
    "\t\tpix_raw_index_gsm_ps = {}\n",
    "\t\tpix_max_index_gsm_ps = {}\n",
    "\t\tpt_sources = southern_points.keys()\n",
    "\t\tfor source in pt_sources:\n",
    "\t\t\tflux_raw_gsm_ps[source] = 0\n",
    "\t\t\tflux_gsm_ps[source] = 0\n",
    "\t\t\tflux_raw_dis_gsm_ps[source] = []\n",
    "\t\t\tflux_dis_gsm_ps[source] = []\n",
    "\t\t\tpix_raw_index_gsm_ps[source] = []\n",
    "\t\t\tpix_index_gsm_ps[source] = []\n",
    "\t\t\t#pix_max_index_gsm_ps[source] = []\n",
    "\t\t\tfor i in range(len(equatorial_GSM_standard_mfreq[id_f])):\n",
    "\t\t\t\tif la.norm(np.array([full_phis[i] - southern_points[source]['body']._ra,\n",
    "\t\t\t\t\t\t\t\t\t   (PI / 2 - full_thetas[i]) - southern_points[source]['body']._dec])) <= 0.1:\n",
    "\t\t\t\t\tflux_raw_gsm_ps[source] += equatorial_GSM_standard_mfreq[id_f, i]\n",
    "\t\t\t\t\tflux_raw_dis_gsm_ps[source].append(equatorial_GSM_standard_mfreq[id_f, i])\n",
    "\t\t\t\t\tpix_raw_index_gsm_ps[source].append(i)\n",
    "\n",
    "\t\t\tpix_max_index_gsm_ps[source] = pix_raw_index_gsm_ps[source][flux_raw_dis_gsm_ps[source].index(np.array(flux_raw_dis_gsm_ps[source]).max())]\n",
    "\t\t\tfor j in range(len(flux_raw_dis_gsm_ps[source])):\n",
    "\t\t\t\tif flux_raw_dis_gsm_ps[source][j] >= 0.5 * equatorial_GSM_standard_mfreq[id_f, pix_max_index_gsm_ps[source]]:\n",
    "\t\t\t\t\tflux_gsm_ps[source] += equatorial_GSM_standard_mfreq[id_f, pix_raw_index_gsm_ps[source][j]]\n",
    "\t\t\t\t\tflux_dis_gsm_ps[source].append(equatorial_GSM_standard_mfreq[id_f, pix_raw_index_gsm_ps[source][j]])\n",
    "\t\t\t\t\tpix_index_gsm_ps[source].append(pix_raw_index_gsm_ps[source][j])\n",
    "\n",
    "\t\t\tprint('total flux of %s'%source, flux_gsm_ps[source])\n",
    "\t\t\tprint('total raw flux of %s'%source, flux_raw_gsm_ps[source])\n",
    "\t\t\tprint('maximum pix flux of %s'%source, equatorial_GSM_standard_mfreq[id_f, pix_max_index_gsm_ps[source]])\n",
    "\t\t\tprint('pix-index with maximum flux of %s'%source, pix_max_index_gsm_ps[source])\n",
    "\t\t\tprint('raw-pix-indexes of %s'%source, pix_raw_index_gsm_ps[source])\n",
    "\t\t\tprint('pix-indexes of %s'%source, pix_index_gsm_ps[source])\n",
    "\t\t\tprint('\\n')\n",
    "        \n",
    "\t\tNi = {}\n",
    "\t\tcubls = copy.deepcopy(ubls)\n",
    "\t\tubl_sort = {}\n",
    "\t\tnoise_data_pscal = {}\n",
    "\t\tN_data_pscal = {}\n",
    "\t\tvis_data_dred_pscal = {}\n",
    "\t\t\n",
    "\t\tFrom_AbsCal = False\n",
    "\t\t\n",
    "\t\tfor i, p in enumerate(['x', 'y']):\n",
    "\t\t\tpol = p+p\n",
    "\t\t\tcal_ubl_mask = np.linalg.norm(ubls[p], axis=1) >= calibrate_ubl_length\n",
    "\t\t\t#get Ni (1/variance) and data\n",
    "\t\t\t#var_filename = datadir + tag + '_%s%s_%i_%i%s.var'%(p, p, nt, nUBL, vartag)\n",
    "\t\t\t#noise_data_pscal['y'] = np.array([(np.random.normal(0,autocorr_data[1][t_index]/(Integration_Time*Frequency_Bin)**0.5,nUBL_used) ) for t_index in range(len(autocorr_data[1]))],dtype='complex128').flatten()\n",
    "\t\t\t\n",
    "\t\t\tif From_AbsCal:\n",
    "\t\t\t\tvis_data_dred_pscal[i] = vis_data_dred_mfreq_abscal[i][id_f][np.ix_(cal_time_mask, cal_ubl_mask)].transpose()\n",
    "\t\t\t\tnoise_data_pscal[p] = np.array([(np.random.normal(0,autocorr_data_dred_mfreq_abscal[i][t_index, id_f]/(Integration_Time*Frequency_Bin)**0.5, nUBL) / np.array(redundancy[0])**0.5 ) for t_index in range(len(autocorr_data[i]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "\t\t\telse:\n",
    "\t\t\t\tvis_data_dred_pscal[i] = vis_data_dred_mfreq[i][id_f][np.ix_(cal_time_mask, cal_ubl_mask)].transpose()\n",
    "\t\t\t\tnoise_data_pscal[p] = np.array([(np.random.normal(0,autocorr_data_mfreq[i][t_index, id_f]/(Integration_Time*Frequency_Bin)**0.5, nUBL) / np.array(redundancy[0])**0.5 ) for t_index in range(len(autocorr_data[i]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "\t\t\t\t\n",
    "\t\t\tN_data_pscal[p] = noise_data_pscal[p] * noise_data_pscal[p]\n",
    "\t\t\t#N_data_pscal[p] = N_data[p]\n",
    "\t\t\t#N_data_pscal['y'] = noise_data_pscal['y'] * noise_data_pscal['y']\n",
    "\t\t\tNi[p] = 1./N_data_pscal[p].reshape((nt, nUBL))[np.ix_(cal_time_mask, cal_ubl_mask)].transpose()\n",
    "\t\t\tubls[p] = ubls[p][cal_ubl_mask]\n",
    "\t\t\tubl_sort[p] = np.argsort(la.norm(ubls[p], axis=1))\n",
    "\n",
    "\t\t\tprint \"%i UBLs to include\"%len(ubls[p])\n",
    "\t\t\n",
    "\t\tdel(noise_data_pscal)\n",
    "\t\t\n",
    "\t\tprint \"Computing UNpolarized point sources matrix...\"\n",
    "\t\tsys.stdout.flush()\n",
    "\t\t#cal_sources = ['cyg', 'cas']\n",
    "\t\tcal_sources = southern_points.keys()      \n",
    "\t\tApol = np.empty((np.sum(cal_ubl_mask), 2, np.sum(cal_time_mask), len(cal_sources)), dtype='complex128')\n",
    "\t\ttimer = time.time()\n",
    "\t\tfor n, source in enumerate(cal_sources):\n",
    "\t\t\tra = southern_points[source]['body']._ra\n",
    "\t\t\tdec = southern_points[source]['body']._dec\n",
    "\n",
    "\t\t\tApol[:, 0, :, n] = vs.calculate_pointsource_visibility(ra, dec, ubls[p], vis_freq[0], beam_heal_equ=beam_heal_equ_x_mfreq[id_f], tlist=lsts[cal_time_mask])\n",
    "\t\t\tApol[:, 1, :, n] = vs.calculate_pointsource_visibility(ra, dec, ubls[p], vis_freq[1], beam_heal_equ=beam_heal_equ_y_mfreq[id_f], tlist=lsts[cal_time_mask])\n",
    "\n",
    "\t\tApol = np.conjugate(Apol).reshape((np.sum(cal_ubl_mask), 2 * np.sum(cal_time_mask), len(cal_sources)))\n",
    "\t\tNi = np.transpose([Ni['x'], Ni['y']], (1, 0, 2))\n",
    "\n",
    "\t\trealA = np.zeros((2 * Apol.shape[0] * Apol.shape[1], 1 + 2 * np.sum(cal_ubl_mask) * 2), dtype='complex128')\n",
    "# \t\trealA[:, 0] = np.concatenate((np.real(Apol.reshape((Apol.shape[0] * Apol.shape[1], Apol.shape[2]))), np.imag(Apol.reshape((Apol.shape[0] * Apol.shape[1], Apol.shape[2])))), axis=0).dot([jansky2kelvin_mfreq[0][id_f] * flux_func[source](vis_freq[0]) for source in cal_sources])\n",
    "\t\trealA[:, 0] = np.concatenate((np.real(Apol.reshape((Apol.shape[0] * Apol.shape[1], Apol.shape[2]))), np.imag(Apol.reshape((Apol.shape[0] * Apol.shape[1], Apol.shape[2])))), axis=0).dot([flux_gsm_ps[source] for source in cal_sources])\n",
    "\t\tvis_scale = la.norm(realA[:, 0]) / len(realA)**.5\n",
    "\t\tfor coli, ncol in enumerate(range(1, realA.shape[1])):\n",
    "\t\t\trealA[coli * np.sum(cal_time_mask): (coli + 1) * np.sum(cal_time_mask), ncol] = vis_scale\n",
    "\n",
    "\t\trealNi = np.concatenate((Ni.flatten() * 2, Ni.flatten() * 2))\n",
    "\t\trealAtNiAinv = np.linalg.pinv(np.einsum('ji,j,jk->ik', realA, realNi, realA))\n",
    "\n",
    "\n",
    "\t\tb = np.transpose([vis_data_dred_pscal[0], vis_data_dred_pscal[1]], (1, 0, 2))\n",
    "\t\tphase_degen_niter = 0\n",
    "\t\tphase_degen2 = {'x': np.zeros(2), 'y': np.zeros(2)}\n",
    "\t\tphase_degen_iterative_x = np.zeros(2)\n",
    "\t\tphase_degen_iterative_y = np.zeros(2)\n",
    "\t\tdef tocomplex(realdata):\n",
    "\t\t\treshapedata = realdata.reshape((2, np.sum(cal_ubl_mask), 2, np.sum(cal_time_mask)))\n",
    "\t\t\treturn reshapedata[0] + reshapedata[1] * 1.j\n",
    "\n",
    "\t\tphase_degen_niter_max = 100\n",
    "\t\twhile (phase_degen_niter < phase_degen_niter_max and max(np.linalg.norm(phase_degen_iterative_x), np.linalg.norm(phase_degen_iterative_y)) > 1e-5) or phase_degen_niter == 0:\n",
    "\t\t\tphase_degen_niter += 1\n",
    "\t\t\tb[:, 0] = b[:, 0] * np.exp(1.j * ubls['x'][:, :2].dot(phase_degen_iterative_x))[:, None]\n",
    "\t\t\tb[:, -1] = b[:, -1] * np.exp(1.j * ubls['y'][:, :2].dot(phase_degen_iterative_y))[:, None]\n",
    "\t\t\trealb = np.concatenate((np.real(b.flatten()), np.imag(b.flatten())))\n",
    "\n",
    "\t\t\tpsol = realAtNiAinv.dot(np.transpose(realA).dot(realNi * realb))\n",
    "\t\t\trealb_fit = realA.dot(psol)\n",
    "\t\t\tperror = ((realb_fit - realb) * (realNi**.5)).reshape((2, np.sum(cal_ubl_mask), 2, np.sum(cal_time_mask)))\n",
    "\n",
    "\t\t\trealbfit_noadditive = realA[:, 0] * psol[0]\n",
    "\t\t\trealbfit_additive = realb_fit - realbfit_noadditive\n",
    "\t\t\trealb_noadditive = realb - realbfit_additive\n",
    "\t\t\tbfit_noadditive = tocomplex(realbfit_noadditive)\n",
    "\t\t\tb_noadditive = tocomplex(realb_noadditive)\n",
    "\t\t\tif phase_degen_niter == phase_degen_niter_max:\n",
    "\t\t\t\tphase_degen_iterative_x = solve_phase_degen(np.transpose(b_noadditive[:, 0]), np.transpose(b_noadditive[:, 0]), np.transpose(bfit_noadditive[:, 0]), np.transpose(bfit_noadditive[:, 0]), ubls['x'])#, [3, 3, 1e3])\n",
    "\t\t\t\tphase_degen_iterative_y = solve_phase_degen(np.transpose(b_noadditive[:, -1]), np.transpose(b_noadditive[:, -1]), np.transpose(bfit_noadditive[:, -1]), np.transpose(bfit_noadditive[:, -1]), ubls['y'])#, [3, 3, 1e3])\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tphase_degen_iterative_x = solve_phase_degen(np.transpose(b_noadditive[:, 0]), np.transpose(b_noadditive[:, 0]), np.transpose(bfit_noadditive[:, 0]), np.transpose(bfit_noadditive[:, 0]), ubls['x'])\n",
    "\t\t\t\tphase_degen_iterative_y = solve_phase_degen(np.transpose(b_noadditive[:, -1]), np.transpose(b_noadditive[:, -1]), np.transpose(bfit_noadditive[:, -1]), np.transpose(bfit_noadditive[:, -1]), ubls['y'])\n",
    "\t\t\tphase_degen2['x'] += phase_degen_iterative_x\n",
    "\t\t\tphase_degen2['y'] += phase_degen_iterative_y\n",
    "\t\t\tprint phase_degen_niter, phase_degen2['x'], phase_degen2['y'], np.linalg.norm(perror)\n",
    "\n",
    "\t\trenorm = 1 / (2 * psol[0])\n",
    "\n",
    "\t\tprint (renorm, vis_freq[0],  phase_degen2['x'], vis_freq[1], phase_degen2['y'])\n",
    "\n",
    "\t\t#freqs[fi] = vis_freq\n",
    "\n",
    "\t\t################################# apply to data and var and output unpolarized version ####################################\n",
    "\t\tdata_var_xx_filename_pscal = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_var_data_xx_pscal.simvis'%(INSTRUMENT, freq, nUBL, nt, nside_standard, bnside)\n",
    "\t\tdata_var_yy_filename_pscal = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_var_data_yy_pscal.simvis'%(INSTRUMENT, freq, nUBL, nt, nside_standard, bnside)\n",
    "\t\t\n",
    "\t\t#vis_data_dred_pscal = {}\n",
    "\t\t#N_data_pscal = {}\n",
    "\t\t\n",
    "\t\t######### recover ubls and ubl_sort ##########\n",
    "\t\tubls = cubls\n",
    "\t\t#ubl_sort = cubl_sort\n",
    "\t\t\n",
    "\t\tif Keep_Red:\n",
    "\t\t\tnUBL = len(bsl_coord_x)\n",
    "\t\t\tfor p in ['x', 'y']:\n",
    "\t\t\t\t#ubl_filename = datadir + tag + '_%s%s_%i_%i.ubl' % (p, p, nUBL, 3)\n",
    "\t\t\t\tubls[p] = globals()['bsl_coord_' + p]\n",
    "\t\t\tcommon_ubls = np.array([u for u in ubls['x'] if (u in ubls['y'] or -u in ubls['y'])])\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tnUBL = len(bsl_coord_dred[0])\n",
    "\t\t\tnUBL_yy = len(bsl_coord_dred[1])\n",
    "\t\t\tfor i in range(2):\n",
    "\t\t\t\tp = ['x', 'y'][i]\n",
    "\t\t\t\tubls[p] = bsl_coord_dred[i]\n",
    "\t\t\tcommon_ubls = np.array([u for u in ubls['x'] if (u in ubls['y'] or -u in ubls['y'])])\n",
    "\t\t\n",
    "\t\t#get data and var and apply change\n",
    "\t\t\n",
    "\t\tfor j, p in enumerate(['x', 'y']):\n",
    "\t\t\tpol = p+p\n",
    "\n",
    "\t\t\tif From_AbsCal:\n",
    "\t\t\t\tvis_data_dred_mfreq_pscal[j][id_f] = vis_data_dred_mfreq_abscal[j][id_f] * np.exp(1.j * ubls[p][:, :2].dot(phase_degen2[p])) * renorm\n",
    "\t\t\t\tif comply_ps2mod_autocorr:\n",
    "\t\t\t\t\tautocorr_data_dred_mfreq_pscal[j][:, id_f] = autocorr_vis_mfreq[j][:, id_f]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tautocorr_data_dred_mfreq_pscal[j][:, id_f] = autocorr_data_dred_mfreq_abscal[j][:, id_f] * np.abs(renorm)  # Absolute Calibrated\n",
    "\t\t\telse:\n",
    "\t\t\t\tvis_data_dred_mfreq_pscal[j][id_f] = vis_data_dred_mfreq[j][id_f] * np.exp(1.j * ubls[p][:, :2].dot(phase_degen2[p])) * renorm\n",
    "\t\t\t\tif comply_ps2mod_autocorr:\n",
    "\t\t\t\t\tautocorr_data_dred_mfreq_pscal[j][:, id_f] = autocorr_vis_mfreq[j][:, id_f]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tautocorr_data_dred_mfreq_pscal[j][:, id_f] = autocorr_data_mfreq[j][:, id_f] * np.abs(renorm) # Absolute Calibrated\n",
    "\t\t\n",
    "\t\t\n",
    "\tnoise_data_pscal = {}\n",
    "\tN_data_pscal = {}\n",
    "\tvis_data_dred_pscal = {}\n",
    "\tfor i, p in enumerate(['x', 'y']):\n",
    "\t\tpol = p+p\n",
    "#\t\tdata_filename = glob.glob(datadir + tag + '_%s%s_*_*'%(p, p) + datatag)[0]\n",
    "#\t\tnt_nUBL = os.path.basename(data_filename).split(datatag)[0].split('%s%s_'%(p, p))[-1]\n",
    "#\t\tnt = int(nt_nUBL.split('_')[0])\n",
    "#\t\tnUBL = int(nt_nUBL.split('_')[1])\n",
    "#\t\tvar_filename = datadir + tag + '_%s%s_%i_%i%s.var'%(p, p, nt, nUBL, vartag)\n",
    "#\n",
    "#\t\top_data_filename = datadir + tag + '_%s%s_%i_%i%s'%(p, p, nt, nUBL, dataoptag)\n",
    "#\t\top_var_filename = datadir + tag + '_%s%s_%i_%i%s.var'%(p, p, nt, nUBL, varoptag)\n",
    "#\t\top_var100_filename = datadir + tag + '_%s%s_%i_%i%s.var'%(p, p, nt, nUBL, varoptag+'x100')\n",
    "\n",
    "\t\t#ubl file\n",
    "\t\t#ubl_filename = datadir + tag + '_%s%s_%i_%i.ubl'%(p, p, nUBL, 3)\n",
    "\t\t#ubls = np.fromfile(ubl_filename, dtype='float32').reshape((nUBL, 3))\n",
    "\t\t\n",
    "#\t\tif From_AbsCal:\n",
    "#\t\t\tvis_data_dred_pscal[i] = vis_data_dred_abscal[i] * np.exp(1.j * ubls[p][:, :2].dot(phase_degen2[p])) * renorm\n",
    "#\t\t\tnoise_data_pscal[p] = np.array([(np.random.normal(0,autocorr_data_dred_abscal[i][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL) ) for t_index in range(len(autocorr_data[i]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "#\t\telse:\n",
    "#\t\t\tvis_data_dred_pscal[i] = vis_data_dred[i] * np.exp(1.j * ubls[p][:, :2].dot(phase_degen2[p])) * renorm\n",
    "#\t\t\tnoise_data_pscal[p] = np.array([(np.random.normal(0,autocorr_data[i][t_index]/(Integration_Time*Frequency_Bin)**0.5, nUBL) ) for t_index in range(len(autocorr_data[i]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "\t\t\n",
    "\t\tvis_data_dred_pscal[i] = vis_data_dred_mfreq_pscal[i][index_freq[i]]\n",
    "\t\tnoise_data_pscal[p] = np.array([(np.random.normal(0, autocorr_data_dred_mfreq_pscal[i][t_index, index_freq[i]]/ (Integration_Time*Frequency_Bin)**0.5, nUBL)/ np.array(redundancy[i])**0.5 ) for t_index in range(len(autocorr_data_dred_mfreq_pscal[i]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "\t\t\n",
    "#\t\tif From_AbsCal:\n",
    "#\t\t\tvis_data_dred_pscal[i] = vis_data_dred_mfreq_pscal[i][index_freq[i]]\n",
    "#\t\t\tnoise_data_pscal[p] = np.array([(np.random.normal(0,autocorr_data_dred_mfreq_pscal[i][t_index, index_freq[i]]/(Integration_Time*Frequency_Bin)**0.5, nUBL) ) for t_index in range(len(autocorr_data_dred_mfreq_pscal[i]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "#\t\telse:\n",
    "#\t\t\tvis_data_dred_pscal[i] = vis_data_dred_mfreq_pscal[i][index_freq[i]]\n",
    "#\t\t\tnoise_data_pscal[p] = np.array([(np.random.normal(0,autocorr_data_dred_mfreq_pscal[i][t_index, index_freq[i]]/(Integration_Time*Frequency_Bin)**0.5, nUBL) ) for t_index in range(len(autocorr_data_dred_mfreq_pscal[i]))],dtype='complex128').flatten() # Absolute Calibrated\n",
    "\t\t\t\t\t\n",
    "\t\tN_data_pscal[p] = noise_data_pscal[p] * noise_data_pscal[p]\n",
    "\t\tN_data_pscal[p] = N_data_pscal[p].reshape((nt, nUBL))\n",
    "\t\t\n",
    "\t\t#save\n",
    "#\t\tif os.path.isfile(op_data_filename) and not overwrite:\n",
    "#\t\t\traise IOError(op_data_filename + ' exists.')\n",
    "#\t\telse:\n",
    "#\t\t\tnew_data.astype('complex128').tofile(op_data_filename)\n",
    "\n",
    "\t\tN_data_pscal[p].astype('complex128').tofile(globals()['data_var_' + pol + '_filename_pscal'])\n",
    "\t\t#(new_var * 100.).astype('float32').tofile(op_var100_filename)\n",
    "\tdel(noise_data_pscal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(southern_points['cas']['ra'], southern_points['cas']['dec'])\n",
    "print(southern_points['cyg']['ra'], southern_points['cyg']['dec'])\n",
    "print(southern_points['sag']['ra'], southern_points['sag']['dec'])\n",
    "print(southern_points['cen']['ra'], southern_points['cen']['dec'])\n",
    "print(southern_points['cas']['body']._ra, southern_points['cas']['body']._dec)\n",
    "print(southern_points['cyg']['body']._ra, southern_points['cyg']['body']._dec)\n",
    "print(southern_points['sag']['body']._ra, southern_points['sag']['body']._dec)\n",
    "print(southern_points['cen']['body']._ra, southern_points['cen']['body']._dec)\n",
    "print(southern_points['hyd']['body']._ra, southern_points['hyd']['body']._dec)\n",
    "print(southern_points['pic']['body']._ra, southern_points['pic']['body']._dec)\n",
    "print(southern_points['for']['body']._ra, southern_points['for']['body']._dec)\n",
    "print(southern_points['crab']['body']._ra, southern_points['crab']['body']._dec)\n",
    "print(southern_points['vir']['body']._ra, southern_points['vir']['body']._dec)\n",
    "print(np.where((equatorial_GSM_standard>3000) & (equatorial_GSM_standard<=7500)))\n",
    "print(np.where(((PI / 2 - full_thetas)>=-0.81) & ((PI / 2 - full_thetas)<=-0.78) & (full_phis>=1.38) & (full_phis<=1.41))\n",
    "     )\n",
    "\n",
    "print(full_phis[3686], (PI / 2 - full_thetas)[3686]) # cyg\n",
    "print(full_phis[3571], (PI / 2 - full_thetas)[3571]) # cas\n",
    "print(full_phis[7206], (PI / 2 - full_thetas)[7206]) # sag\n",
    "print(full_phis[6044], (PI / 2 - full_thetas)[6044]) # crab\n",
    "print(full_phis[8623], (PI / 2 - full_thetas)[8623]) # for\n",
    "print(full_phis[10815], (PI / 2 - full_thetas)[10815]) # cen\n",
    "print(full_phis[10194], (PI / 2 - full_thetas)[10194]) # hyd\n",
    "print(full_phis[8526], (PI / 2 - full_thetas)[8526]) # pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_phis[3686], (PI / 2 - full_thetas)[3686]) # cyg: 3544.825\n",
    "print(full_phis[3571], (PI / 2 - full_thetas)[3571]) # cas: 5537.374\n",
    "print(full_phis[3572], (PI / 2 - full_thetas)[3572]) # cas: 3438.114\n",
    "print(full_phis[7206], (PI / 2 - full_thetas)[7206]) # sag: 7382.852\n",
    "print(full_phis[7207], (PI / 2 - full_thetas)[7207]) # sag: 7442.244\n",
    "print(full_phis[6044], (PI / 2 - full_thetas)[6044]) # crab: 868.720\n",
    "print(full_phis[8623], (PI / 2 - full_thetas)[8623]) # for: 457.697\n",
    "print(full_phis[10815], (PI / 2 - full_thetas)[10815]) # cen: 1334.333\n",
    "print(full_phis[10194], (PI / 2 - full_thetas)[10194]) # hyd: 238.472\n",
    "print(full_phis[8526], (PI / 2 - full_thetas)[8526]) # pic: 287.830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(equatorial_GSM_standard[3571], equatorial_GSM_standard[3566:3579], equatorial_GSM_standard[3686],\n",
    "      equatorial_GSM_standard[3683:3689], equatorial_GSM_standard[7203:7230],\n",
    "      equatorial_GSM_standard[7207], equatorial_GSM_standard[6044], equatorial_GSM_standard[8623],\n",
    "      equatorial_GSM_standard[8526], equatorial_GSM_standard[10194], equatorial_GSM_standard[10815],\n",
    "     np.mean(equatorial_GSM_standard), np.max(equatorial_GSM_standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Absolute_Calibration_dred_mfreq_pscal = True\n",
    "\n",
    "if Absolute_Calibration_dred_mfreq_pscal:\n",
    "\t\n",
    "\tfor i in range(2):\n",
    "\t\tdata_dred_mfreq_pscal[i] = LastUpdatedOrderedDict()\n",
    "\t\tpol = ['xx', 'yy'][i]\n",
    "\t\tif Absolute_Calibration_dred_mfreq:\n",
    "\t\t\tkeys = dflags_dred_mfreq[i].keys()\n",
    "\t\t\tfor key_index, key in enumerate(keys):\n",
    "\t\t\t\t#model_dred_mfreq[i][key] = fullsim_vis_mfreq[key_index, i]\n",
    "\t\t\t\t#data_dred_mfreq[i][key] = np.real(vis_data_dred_mfreq[i][:, :, key_index].transpose()) + np.abs(np.imag(vis_data_dred_mfreq[i][:, :, key_index].transpose()))*1j #[pol][freq,time,ubl_index].transpose()\n",
    "\t\t\t\tdata_dred_mfreq_pscal[i][key] = vis_data_dred_mfreq_pscal[i][:, :, key_index].transpose() #[pol][freq,time,ubl_index].transpose()\n",
    "\t\t\tif add_Autobsl:\n",
    "\t\t\t\tmodel_dred_mfreq[i][keys[0][0], keys[0][0], keys[0][2]] = autocorr_vis_mfreq[i] # not lose generality, choose the first anntena in the first UBL for autocorrelation calibraiton.\n",
    "\t\t\t\tdata_dred_mfreq_pscal[i][keys[0][0], keys[0][0], keys[0][2]] = autocorr_data_mfreq[i] # add the autocorrelation of first antenna in the first UBL as the last line in visibility.\n",
    "\t\t\t\tcdflags_dred_mfreq[i][keys[0][0], keys[0][0], keys[0][2]] = np.array([[False]*autocorr_data_mfreq[i].shape[1]]*autocorr_data_mfreq[i].shape[0])\n",
    "\t\t\t\tauto_select_dred_mfreq_pscal[i] = (keys[0][0], keys[0][0], keys[0][2])\n",
    "\t\t\tprint(dflags_dred_mfreq[i].keys())\n",
    "\t\t\tprint(dflags_dred_mfreq[i].keys()[0][0])\n",
    "\t\t\t\t\n",
    "\t\t\n",
    "\t\t\t\t\n",
    "\tre_cal_times = 3\n",
    "\n",
    "\tfor i in range(2):\n",
    "\t\tpol = ['xx', 'yy'][i]\n",
    "\t\tre_cal = 0\n",
    "\t\t\n",
    "\t\tif Absolute_Calibration_dred_mfreq_pscal:\n",
    "\t\t\tfor re_cal in range(re_cal_times): # number of times of absolute calibration\n",
    "\t\t\t\tif re_cal == 0:\n",
    "\t\t\t\t\tmodel_dred_mfreq[i], interp_flags_dred_mfreq[i] = hc.abscal.interp2d_vis(model_dred_mfreq[i], lsts, flist[i], lsts, flist[i])\n",
    "\t\t\t\t\t# instantiate class\n",
    "\t\t\t\t\tAC_dred_mfreq_pscal[i] = hc.abscal.AbsCal(model_dred_mfreq[i], data_dred_mfreq_pscal[i], antpos=antpos[i], wgts=wgts_dred_mfreq[i], freqs=flist[i])\n",
    "\t\t\t\t\t# kernel is median filter kernel, chosen to produce time-smooth output delays for this particular dataset\n",
    "\t\t\t\t\tAC_dred_mfreq_pscal[i].delay_lincal(kernel=(1, 11), medfilt=True, time_avg=True, solve_offsets=True)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\t#model_dred_mfreq[i], interp_flags_dred_mfreq[i] = hc.abscal.interp2d_vis(model_dred_mfreq[i], lsts, flist[i], lsts, flist[i])\n",
    "\t\t\t\t\t# instantiate class\n",
    "\t\t\t\t\tAC_dred_mfreq_pscal[i] = hc.abscal.AbsCal(model_dred_mfreq[i], abs_corr_data_dred_mfreq_pscal[i], antpos=antpos[i], wgts=wgts_dred_mfreq[i], freqs=flist[i])\n",
    "\t\t\t\t\t# kernel is median filter kernel, chosen to produce time-smooth output delays for this particular dataset\n",
    "\t\t\t\t\tAC_dred_mfreq_pscal[i].delay_lincal(kernel=(1, 3), medfilt=True, time_avg=True, solve_offsets=True)\n",
    "\t\t\t\t# apply to data\n",
    "\t\t\t\tdelay_corr_data_dred_mfreq_pscal[i] = hc.abscal.apply_gains(AC_dred_mfreq_pscal[i].data, (AC_dred_mfreq_pscal[i].ant_dly_gain))\n",
    "\t\t\t\t# instantiate class\n",
    "\t\t\t\tDAC_dred_mfreq_pscal[i] = hc.abscal.AbsCal(model_dred_mfreq[i], delay_corr_data_dred_mfreq_pscal[i], antpos=antpos[i], wgts=wgts_dred_mfreq[i], freqs=flist[i])\n",
    "\t\t\t\t# avg phase solver\n",
    "\t\t\t\tDAC_dred_mfreq_pscal[i].phs_logcal(avg=True)\n",
    "\t\t\t\t# apply to data\n",
    "\t\t\t\tdly_phs_corr_data_dred_mfreq_pscal[i] = hc.abscal.apply_gains(DAC_dred_mfreq_pscal[i].data, (DAC_dred_mfreq_pscal[i].ant_phi_gain))\n",
    "\t\t\t\t# instantiate class\n",
    "\t\t\t\tDPAC_dred_mfreq_pscal[i] = hc.abscal.AbsCal(model_dred_mfreq[i], dly_phs_corr_data_dred_mfreq_pscal[i], antpos=antpos[i], wgts=wgts_dred_mfreq[i], freqs=flist[i])\n",
    "\t\t\t\t# run amp linsolve\n",
    "\t\t\t\tDPAC_dred_mfreq_pscal[i].abs_amp_logcal()\n",
    "\t\t\t\t# run phs linsolve\n",
    "\t\t\t\tDPAC_dred_mfreq_pscal[i].TT_phs_logcal(zero_psi=False, four_pol=False)\n",
    "\t\t\t\t# apply to data\n",
    "\t\t\t\tabs_corr_data_dred_mfreq_pscal[i] = hc.abscal.apply_gains(DPAC_dred_mfreq_pscal[i].data, \n",
    "\t\t\t\t\t\t\t\t\t\t(DPAC_dred_mfreq_pscal[i].abs_psi_gain, DPAC_dred_mfreq_pscal[i].TT_Phi_gain, DPAC_dred_mfreq_pscal[i].abs_eta_gain), gain_convention='multiply')\n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\tvis_data_dred_mfreq_pscal_abscal[i] = np.zeros_like(vis_data_dred_mfreq_pscal[i], dtype='complex128')\n",
    "\t\t\tfor key_id, key in enumerate(dflags_dred_mfreq[i].keys()):\n",
    "\t\t\t\tvis_data_dred_mfreq_pscal_abscal[i][:, :, key_id] = abs_corr_data_dred_mfreq_pscal[i][key].transpose()\n",
    "\t\t\t\t#vis_data_dred_mfreq_pscal_abscal[i][:, :, key_id] = np.real(abs_corr_data_dred_mfreq_pscal[i][key].transpose()) + np.abs(np.imag(abs_corr_data_dred_mfreq_pscal[i][key].transpose()))*1j\n",
    "\t\t\tif add_Autobsl:\n",
    "\t\t\t\tautocorr_data_dred_mfreq_pscal_abscal[i] = abs_corr_data_dred_mfreq_pscal[i][auto_select_dred_mfreq_pscal[i]]\n",
    "\t\t\telse:\n",
    "\t\t\t\tautocorr_data_dred_mfreq_pscal_abscal[i] = autocorr_vis_mfreq[i]\n",
    "\t\t\t\t\n",
    "\t\t\tvis_data_dred_pscal_abscal[i] = vis_data_dred_mfreq_pscal_abscal[i][index_freq[i], :, :]\n",
    "\t\t\tif add_Autobsl: \n",
    "\t\t\t\tautocorr_data_dred_pscal_abscal[i] = autocorr_data_dred_mfreq_pscal_abscal[i][:, index_freq[i]]\n",
    "\t\t\telse:\n",
    "\t\t\t\tautocorr_data_dred_pscal_abscal[i] = autocorr_vis_mfreq[i][:, index_freq[i]]\n",
    "\t\t\t\n",
    "\tfor i in range(2):\n",
    "\t\tpol = ['xx', 'yy'][i]\n",
    "\t\t\n",
    "\t\tif Absolute_Calibration_dred_mfreq_pscal:\t\t\t\t\t\t\t\t\n",
    "\t\t\tplt.figure(85000000+10*i)\n",
    "\t\t\tfig4[i], axes4[i] = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\t\t\tplt.sca(axes4[i][0])\n",
    "\t\t\tuvt.plot.waterfall(AC_dred_mfreq_pscal[i].model[bl_dred_mfreq_pscal[i]], mode='log', mx=6, drng=4)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' model AMP {}'.format(bl_dred_mfreq_pscal[i]))\n",
    "\t\t\tplt.sca(axes4[i][1])\n",
    "\t\t\tuvt.plot.waterfall(AC_dred_mfreq_pscal[i].model[bl_dred_mfreq_pscal[i]], mode='phs', mx=np.pi, drng=2*np.pi)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' model PHS {}'.format(bl_dred_mfreq_pscal[i]))\n",
    "\t\t\tplt.show(block=False)\t\t\t\n",
    "\t\t\t#plt.cla()\n",
    "\t\t\t\t\n",
    "\t\t\tplt.figure(95000000+10*i)\n",
    "\t\t\tfig4_data[i], axes4_data[i] = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\t\t\tplt.sca(axes4_data[i][0])\n",
    "\t\t\tuvt.plot.waterfall(data_dred_mfreq_pscal[i][bl_dred_mfreq_pscal[i]], mode='log', mx=6, drng=6)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' data AMP {}'.format(bl_dred_mfreq_pscal[i]))\n",
    "\t\t\tplt.sca(axes4_data[i][1])\n",
    "\t\t\tuvt.plot.waterfall(data_dred_mfreq_pscal[i][bl_dred_mfreq_pscal[i]], mode='phs', mx=np.pi, drng=2*np.pi)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' data PHS {}'.format(bl_dred_mfreq_pscal[i]))\n",
    "\t\t\tplt.show(block=False)\n",
    "\t\t\t#plt.cla()\t\t\n",
    "\t\t\t\t\n",
    "\t\t\t####################### after ABS Calibration #########################\t\n",
    "\t\t\tplt.figure(8500000+10*i)\n",
    "\t\t\tfig4_data_abscorr[i], axes4_data_abscorr[i] = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\t\t\tplt.sca(axes4_data_abscorr[i][0])\n",
    "\t\t\tuvt.plot.waterfall(abs_corr_data_dred_mfreq_pscal[i][bl_dred_mfreq_pscal[i]], mode='log', mx=6, drng=4)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' abs_caled data AMP {}'.format(bl_dred_mfreq_pscal[i]))\n",
    "\t\t\tplt.sca(axes4_data_abscorr[i][1])\n",
    "\t\t\tuvt.plot.waterfall(abs_corr_data_dred_mfreq_pscal[i][bl_dred_mfreq_pscal[i]], mode='phs', mx=np.pi, drng=2*np.pi)\n",
    "\t\t\tplt.colorbar()\n",
    "\t\t\tplt.title(pol + ' abs_caled data PHS {}'.format(bl_dred_mfreq_pscal[i]))\n",
    "\t\t\tplt.show(block=False)\n",
    "\t\t\t#plt.cla()\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################### Store Visibility Data and prepare to Delete Variable ##################################\n",
    "try:\n",
    "    data_vis_xx_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_xx.simvis' % (INSTRUMENT, freq, nUBL_used + 1, nt_used, nside_standard, bnside)\n",
    "    data_vis_yy_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_yy.simvis' % (INSTRUMENT, freq, nUBL_used + 1, nt_used, nside_standard, bnside)\n",
    "    vis_data[0].astype('complex128').tofile(data_vis_xx_filename)\n",
    "    vis_data[1].astype('complex128').tofile(data_vis_yy_filename)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    data_vis_dred_xx_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_dred_xx_dred.simvis' % (INSTRUMENT, freq, nUBL_used + 1, nt_used, nside_standard, bnside)\n",
    "    data_vis_dred_yy_filename = script_dir + '/../Output/%s_%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_dred_yy_dred.simvis' % (INSTRUMENT, freq, nUBL_used + 1, nt_used, nside_standard, bnside)\n",
    "    vis_data_dred[0].astype('complex128').tofile(data_vis_dred_xx_filename)\n",
    "    vis_data_dred[1].astype('complex128').tofile(data_vis_dred_yy_filename)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    data_vis_dred_mfreq_xx_filename = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_xx_mfreq%s-%s-%s_dred_mfreq.simvis' % (INSTRUMENT, nUBL_used + 1, nt_used, nside_standard, bnside, np.min(flist[0]), np.max(flist[0]), len(flist[0]))\n",
    "    data_vis_dred_mfreq_yy_filename = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_yy_mfreq%s-%s-%s_dred_mfreq.simvis' % (INSTRUMENT, nUBL_used + 1, nt_used, nside_standard, bnside, np.min(flist[1]), np.max(flist[1]), len(flist[1]))\n",
    "    vis_data_dred_mfreq[0].astype('complex128').tofile(data_vis_dred_mfreq_xx_filename)\n",
    "    vis_data_dred_mfreq[1].astype('complex128').tofile(data_vis_dred_mfreq_yy_filename)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    abscal_data_vis_dred_mfreq_xx_filename = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_xx_mfreq%s-%s-%s_dred_mfreq_abscal.simvis' % (INSTRUMENT, nUBL_used + 1, nt_used, nside_standard, bnside, np.min(flist[0]), np.max(flist[0]), len(flist[0]))\n",
    "    abscal_data_vis_dred_mfreq_yy_filename = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_yy_mfreq%s-%s-%s_dred_mfreq_abscal.simvis' % (INSTRUMENT, nUBL_used + 1, nt_used, nside_standard, bnside, np.min(flist[1]), np.max(flist[1]), len(flist[1]))\n",
    "    vis_data_dred_mfreq_abscal[0].astype('complex128').tofile(abscal_data_vis_dred_mfreq_xx_filename)\n",
    "    vis_data_dred_mfreq_abscal[1].astype('complex128').tofile(abscal_data_vis_dred_mfreq_yy_filename)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    abscal_data_vis_dred_xx_filename = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_xx_%s_dred_abscal.simvis' % (INSTRUMENT, nUBL_used + 1, nt_used, nside_standard, bnside, freq)\n",
    "    abscal_data_vis_dred_yy_filename = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_yy_%s_dred_abscal.simvis' % (INSTRUMENT, nUBL_used + 1, nt_used, nside_standard, bnside, freq)\n",
    "    vis_data_dred_abscal[0].astype('complex128').tofile(abscal_data_vis_dred_xx_filename)\n",
    "    vis_data_dred_abscal[1].astype('complex128').tofile(abscal_data_vis_dred_yy_filename)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    pscal_data_vis_dred_mfreq_xx_filename = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_xx_%s_dred_mfreq_pscal.simvis' % (INSTRUMENT, nUBL, nt, nside_standard, bnside, freq)\n",
    "    pscal_data_vis_dred_mfreq_yy_filename = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_yy_%s_dred_mfreq_pscal.simvis' % (INSTRUMENT, nUBL, nt, nside_standard, bnside, freq)\n",
    "    vis_data_dred_mfreq_pscal[0].astype('complex128').tofile(pscal_data_vis_dred_mfreq_xx_filename)\n",
    "    vis_data_dred_mfreq_pscal[1].astype('complex128').tofile(pscal_data_vis_dred_mfreq_yy_filename)\n",
    "    \n",
    "    pscal_data_vis_dred_xx_filename = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_xx_%s_pscal.simvis' % (INSTRUMENT, nUBL, nt, nside_standard, bnside, freq)\n",
    "    pscal_data_vis_dred_yy_filename = script_dir + '/../Output/%s_p2_u%i_t%i_nside%i_bnside%i_vis_data_yy_%s_pscal.simvis' % (INSTRUMENT, nUBL, nt, nside_standard, bnside, freq)\n",
    "    vis_data_dred_pscal[0].astype('complex128').tofile(pscal_data_vis_dred_xx_filename)\n",
    "    vis_data_dred_pscal[1].astype('complex128').tofile(pscal_data_vis_dred_yy_filename)\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print noise['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "####read data and N\n",
    "################\n",
    "data = {}\n",
    "Ni = {}\n",
    "data_shape = {}\n",
    "ubl_sort = {}\n",
    "data_filename = full_sim_filename\n",
    "\n",
    "Use_Simulation_noise = True\n",
    "From_File_Data = True\n",
    "\n",
    "\n",
    "for p in ['x', 'y']:\n",
    "\tpol = p + p\n",
    "\tprint \"%i UBLs to include, longest baseline is %i wavelengths\" % (\n",
    "\tnUBL_used, np.max(np.linalg.norm(used_common_ubls, axis=1)) / (C / freq))\n",
    "\tif p == 'x':\n",
    "\t\tpol_index = 0\n",
    "\t\tsim_var_filename = sim_var_xx_filename\n",
    "\t\tsim_vis_filename = sim_vis_xx_filename\n",
    "\t\ttry:\n",
    "\t\t\tdata_var_filename = data_var_xx_filename\n",
    "\t\t\tdata_var_filename_pscal = data_var_xx_filename_pscal\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\telif p == 'y':\n",
    "\t\tpol_index = 1\n",
    "\t\tsim_var_filename = sim_var_yy_filename\n",
    "\t\tsim_vis_filename = sim_vis_yy_filename\n",
    "\t\ttry:\n",
    "\t\t\tdata_var_filename = data_var_yy_filename\n",
    "\t\t\tdata_var_filename_pscal = data_var_yy_filename_pscal\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\n",
    "\t# get Ni (1/variance) and data\n",
    "#\tvar_filename = datadir + tag + '_%s%s_%i_%i' % (p, p, nt, nUBL) + vartag + '.var'\n",
    "#\tNi[pol] = 1. / (N[p].reshape((nt_used, nUBL_used))[tmask].transpose()[abs(ubl_index[p]) - 1].flatten() * jansky2kelvin ** 2)\n",
    "\tif Use_SimulatedData == 1:\n",
    "#\t\tNi[pol] = 1. / (np.fromfile(data_var_filename, dtype='complex128').reshape((nt_used, nUBL_used))[tmask].transpose()[abs(ubl_index[p]) - 1].flatten() * jansky2kelvin ** 2)\n",
    "\t\tNi[pol] = 1. / (np.fromfile(sim_var_filename, dtype='complex128').reshape((nt_used, nUBL_used)).transpose().flatten())\n",
    "\t\tdata[pol] = np.fromfile(sim_vis_filename, dtype='complex128').reshape((nUBL_used, nt_used))\n",
    "\telse:\n",
    "\t\tif INSTRUMENT == 'miteor':\n",
    "\t\t\tif Use_Simulation_noise:\n",
    "\t\t\t\tNi[pol] = 1. / (np.fromfile(data_var_filename, dtype='complex128').reshape((nt, nUBL))[tmask].transpose()[abs(ubl_index[p]) - 1].flatten())\n",
    "\t\t\telse:\n",
    "\t\t\t\tNi[pol] = 1. / var_data[pol_index][tmask].transpose()[abs(ubl_index[p]) - 1].flatten()\n",
    "\t\t\tdata[pol] = vis_data[pol_index][tmask].transpose()[abs(ubl_index[p]) - 1] #= (time_vis_data[:,1:,1::3] + time_vis_data[:,1:,2::3] * 1j).astype('complex64')\t\t\t\n",
    "\t\t\tdata[pol][ubl_index[p] < 0] = data[pol][ubl_index[p] < 0].conjugate()\n",
    "#\t\t\tdata[pol] = (data[pol].flatten() * jansky2kelvin).conjugate()  # there's a conjugate convention difference\n",
    "\t\t\tdata[pol] = (data[pol].flatten()).conjugate()  # there's a conjugate convention difference\n",
    "\t\telif INSTRUMENT == 'hera47':\n",
    "\t\t\tif From_File_Data:\n",
    "\t\t\t\tif Use_PsAbsCal:\n",
    "\t\t\t\t\tNi[pol] = 1. / (np.fromfile(data_var_filename_pscal, dtype='complex128').reshape((nt, nUBL))[tmask].transpose()[abs(ubl_index[p]) - 1].flatten()) #var_data[pol_index][tmask].transpose()[abs(ubl_index[p]) - 1].flatten()\n",
    "\t\t\t\telif Use_Fullsim_Noise:\n",
    "\t\t\t\t\tNi[pol] = 1. / (np.fromfile(sim_var_filename, dtype='complex128').reshape((nt_used, nUBL_used)).transpose().flatten())\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tNi[pol] = 1. / (np.fromfile(data_var_filename, dtype='complex128').reshape((nt, nUBL))[tmask].transpose()[abs(ubl_index[p]) - 1].flatten()) #var_data[pol_index][tmask].transpose()[abs(ubl_index[p]) - 1].flatten()\n",
    "\t\t\telse:\n",
    "\t\t\t\tif Use_PsAbsCal:\n",
    "\t\t\t\t\tNi[pol] = 1. / N_data_pscal[p].reshape((nt, nUBL))[tmask].transpose()[abs(ubl_index[p]) - 1].flatten() #var_data[pol_index][tmask].transpose()[abs(ubl_index[p]) - 1].flatten()\n",
    "\t\t\t\telif Use_Fullsim_Noise:\n",
    "\t\t\t\t\tNi[pol] = 1. / (np.fromfile(sim_var_filename, dtype='complex128').reshape((nt_used, nUBL_used)).transpose().flatten())\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tNi[pol] = 1. / N_data[p].reshape((nt, nUBL))[tmask].transpose()[abs(ubl_index[p]) - 1].flatten() #var_data[pol_index][tmask].transpose()[abs(ubl_index[p]) - 1].flatten()\n",
    "\t\t\tif From_File_Data:\n",
    "\t\t\t\tif Use_PsAbsCal:\n",
    "\t\t\t\t\tdata[pol] = np.fromfile(globals()['pscal_data_vis_dred_' + pol + '_filename'], dtype='complex128').reshape((nt, nUBL))[tmask].transpose()[abs(ubl_index[p]) - 1]\n",
    "\t\t\t\telif Use_AbsCal:\t\t\t\t\n",
    "\t\t\t\t\tdata[pol] = np.fromfile(globals()['abscal_data_vis_dred_' + pol + '_filename'], dtype='complex128').reshape((nt, nUBL))[tmask].transpose()[abs(ubl_index[p]) - 1]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdata[pol] = np.fromfile(globals()['data_vis_dred_' + pol + '_filename'], dtype='complex128').reshape((nt, nUBL))[tmask].transpose()[abs(ubl_index[p]) - 1]\n",
    "\t\t\telse:\n",
    "\t\t\t\tif Use_PsAbsCal:\n",
    "\t\t\t\t\tdata[pol] = vis_data_dred_pscal[pol_index][tmask].transpose()[abs(ubl_index[p]) - 1] #= (time_vis_data[:,1:,1::3] + time_vis_data[:,1:,2::3] * 1j).astype('complex64')\n",
    "\t\t\t\t\t#data[pol][ubl_index[p] < 0] = data[pol][ubl_index[p] < 0]#.conjugate()\n",
    "\t\t\t\t\tdata[pol] = data[pol].flatten()#.conjugate()  # there's a conjugate convention difference\n",
    "\t\t\t\telif Use_AbsCal:\t\t\t\t\n",
    "\t\t\t\t\tdata[pol] = vis_data_dred_abscal[pol_index][tmask].transpose()[abs(ubl_index[p]) - 1] #= (time_vis_data[:,1:,1::3] + time_vis_data[:,1:,2::3] * 1j).astype('complex64')\n",
    "\t\t\t\t\t#data[pol][ubl_index[p] < 0] = data[pol][ubl_index[p] < 0]#.conjugate()\n",
    "\t\t\t\t\tdata[pol] = data[pol].flatten()#.conjugate()  # there's a conjugate convention difference\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdata[pol] = vis_data_dred[pol_index][tmask].transpose()[abs(ubl_index[p]) - 1] #= (time_vis_data[:,1:,1::3] + time_vis_data[:,1:,2::3] * 1j).astype('complex64')\n",
    "\t\t\t\t\t#data[pol][ubl_index[p] < 0] = data[pol][ubl_index[p] < 0]#.conjugate()\n",
    "\t\t\t\t\tdata[pol] = (data[pol].flatten() * jansky2kelvin)#.conjugate()  # there's a conjugate convention difference\n",
    "\t\t\t#data[pol][ubl_index[p] < 0] = data[pol][ubl_index[p] < 0]#.conjugate()\n",
    "\t\t\t#data[pol] = (data[pol].flatten() * jansky2kelvin)#.conjugate()  # there's a conjugate convention difference\n",
    "\tdata_shape[pol] = (nUBL_used, nt_used)\n",
    "\tubl_sort[p] = np.argsort(la.norm(used_common_ubls, axis=1))\n",
    "print \"Memory usage: %.3fMB\" % (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1024)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Merge data\n",
    "data = np.array([data['xx'], data['yy']]).reshape([2] + list(data_shape['xx'])).transpose(\n",
    "\t(1, 0, 2)).flatten()\n",
    "data = np.concatenate((np.real(data), np.imag(data))).astype('complex128')\n",
    "Ni = np.concatenate((Ni['xx'], Ni['yy'])).reshape([2] + list(data_shape['xx'])).transpose(\n",
    "\t(1, 0, 2)).flatten()\n",
    "Ni = np.concatenate((Ni * 2, Ni * 2))\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "def get_complex_data(real_data, nubl=nUBL_used, nt=nt_used):\n",
    "\tif len(real_data.flatten()) != 2 * nubl * 2 * nt:\n",
    "\t\traise ValueError(\"Incorrect dimensions: data has length %i where nubl %i and nt %i together require length of %i.\"%(len(real_data), nubl, nt, 2 * nubl * 2 * nt))\n",
    "\tinput_shape = real_data.shape\n",
    "\treal_data.shape = (2, nubl, 2, nt)\n",
    "\tresult = real_data[0] + 1.j * real_data[1]\n",
    "\treal_data.shape = input_shape\n",
    "\treturn result\n",
    "\n",
    "def stitch_complex_data(complex_data):\n",
    "\treturn np.concatenate((np.real(complex_data.flatten()), np.imag(complex_data.flatten()))).astype('complex128')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################### Delete or Erase Data #######################\n",
    "#Erase = True\n",
    "if Erase:\n",
    "\tmodel_sf = {}\n",
    "\tmodel_dred = {}\n",
    "\tmodel_dred_mfreq = {}\n",
    "\t#data = {}\n",
    "\tdata_sf = {}\n",
    "\tdata_dred = {}\n",
    "\tdata_dred_mfreq = {}\n",
    "\tAC = {}\n",
    "\tAC_sf = {}\n",
    "\tAC_dred = {}\n",
    "\tAC_dred_mfreq = {}\n",
    "\tfreq_to_cal = [freq]\n",
    "\tfulldflags = {}\n",
    "\tauto_select_dred_mfreq = {}\n",
    "\n",
    "\t#\ttry:\n",
    "\t#\t\tcdata = copy.deepcopy(data)\n",
    "\t#\texcept:\n",
    "\t#\t\tpass\n",
    "\n",
    "\ttry:\n",
    "\t\tdel(dflags_sf) \n",
    "\t\t#del(cdflags_sf)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\t\t\n",
    "\ttry:\n",
    "\t\tdel(dflags_dred) \n",
    "\t\t#del(cdflags_dred)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\n",
    "\ttry:\n",
    "\t\tdel(dflags)\n",
    "\t\t#del(cdflags) \n",
    "\texcept:\n",
    "\t\tpass\n",
    "\n",
    "\ttry:\n",
    "\t\tdel(dflags_dred_mfreq)\n",
    "\t\t#del(cdflags_dred_mfreq) \n",
    "\texcept:\n",
    "\t\tpass\n",
    "\t\t\n",
    "\t#cwgts = copy.deepcopy(wgts)\n",
    "\t#cwgts_dred = copy.deepcopy(wgts_dred)\n",
    "\n",
    "\tbl_select = 0\n",
    "\t#bl = dflags.keys()[bl_select] #dflags and dflags_yy #[(24, 53, 'xx')\n",
    "\tfig = {}\n",
    "\taxes = {}\n",
    "\tfig_data = {}\n",
    "\taxes_data = {}\n",
    "\n",
    "\tbl_dred_select = 0\n",
    "\t#bl_dred = dflags_dred[0].keys()[bl_dred_select] #[(25, 37, 'xx')\n",
    "\tfig2 = {}\n",
    "\taxes2 = {}\n",
    "\tfig2_data = {}\n",
    "\taxes2_data = {}\n",
    "\n",
    "\tbl_dred_mfreq_select = 8\n",
    "\t#bl_dred_mfreq = [dflags_dred_mfreq[0].keys()[bl_dred_mfreq_select], dflags_dred_mfreq[1].keys()[bl_dred_mfreq_select]]  #[(25, 37, 'xx'), (25, 37, 'yy')]\n",
    "\tfig3 = {}\n",
    "\taxes3 = {}\n",
    "\tfig3_data = {}\n",
    "\taxes3_data = {}\n",
    "\tfig3_data_abscorr = {} \n",
    "\taxes3_data_abscorr = {}\n",
    "\n",
    "\tdelay_corr_data = {}\n",
    "\tdelay_corr_data_sf = {}\n",
    "\tdelay_corr_data_dred = {}\n",
    "\tdelay_corr_data_dred_mfreq = {}\n",
    "\tDAC = {}\n",
    "\tDAC_sf = {}\n",
    "\tDAC_dred = {}\n",
    "\tDAC_dred_mfreq = {}\n",
    "\tdly_phs_corr_data = {}\n",
    "\tdly_phs_corr_data_sf = {}\n",
    "\tdly_phs_corr_data_dred = {}\n",
    "\tdly_phs_corr_data_dred_mfreq = {}\n",
    "\tDPAC = {}\n",
    "\tDPAC_sf = {}\n",
    "\tDPAC_dred = {}\n",
    "\tDPAC_dred_mfreq = {}\n",
    "\tabs_corr_data = {}\n",
    "\tabs_corr_data_sf = {}\n",
    "\tabs_corr_data_dred = {}\n",
    "\tabs_corr_data_dred_mfreq = {}\n",
    "\n",
    "\tvis_data_dred_mfreq_abscal = [[], []]\n",
    "\tautocorr_data_dred_mfreq_abscal = [[], []]\n",
    "\tvis_data_dred_abscal = [[], []]\n",
    "\tautocorr_data_dred_abscal = [[], []]\n",
    "\n",
    "\n",
    "\tDel = True\n",
    "\tif Del:\n",
    "\t\ttry:\n",
    "\t\t\tdel(vis_data)\n",
    "\t\t\tdel(vis_data_dred)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t\ttry:\n",
    "\t\t\tdel(vis_data_mfreq)\n",
    "\t\t\tdel(vis_data_dred_mfreq)\n",
    "\t\texcept:\n",
    "\t\t\tpass\t\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\ttry:\n",
    "\t\t\tdel(N_data)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t\ttry:\n",
    "\t\t\tdel(noise_data)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t\ttry:\n",
    "\t\t\tdel(var_data)\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t#\ttry:\n",
    "\t#\t\tdel(var_data)\n",
    "\t#\texcept:\n",
    "\t#\t\tpass\n",
    "\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print Ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre_ampcal = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pre_ampcal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "################################\n",
    "####pre_calibrate################\n",
    "################################\n",
    "################################\n",
    "#####1. antenna based calibration#######\n",
    "for cal_index in range(1):\n",
    "\tif cal_index == 0:\n",
    "\t\traw_data = np.copy(data).reshape(2, data_shape['xx'][0], 2, data_shape['xx'][1])\n",
    "#\tif pre_ampcal:\n",
    "#\t\tpre_ampcal = False if cal_index == 0 else True\n",
    "#\t\tcal_index += 1\n",
    "#\telse:\n",
    "#\t\tcal_index = 2 \n",
    "\tif antpairs is not None:\n",
    "\t\tused_antpairs = antpairs[abs(ubl_index['x'])-1]\n",
    "\t\tn_usedants = np.unique(used_antpairs)\n",
    "\t#####2. re-phasing and crosstalk#######\n",
    "\tadditive_A = np.zeros((nUBL_used, 2, nt_used, 1 + 4 * nUBL_used)).astype('complex128')\n",
    "\n",
    "\t#put in autocorr regardless of whats saved on disk\n",
    "\tfor p in range(2):\n",
    "\t\tadditive_A[:, p, :, 0] = fullsim_vis[:, p]\n",
    "\t\tfor i in range(nUBL_used):\n",
    "\t\t\tadditive_A[i, p, :, 1 + 4 * i + 2 * p] = 1. * autocorr_vis_normalized[p]\n",
    "\t\t\tadditive_A[i, p, :, 1 + 4 * i + 2 * p + 1] = 1.j * autocorr_vis_normalized[p]\n",
    "\tadditive_A.shape = (nUBL_used * 2 * nt_used, 1 + 4 * nUBL_used)\n",
    "\n",
    "\tif pre_calibrate:\n",
    "\t\t#import omnical.calibration_omni as omni\n",
    "\t\t#raw_data = np.copy(data).reshape(2, data_shape['xx'][0], 2, data_shape['xx'][1])\n",
    "\t\t#raw_Ni = np.copy(Ni)\n",
    "\n",
    "\t\treal_additive_A = np.concatenate((np.real(additive_A), np.imag(additive_A)), axis=0).astype('complex128')\n",
    "\t\tif pre_ampcal:#if pre_ampcal, allow xx and yy to fit amp seperately\n",
    "\t\t\tn_prefit_amp = 2\n",
    "\t\t\treal_additive_A.shape = (2 * nUBL_used, 2, nt_used, 1 + 4 * nUBL_used)\n",
    "\t\t\treal_additive_A_expand = np.zeros((2 * nUBL_used, 2, nt_used, n_prefit_amp + 4 * nUBL_used), dtype='complex128')\n",
    "\t\t\tfor i in range(n_prefit_amp):\n",
    "\t\t\t\treal_additive_A_expand[:, i, :, i] = real_additive_A[:, i, :, 0]\n",
    "\t\t\treal_additive_A_expand[..., n_prefit_amp:] = real_additive_A[..., 1:]\n",
    "\t\t\treal_additive_A = real_additive_A_expand\n",
    "\t\t\treal_additive_A.shape = (2 * nUBL_used * 2 * nt_used, n_prefit_amp + 4 * nUBL_used)\n",
    "\t\telse:\n",
    "\t\t\tn_prefit_amp = 1\n",
    "\n",
    "\t\tadditive_AtNiA = np.empty((n_prefit_amp + 4 * nUBL_used, n_prefit_amp + 4 * nUBL_used), dtype='complex128')\n",
    "\t\tif pre_addcal:\n",
    "\t\t\tATNIA(real_additive_A, Ni, additive_AtNiA)\n",
    "\t\t\tadditive_AtNiAi = sla.inv(additive_AtNiA)\n",
    "\t\telse:\n",
    "\t\t\treal_additive_A[..., n_prefit_amp:] = 0.\n",
    "\t\t\tATNIA(real_additive_A, Ni, additive_AtNiA)\n",
    "\t\t\tadditive_AtNiAi = sla.pinv(additive_AtNiA)\n",
    "\n",
    "\t\tniter = 0\n",
    "\t\trephases = np.zeros((2,2))\n",
    "\t\tadditive_term = np.zeros_like(data)\n",
    "\t\tadditive_term_incr = np.zeros_like(data)\n",
    "\t\twhile (niter == 0 or la.norm(rephases) > .001 or la.norm(additive_term_incr) / la.norm(data) > .001) and niter < 500:\n",
    "\t\t\tniter += 1\n",
    "\n",
    "\t\t\tif pre_phscal:\n",
    "\t\t\t\tcdata = get_complex_data(data)\n",
    "\t\t\t\tfor p, pol in enumerate(['xx', 'yy']):\n",
    "\t\t\t\t\t#rephase = omni.solve_phase_degen_fast(cdata[:, p].transpose(), cdata[:, p].transpose(), fullsim_vis[:, p].transpose(), fullsim_vis[:, p].transpose(), used_common_ubls)\n",
    "\t\t\t\t\trephase = solve_phase_degen(cdata[:, p].transpose(), cdata[:, p].transpose(), fullsim_vis[:, p].transpose(), fullsim_vis[:, p].transpose(), used_common_ubls)\n",
    "\t\t\t\t\trephases[p] = rephase\n",
    "\t\t\t\t\tif p == 0:\n",
    "\t\t\t\t\t\tprint 'pre process rephase', pol, rephase,\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tprint pol, rephase\n",
    "\t\t\t\t\tcdata[:, p] *= np.exp(1.j * used_common_ubls[:, :2].dot(rephase))[:, None]\n",
    "\t\t\t\tdata = stitch_complex_data(cdata).astype('complex128')\n",
    "\n",
    "\t\t\tadditive_sol = additive_AtNiAi.dot(np.transpose(real_additive_A).dot(data * Ni))\n",
    "\t\t\tprint '>>>>>>>>>>>>>additive fitting amp', additive_sol[:n_prefit_amp],\n",
    "\t\t\tadditive_term_incr = real_additive_A[:, n_prefit_amp:].dot(additive_sol[n_prefit_amp:])\n",
    "\t\t\tdata -= additive_term_incr\n",
    "\t\t\tadditive_term += additive_term_incr\n",
    "\t\t\tprint \"additive fraction\", la.norm(additive_term_incr) / la.norm(data),\n",
    "\n",
    "\t\tcadd = get_complex_data(additive_term)\n",
    "\n",
    "\t\tif pre_ampcal:\n",
    "\t\t\tdata = stitch_complex_data(get_complex_data(data) / additive_sol[:n_prefit_amp, None])\n",
    "\t\t\tif Use_PsAbsCal and not comply_ps2mod_autocorr:\n",
    "\t\t\t\tNi = stitch_complex_data(get_complex_data(Ni) * additive_sol[:n_prefit_amp, None]**2)\n",
    "\t\t\tadditive_term = stitch_complex_data(get_complex_data(additive_term) / additive_sol[:n_prefit_amp, None])\n",
    "\t\t\t\n",
    "\t\t\tprint(additive_sol[:n_prefit_amp])\n",
    "\t\t\t\n",
    "print 'saving data to', os.path.dirname(data_filename) + '/' + INSTRUMENT + tag + datatag + vartag + '_gsmcal_n%i_bn%i.npz'%(nside_standard, bnside)\n",
    "np.savez(os.path.dirname(data_filename) + '/' + INSTRUMENT + tag + datatag + vartag + '_gsmcal_n%i_bn%i.npz'%(nside_standard, bnside),\n",
    "\t\t data=data,\n",
    "\t\t simdata=stitch_complex_data(fullsim_vis),\n",
    "\t\t psdata=[stitch_complex_data(vis) for vis in pt_vis],\n",
    "\t\t pt_sources=pt_sources,\n",
    "\t\t ubls=used_common_ubls,\n",
    "\t\t tlist=lsts,\n",
    "\t\t Ni=Ni,\n",
    "\t\t freq=freq)\n",
    "\t\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rephases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print la.norm(data)\n",
    "print la.norm(raw_data)\n",
    "print la.norm(fullsim_vis)\n",
    "print la.norm(raw_data)/la.norm(data)\n",
    "print #la.norm(raw_Ni)\n",
    "print la.norm(Ni)\n",
    "print data\n",
    "print fullsim_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print additive_sol[0], additive_sol[1], n_prefit_amp\n",
    "print (additive_sol[0] * (pre_ampcal)+(not pre_ampcal))\n",
    "print additive_sol[:n_prefit_amp, None]\n",
    "print pre_ampcal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print la.norm(data)\n",
    "print la.norm(raw_data)\n",
    "print la.norm(fullsim_vis)\n",
    "print la.norm(fullsim_vis)/la.norm(data)\n",
    "#print la.norm(raw_Ni)\n",
    "print la.norm(Ni)\n",
    "print Ni\n",
    "print Ni.max()\n",
    "print Ni**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_data_error:\n",
    "\t#plt.clf()\n",
    "\t\n",
    "\tcdata = get_complex_data(data)\n",
    "\tcrdata = get_complex_data(raw_data) #/ (additive_sol[0] * (pre_ampcal) + (not pre_ampcal))\n",
    "\tcNi = get_complex_data(Ni)\n",
    "\t\n",
    "\n",
    "\tfun = np.abs\n",
    "\tsrt = sorted((lsts - lst_offset)%24.+lst_offset)\n",
    "\tasrt = np.argsort((lsts - lst_offset)%24.+lst_offset)\n",
    "\tpncol = min(int(60. / (srt[-1] - srt[0])), 12) if nt_used > 1 else (len(ubl_sort['x'])/2) \n",
    "\tus = ubl_sort['x'][::len(ubl_sort['x'])/pncol] if len(ubl_sort['x'])/pncol >=1 else ubl_sort['x']\n",
    "\tfigure = {}\n",
    "#\t\tplt.figure(400)\n",
    "#\t\tplt.subplots_adjust(hspace=1.2,wspace=0.7)\n",
    "\tfor p in range(2):\n",
    "#\t\t\tplt.figure(400+10*p)\n",
    "#\t\t\tplt.subplots_adjust(hspace=1.2,wspace=0.7)\n",
    "#\t\t\tfor nu, u in enumerate(us):\n",
    "#\t\t\t\t\n",
    "#\t\t\t\tplt.subplot(5, (len(us) + 4) / 5, nu + 1)\n",
    "#\t\t\t\tplt.plot(srt, fun(cdata[u, p][asrt]))\n",
    "#\t\t\t\tplt.plot(srt, fun(fullsim_vis[u, p][asrt]))\n",
    "#\t\t\t\tplt.plot(srt, fun(crdata[u, p][asrt]))\n",
    "#\t\t\t\tplt.plot(srt, fun(cNi[u, p][asrt])**-.5)\n",
    "#\t\t\t\tif pre_calibrate:\n",
    "#\t\t\t\t\tplt.plot(srt, fun(cadd[u, p][asrt]))\n",
    "#\t\t\t\tdata_range = np.max([np.max(np.abs(fun(cdata[u, p]))), np.max(np.abs(fun(crdata[u, p]))), np.max(np.abs(fun(fullsim_vis[u, p]))), 5 * np.max(np.abs(fun(cNi[u, p]))), np.max(fun(cadd[u, p]))])\n",
    "#\t\t\t\tplt.title(\"%s Baseline-%.1f_%.1f results on srtime\"%(['xx','yy'][p], used_common_ubls[u, 0], used_common_ubls[u, 1]))\n",
    "#\t\t\t\tplt.ylim([-1.05*data_range, 1.05*data_range])\t\t\n",
    "#\t\t\tplt.savefig(script_dir + '/../Output/%s-dipole-precal_data_error-fullvis-%s-%.2f-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, ['xx','yy'][p], beam_freqs[ind], bnside, nside_standard))\n",
    "#\t\t\tplt.show(block=False)\n",
    "\t\t\n",
    "\t\t#plt.figure(500+10*p)\n",
    "\t\t#plt.subplots_adjust(hspace=1.2,wspace=0.7)\n",
    "\t\tfor nu, u in enumerate(us):\n",
    "\t\t\tplt.figure(5000+100*p+nu)\n",
    "\t\t\t#plt.subplot(5, (len(us) + 4) / 5, nu + 1)\n",
    "\t\t\tfigure[1], = plt.plot(srt, fun(cdata[u, p][asrt]), label='calibrated_data')\n",
    "\t\t\tfigure[2], = plt.plot(srt, fun(fullsim_vis[u, p][asrt]), label='fullsim_vis')\n",
    "\t\t\tfigure[3], = plt.plot(srt, fun(crdata[u, p][asrt]), '+', label='raw_data')\n",
    "\t\t\tfigure[4], = plt.plot(srt, fun(cNi[u, p][asrt])**-.5, label='Ni')\n",
    "\t\t\tif pre_calibrate:\n",
    "\t\t\t\tfigure[5], = plt.plot(srt, fun(cadd[u, p][asrt]), label='additive')\n",
    "\t\t\t\tdata_range = np.max([np.max(np.abs(fun(cdata[u, p]))), np.max(np.abs(fun(crdata[u, p]))), np.max(np.abs(fun(fullsim_vis[u, p]))), np.max(fun(cadd[u, p]))]) #5 * np.max(np.abs(fun(cNi[u, p]))),\n",
    "\t\t\telse:\n",
    "\t\t\t\tdata_range = np.max([np.max(np.abs(fun(cdata[u, p]))), np.max(np.abs(fun(crdata[u, p]))), np.max(np.abs(fun(fullsim_vis[u, p])))]) #5 * np.max(np.abs(fun(cNi[u, p])))\n",
    "\t\t\tplt.title(\"%s Baseline-%.1f_%.1f results on srtime\"%(['xx','yy'][p], used_common_ubls[u, 0], used_common_ubls[u, 1]))\n",
    "\t\t\tplt.ylim([-1.05*data_range, 1.05*data_range])\n",
    "\t\t\tif pre_calibrate:\n",
    "\t\t\t\tplt.legend(handles=[figure[1], figure[2], figure[3], figure[4], figure[5]], labels=['calibrated_data', 'fullsim_vis', 'raw_data', 'noise', 'additive'], loc=0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tplt.legend(handles=[figure[1], figure[2], figure[3], figure[4]], labels=['calibrated_data', 'fullsim_vis', 'raw_data', 'noise'], loc=0)\n",
    "\t\t\tplt.savefig(script_dir + '/../Output/%s-Baseline-%.1f_%.1f-dipole-precal_data_error-Full_vis-%s-%.2f-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, used_common_ubls[u, 0], used_common_ubls[u, 1], ['xx','yy'][p], freq, bnside, nside_standard))\n",
    "\t\t\tplt.show(block=False)\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t#plt.gcf().clear()\n",
    "\t\t#plt.clf()\n",
    "\t\t#plt.close()\n",
    "\n",
    "Del=True\n",
    "if Del:\n",
    "\ttry:\n",
    "\t\tdel(crdata)\n",
    "\t\tdel(cNi)\n",
    "\t\tdel(cdata)\n",
    "\t\tdel(cadd)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\t\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "####Use N and the par file generated by pixel_parameter_search to determine dynamic pixel parameters\n",
    "################\n",
    "if seek_optimal_threshs:\n",
    "\tpar_result_filename = full_sim_filename.replace('.simvis', '_par_search.npz')\n",
    "\tpar_file = np.load(par_result_filename)\n",
    "\tqualified_par_mask = (par_file['err_norm'] / np.sum(1./Ni)**.5) < dynamic_precision\n",
    "\tindex_min_pix_in_mask = np.argmin(par_file['n_pix'][qualified_par_mask])\n",
    "\tthresh, valid_pix_thresh = par_file['parameters'][qualified_par_mask][index_min_pix_in_mask]\n",
    "print \"<<<<<<<<<<<<picked std thresh %.3f, pix thresh %.1e\"%(thresh, valid_pix_thresh)\n",
    "\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "########################processing dynamic pixelization######################\n",
    "########################################################################\n",
    "gsm_beamweighted = equatorial_GSM_standard * beam_weight\n",
    "if AtNiA_only:\n",
    "\tvalid_npix = pixel_scheme_number\n",
    "\tpixel_scheme_file = np.load(pixel_directory + 'pixel_scheme_%i_%s.npz'%(valid_npix,freq))\n",
    "\tfake_solution_map = pixel_scheme_file['gsm']\n",
    "\tthetas = pixel_scheme_file['thetas']\n",
    "\tphis= pixel_scheme_file['phis']\n",
    "\tsizes= pixel_scheme_file['sizes']\n",
    "\tnside_distribution= pixel_scheme_file['nside_distribution']\n",
    "\tfinal_index= pixel_scheme_file['final_index']\n",
    "\tnpix = pixel_scheme_file['n_fullsky_pix']\n",
    "\tvalid_pix_mask= pixel_scheme_file['valid_pix_mask']\n",
    "\tthresh= pixel_scheme_file['thresh']\n",
    "else:\n",
    "\tnside_distribution = np.zeros(12 * nside_standard ** 2)\n",
    "\tfinal_index = np.zeros(12 * nside_standard ** 2, dtype=int)\n",
    "\tthetas, phis, sizes = [], [], []\n",
    "\tabs_thresh = np.mean(gsm_beamweighted) * thresh\n",
    "\tpixelize(gsm_beamweighted, nside_distribution, nside_standard, nside_start, abs_thresh,\n",
    "\t\t\t final_index, thetas, phis, sizes)\n",
    "\tnpix = len(thetas)\n",
    "\tvalid_pix_mask = hpf.get_interp_val(gsm_beamweighted, thetas, phis, nest=True) > valid_pix_thresh * max(gsm_beamweighted)\n",
    "\tvalid_npix = np.sum(valid_pix_mask)\n",
    "\tprint '>>>>>>VALID NPIX =', valid_npix\n",
    "\n",
    "\tfake_solution_map = np.zeros_like(thetas)      \n",
    "\tfor i in range(len(fake_solution_map)):\n",
    "\t\tfake_solution_map[i] = np.sum(equatorial_GSM_standard[final_index == i])\n",
    "\tfake_solution_map = fake_solution_map[valid_pix_mask]\n",
    "\tsizes = np.array(sizes)[valid_pix_mask]\n",
    "\tthetas = np.array(thetas)[valid_pix_mask]\n",
    "\tphis = np.array(phis)[valid_pix_mask]\n",
    "\tnp.savez(pixel_directory + 'pixel_scheme_%i_%s.npz'%(valid_npix,freq), gsm=fake_solution_map, thetas=thetas, phis=phis, sizes=sizes, nside_distribution=nside_distribution, final_index=final_index, n_fullsky_pix=npix, valid_pix_mask=valid_pix_mask, thresh=thresh)#thresh is in there for idiotic reason  due to unneccessary inclusion of thresh in A filename\n",
    "\n",
    "if not fit_for_additive:\n",
    "\tfake_solution = np.copy(fake_solution_map)\n",
    "else:\n",
    "\tfake_solution = np.concatenate((fake_solution_map, np.zeros(4 * nUBL_used)))\n",
    "\n",
    "def sol2map(sol):\n",
    "\tsolx = sol[:valid_npix]\n",
    "\tfull_sol = np.zeros(npix)\n",
    "\tfull_sol[valid_pix_mask] = solx / sizes\n",
    "\treturn full_sol[final_index]\n",
    "\n",
    "def sol2additive(sol):\n",
    "\treturn np.transpose(sol[valid_npix:].reshape(nUBL_used, 2, 2), (1, 0, 2))#ubl by pol by re/im before transpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_index_filename = datadir + tag + '_%i.dyind%i_%.3f'%(nside_standard, npix, thresh)\n",
    "# final_index.astype('float32').tofile(final_index_filename)\n",
    "# sizes_filename = final_index_filename.replace('dyind', \"dysiz\")\n",
    "# np.array(sizes).astype('float32').tofile(sizes_filename)\n",
    "if plot_pixelization:\n",
    "\t##################################################################\n",
    "\t####################################sanity check########################\n",
    "\t###############################################################\n",
    "\t# npix = 0\n",
    "\t# for i in nside_distribution:\n",
    "\t# npix += i**2/nside_standard**2\n",
    "\t# print npix, len(thetas)\n",
    "\tstds = np.std((equatorial_GSM_standard * beam_weight).reshape(12 * nside_standard ** 2 / 4, 4), axis=1)\n",
    "\tplotcoord = 'CG'\n",
    "    \n",
    "\t##################################################################\n",
    "\t####################################plotting########################\n",
    "\t###############################################################\n",
    "\twith warnings.catch_warnings():\n",
    "\t\twarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\t\t#plt.clf()\n",
    "\t\tplt.figure(50)\n",
    "\t\thpv.mollview(beam_weight, min=0, max=4, coord=plotcoord, title='%s-dipole-beam_weight-bnside-%s-nside_standard-%s'%(INSTRUMENT, bnside, nside_standard), nest=True)\n",
    "\t\tplt.savefig(script_dir + '/../Output/%s-%s-dipole-beam_weight-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "\t\thpv.mollview(np.log10(equatorial_GSM_standard), min=0, max=4, coord=plotcoord, title='GSM', nest=True)\n",
    "\t\tplt.savefig(script_dir + '/../Output/GSM-3C-for-%s-%s-bnside-%s.pdf'%(INSTRUMENT, freq, bnside))\n",
    "\t\thpv.mollview(np.log10(sol2map(fake_solution)[:len(equatorial_GSM_standard)]), min=0, max=4, coord=plotcoord,\n",
    "\t\t\t\t\t title='GSM gridded', nest=True)\n",
    "\t\tplt.savefig(script_dir + '/../Output/maskedfsol_GSM-3C-%s-%s-dipole-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "\t\thpv.mollview(np.log2(nside_distribution), min=np.log2(nside_start), max=np.log2(nside_standard),\n",
    "\t\t\t\t\t coord=plotcoord,\n",
    "\t\t\t\t\t title='nside_distribution(count %i %.3f)' % (len(thetas), float(len(thetas)) / (12 * nside_standard ** 2)), nest=True)\n",
    "\t\tplt.savefig(script_dir + '/../Output/nside_distribution-%s-%s-dipole-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "\t\thpv.mollview(np.log10(stds / abs_thresh), min=np.log10(thresh) - 3, max=3, coord=plotcoord, title='std',\n",
    "\t\t\t\t\t nest=True)\n",
    "\t\tplt.savefig(script_dir + '/../Output/stds-beam_weight_GSM-%s-%s-dipole-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "\t\tplt.show(block=False)\n",
    "\t\t#plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_pixelization:\n",
    "\t##################################################################\n",
    "\t####################################sanity check########################\n",
    "\t###############################################################\n",
    "\t# npix = 0\n",
    "\t# for i in nside_distribution:\n",
    "\t# npix += i**2/nside_standard**2\n",
    "\t# print npix, len(thetas)\n",
    "\n",
    "\tstds = np.std((equatorial_GSM_standard * beam_weight).reshape(12 * nside_standard ** 2 / 4, 4), axis=1)\n",
    "\tplotcoord = 'C'\n",
    "\t##################################################################\n",
    "\t####################################plotting########################\n",
    "\t###############################################################\n",
    "\twith warnings.catch_warnings():\n",
    "\t\twarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\t\t#plt.clf()\n",
    "\t\tplt.figure(50)\n",
    "\t\thpv.mollview(beam_weight, min=0, max=4, coord=plotcoord, title='%s-dipole-beam_weight-bnside-%s-nside_standard-%s'%(INSTRUMENT, bnside, nside_standard), nest=True)\n",
    "\t\tplt.savefig(script_dir + '/../Output/%s-%s-dipole-beam_weight-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "\t\thpv.mollview(np.log10(equatorial_GSM_standard), min=0, max=4, coord=plotcoord, title='GSM', nest=True)\n",
    "\t\tplt.savefig(script_dir + '/../Output/GSM-3C-for-%s-%s-bnside-%s.pdf'%(INSTRUMENT, freq, bnside))\n",
    "\t\thpv.mollview(np.log10(sol2map(fake_solution)[:len(equatorial_GSM_standard)]), min=0, max=4, coord=plotcoord,\n",
    "\t\t\t\t\t title='GSM gridded', nest=True)\n",
    "\t\tplt.savefig(script_dir + '/../Output/maskedfsol_GSM-3C-%s-%s-dipole-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "\t\thpv.mollview(np.log2(nside_distribution), min=np.log2(nside_start), max=np.log2(nside_standard),\n",
    "\t\t\t\t\t coord=plotcoord,\n",
    "\t\t\t\t\t title='nside_distribution(count %i %.3f)' % (len(thetas), float(len(thetas)) / (12 * nside_standard ** 2)), nest=True)\n",
    "\t\tplt.savefig(script_dir + '/../Output/nside_distribution-%s-%s-dipole-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "\t\thpv.mollview(np.log10(stds / abs_thresh), min=np.log10(thresh) - 3, max=3, coord=plotcoord, title='std',\n",
    "\t\t\t\t\t nest=True)\n",
    "\t\tplt.savefig(script_dir + '/../Output/stds-beam_weight_GSM-%s-%s-dipole-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "\t\tplt.show(block=False)\n",
    "\t\t#plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "####################compute dynamic A matrix########################\n",
    "###############################################################\n",
    "A_tag = 'A_dI'\n",
    "A_filename = A_tag + '_u%i_t%i_p%i_n%i_%i_b%i_%.3f_v%.1f' % (nUBL_used, nt_used, valid_npix, nside_start, nside_standard, bnside, thresh, A_version)\n",
    "A_path = datadir + tag + A_filename\n",
    "AtNiA_tag = 'AtNiA_N%s'%vartag\n",
    "if not fit_for_additive:\n",
    "\tAtNiA_tag += \"_noadd\"\n",
    "elif crosstalk_type == 'autocorr':\n",
    "\tAtNiA_tag += \"_autocorr\"\n",
    "if pre_ampcal:\n",
    "\tAtNiA_tag += \"_ampcal\"\n",
    "AtNiA_filename = AtNiA_tag + A_filename\n",
    "AtNiA_path = datadir + tag + AtNiA_filename\n",
    "if os.path.isfile(AtNiA_path) and AtNiA_only and not force_recompute:\n",
    "\tsys.exit(0)\n",
    "\n",
    "\n",
    "def get_A(additive_A=None):\n",
    "\tif os.path.isfile(A_path) and not force_recompute:\n",
    "\t\tprint \"Reading A matrix from %s\" % A_path\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tA = np.fromfile(A_path, dtype='complex128').reshape((nUBL_used, 2, nt_used, valid_npix + 4 * nUBL_used))\n",
    "\telse:\n",
    "\n",
    "\t\tprint \"Computing A matrix...\"\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tA = np.empty((nUBL_used, 2, nt_used, valid_npix + 4 * nUBL_used), dtype='complex128')\n",
    "\t\ttimer = time.time()\n",
    "\t\tfor n in range(valid_npix):\n",
    "\t\t\tra = phis[n]\n",
    "\t\t\tdec = PI / 2 - thetas[n]\n",
    "\t\t\tprint \"\\r%.1f%% completed, %f minutes left\" % (\n",
    "\t\t\t100. * float(n) / (valid_npix), float(valid_npix - n) / (n + 1) * (float(time.time() - timer) / 60.)),\n",
    "\t\t\tsys.stdout.flush()\n",
    "\n",
    "\t\t\tA[:, 0, :, n] = vs.calculate_pointsource_visibility(ra, dec, used_common_ubls, freq, beam_heal_equ=beam_heal_equ_x, tlist=lsts) / 2 #xx and yy are each half of I\n",
    "\t\t\tA[:, -1, :, n] = vs.calculate_pointsource_visibility(ra, dec, used_common_ubls, freq, beam_heal_equ=beam_heal_equ_y, tlist=lsts) / 2\n",
    "\n",
    "\n",
    "\n",
    "\t\tprint \"%f minutes used\" % (float(time.time() - timer) / 60.)\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tA.tofile(A_path)\n",
    "\n",
    "\t# #put in autocorr regardless of whats saved on disk\n",
    "\t# for i in range(nUBL_used):\n",
    "\t#     for p in range(2):\n",
    "\t#         A[i, p, :, valid_npix + 4 * i + 2 * p] = 1. * autocorr_vis_normalized[p]\n",
    "\t#         A[i, p, :, valid_npix + 4 * i + 2 * p + 1] = 1.j * autocorr_vis_normalized[p]\n",
    "\n",
    "\tA.shape = (nUBL_used * 2 * nt_used, A.shape[-1])\n",
    "\tif not fit_for_additive:\n",
    "\t\tA = A[:, :valid_npix]\n",
    "\telse:\n",
    "\t\tA[:, valid_npix:] = additive_A[:, 1:]\n",
    "\t# Merge A\n",
    "\ttry:\n",
    "\t\treturn np.concatenate((np.real(A), np.imag(A))).astype('complex128')\n",
    "\texcept MemoryError:\n",
    "\t\tprint \"Not enough memory, concatenating A on disk \", A_path + 'tmpre', A_path + 'tmpim',\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tAshape = list(A.shape)\n",
    "\t\tAshape[0] = Ashape[0] * 2\n",
    "\t\tnp.real(A).tofile(A_path + 'tmpre')\n",
    "\t\tnp.imag(A).tofile(A_path + 'tmpim')\n",
    "\t\tdel (A)\n",
    "\t\tos.system(\"cat %s >> %s\" % (A_path + 'tmpim', A_path + 'tmpre'))\n",
    "\n",
    "\t\tos.system(\"rm %s\" % (A_path + 'tmpim'))\n",
    "\t\tA = np.fromfile(A_path + 'tmpre', dtype='complex128').reshape(Ashape)\n",
    "\t\tos.system(\"rm %s\" % (A_path + 'tmpre'))\n",
    "\t\tprint \"done.\"\n",
    "\t\tsys.stdout.flush()\n",
    "\t\treturn A.astype('complex128')\n",
    "\n",
    "if not fit_for_additive:\n",
    "\tA = get_A()\n",
    "else:\n",
    "\tA = get_A(additive_A)\n",
    "\t\n",
    "Ashape0, Ashape1 = A.shape\n",
    "\n",
    "# for ipix in hpf.ang2pix(nside_standard, thetas, phis, nest=True):\n",
    "#     if\n",
    "\n",
    "print \"Memory usage: %.3fMB\" % (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1000)\n",
    "sys.stdout.flush()\n",
    "\n",
    "print \"Memory usage: %.3fMB\" % (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1000)\n",
    "sys.stdout.flush()\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "def get_vis_normalization(data, clean_sim_data):\n",
    "\ta = np.linalg.norm(data.reshape(2, data_shape['xx'][0], 2, data_shape['xx'][1]), axis=0).flatten()\n",
    "\tb = np.linalg.norm(clean_sim_data.reshape(2, data_shape['xx'][0], 2, data_shape['xx'][1]), axis=0).flatten()\n",
    "\treturn a.dot(b) / b.dot(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Integration_Time\n",
    "np.sum(Ni**-1)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# simulate visibilities according to the pixelized A matrix\n",
    "##############\n",
    "clean_sim_data = A.dot(fake_solution.astype(A.dtype))\n",
    "\n",
    "if plot_data_error:\n",
    "\tcdata = get_complex_data(data)\n",
    "\tcdynamicmodel = get_complex_data(clean_sim_data)\n",
    "\tcNi = get_complex_data(Ni)\n",
    "\tif pre_calibrate:\n",
    "\t\tcadd = get_complex_data(additive_term)\n",
    "\n",
    "\tfun = np.imag\n",
    "\tsrt = sorted((lsts - lst_offset)%24.+lst_offset)\n",
    "\tasrt = np.argsort((lsts - lst_offset)%24.+lst_offset)\n",
    "\tpncol = min(int(60. / (srt[-1] - srt[0])), 12) if nt_used > 1 else (len(ubl_sort['x'])/2)\n",
    "\tus = ubl_sort['x'][::len(ubl_sort['x'])/pncol] if len(ubl_sort['x'])/pncol >=1 else ubl_sort['x']\n",
    "\t#plt.clf()\n",
    "#\tplt.figure(60)\n",
    "#\tfor p in range(2):\n",
    "#\t\tfor nu, u in enumerate(us):\n",
    "#\n",
    "#\t\t\tplt.subplot(2, len(us), len(us) * p + nu + 1)\n",
    "#\t\t\tplt.plot(srt, fun(cdata[u, p][asrt]))\n",
    "#\t\t\tplt.plot(srt, fun(fullsim_vis[u, p][asrt]))\n",
    "#\t\t\tplt.plot(srt, fun(cdynamicmodel[u, p][asrt]))\n",
    "#\t\t\tplt.plot(srt, fun(cNi[u, p][asrt])**-.5)\n",
    "#\t\t\tif pre_calibrate:\n",
    "#\t\t\t\tplt.plot(srt, fun(cadd[u, p][asrt]))\n",
    "#\t\t\tdata_range = np.max([np.max(np.abs(fun(cdata[u, p]))), np.max(np.abs(fun(fullsim_vis[u, p]))), 5 * np.max(np.abs(fun(cNi[u, p])))])\n",
    "#\t\t\tplt.title(\"%.1f,%.1f\"%(used_common_ubls[u, 0], used_common_ubls[u, 1]))\n",
    "#\t\t\tplt.ylim([-1.05*data_range, 1.05*data_range])\n",
    "#\n",
    "#\tprint \"total deviation between dynamic and full sim compared to sim\", la.norm(fullsim_vis - cdynamicmodel) / la.norm(fullsim_vis)\n",
    "#\tprint \"total deviation between dynamic and full sim compared to data noise\", la.norm(fullsim_vis - cdynamicmodel) / np.sum(Ni**-1)**.5\n",
    "#\tplt.savefig(script_dir + '/../Output/data_error_dynamic-%s-dipole-bnside-%s-nside_standard-%s.png'%(INSTRUMENT, bnside, nside_standard))\n",
    "#\tplt.show(block=False)\n",
    "\t\n",
    "\tfigure_D={}\n",
    "\tfor p in range(2):\n",
    "\t\tfor nu, u in enumerate(us):\n",
    "\t\t\tplt.figure(6000+100*p+nu)\n",
    "\t\t\t#plt.subplot(2, len(us), len(us) * p + nu + 1)\n",
    "\t\t\tfigure_D[1], = plt.plot(srt, fun(cdata[u, p][asrt]), label='calibrated_data')\n",
    "\t\t\tfigure_D[2], = plt.plot(srt, fun(fullsim_vis[u, p][asrt]), label='fullsim_vis')\n",
    "\t\t\tfigure_D[3], = plt.plot(srt, fun(cdynamicmodel[u, p][asrt]), '+', label='dynsim_vis')\n",
    "\t\t\tfigure_D[4], = plt.plot(srt, fun(cNi[u, p][asrt])**-.5, label='Ni')\n",
    "\t\t\tif pre_calibrate:\n",
    "\t\t\t\tfigure_D[5], = plt.plot(srt, fun(cadd[u, p][asrt]), label='additive')\n",
    "\t\t\t\tdata_range = np.max([np.max(np.abs(fun(cdata[u, p]))), np.max(np.abs(fun(fullsim_vis[u, p]))), np.max(np.abs(fun(cdynamicmodel[u, p]))), np.max(fun(cadd[u, p]))]) # 5 * np.max(np.abs(fun(cNi[u, p])))\n",
    "\t\t\telse:\t\n",
    "\t\t\t\tdata_range = np.max([np.max(np.abs(fun(cdata[u, p]))), np.max(np.abs(fun(fullsim_vis[u, p]))), np.max(np.abs(fun(cdynamicmodel[u, p])))]) # 5 * np.max(np.abs(fun(cNi[u, p])))\n",
    "\t\t\tplt.title(\"Dynamic-Sim %s Baseline-%.1f_%.1f results on srtime\"%(['xx','yy'][p], used_common_ubls[u, 0], used_common_ubls[u, 1]))\n",
    "\t\t\tplt.ylim([-1.05*data_range, 1.05*data_range])\n",
    "\t\t\tif pre_calibrate:\n",
    "\t\t\t\tplt.legend(handles=[figure_D[1], figure_D[2], figure_D[3], figure_D[4], figure_D[5]], labels=['calibrated_data', 'fullsim_vis', 'dynsim_vis', 'noise', 'additive'], loc=0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tplt.legend(handles=[figure_D[1], figure_D[2], figure_D[3], figure_D[4]], labels=['calibrated_data', 'fullsim_vis', 'dynsim_vis', 'noise'], loc=0)\n",
    "\t\t\tplt.savefig(script_dir + '/../Output/%s-Baseline-%.1f_%.1f-dipole-precal_data_error-Dynamic_Vis-%s-%.2f-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, used_common_ubls[u, 0], used_common_ubls[u, 1], ['xx','yy'][p], freq, bnside, nside_standard))\n",
    "\t\t\tplt.show(block=False)\n",
    "\t\t\t#plt.clf()\n",
    "\t\t\t#plt.gcf().clear()\n",
    "\tprint \"total deviation between dynamic and full sim compared to sim: \", la.norm(fullsim_vis - cdynamicmodel) / la.norm(fullsim_vis)\n",
    "\tprint \"total deviation between dynamic and full sim compared to data noise: \", la.norm(fullsim_vis - cdynamicmodel) / np.sum(Ni**-1)**.5\n",
    "\t\n",
    "\tplt.figure(70)\n",
    "\ttry:\n",
    "\t\tfullsim_vis2 = 4 * np.fromfile(datadir + tag + '_p2_u%i_t%i_nside%i_bnside%i.simvis'%(nUBL_used+1, nt_used, nside_standard / 2, bnside), dtype='complex128').reshape((2, nUBL_used+1, nt_used))[:, :-1].transpose((1, 0 ,2))\n",
    "\t\tplt.plot(la.norm(used_common_ubls, axis=-1)*freq/C, la.norm(fullsim_vis - fullsim_vis2, axis=-1)[:, 0] / la.norm(fullsim_vis, axis=-1)[:, 0], 'g+', label='nside error(%s-dipole-beam_weight-bnside-%s-nside_standard-%s)'%(INSTRUMENT, bnside, nside_standard))\n",
    "\t\tplt.savefig(script_dir + '/../Output/nside_error-%s-dipole-beam_weight-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, bnside, nside_standard))\n",
    "\texcept:\n",
    "\t\ttry:\n",
    "\t\t\tfullsim_vis2 = .25 * np.fromfile(datadir + tag + '_p2_u%i_t%i_nside%i_bnside%i.simvis'%(nUBL_used+1, nt_used, nside_standard * 2, bnside), dtype='complex128').reshape((2, nUBL_used+1, nt_used))[:, :-1].transpose((1, 0 ,2))\n",
    "\t\t\tplt.plot(la.norm(used_common_ubls, axis=-1)*freq/C, la.norm(fullsim_vis - fullsim_vis2, axis=-1)[:, 0] / la.norm(fullsim_vis, axis=-1)[:, 0], 'g+', label='nside error(%s-dipole-beam_weight-bnside-%s-nside_standard-%s)'%(INSTRUMENT, bnside, nside_standard))\n",
    "\t\t\tplt.savefig(script_dir + '/../Output/nside_error-%s-dipole-beam_weight-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, bnside, nside_standard))\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\t#plt.clf()\n",
    "\tplt.plot(la.norm(used_common_ubls, axis=-1)*freq/C, np.sum(2. / np.real(get_complex_data(Ni)), axis=-1)[:, 0]**.5 / la.norm(fullsim_vis, axis=-1)[:, 0], 'b+', label='noise error(%s-%s-dipole-beam_weight-bnside-%s-nside_standard-%s)'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "#\tplt.legend()\n",
    "#\tplt.xlabel('Baseline Length (wavelength)')\n",
    "#\tplt.ylabel('Relative RMS Error')\n",
    "\tplt.savefig(script_dir + '/../Output/noise_error-%s-dipole-beam_weight-bnside-%s-nside_standard-%s.png'%(INSTRUMENT, bnside, nside_standard))\n",
    "#\tplt.show(block=False)\n",
    "#\tplt.gcf().clear()\n",
    "\t#plt.clf()\n",
    "\tplt.plot(la.norm(used_common_ubls, axis=-1)*freq/C, la.norm(fullsim_vis - cdynamicmodel, axis=-1)[:, 0] / la.norm(fullsim_vis, axis=-1)[:, 0], 'r+', label='dynamic pixel error(%s-%s-dipole-beam_weight-bnside-%s-nside_standard-%s)'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "\tplt.legend(loc=0)\n",
    "\tplt.xlabel('Baseline Length (wavelength)')\n",
    "\tplt.ylabel('Relative RMS Error')\n",
    "\tplt.savefig(script_dir + '/../Output/dynamic_pixel_error-%s-dipole-beam_weight-bnside-%s-nside_standard-%s.png'%(INSTRUMENT, bnside, nside_standard))\n",
    "\tplt.show(block=False)\n",
    "\t#plt.gcf().clear()\n",
    "\n",
    "\n",
    "vis_normalization = get_vis_normalization(data, stitch_complex_data(fullsim_vis))\n",
    "print \"Normalization from visibilities\", vis_normalization\n",
    "\n",
    "Del=True\n",
    "if Del:\n",
    "\ttry:\n",
    "\t\tdel(cdata)\n",
    "\t\tdel(cNi)\n",
    "\t\tdel(cdynamicmodel)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##renormalize the model\n",
    "fake_solution *= vis_normalization # GSM Masked and being Normalized (abs calibration), Clean\n",
    "clean_sim_data *= vis_normalization # Dynamic Simulated, Clean, being Normalized (abs calibration)\n",
    "fullsim_vis *= vis_normalization # Full Simulated, Clean, being Normalized (abs calibration)\n",
    "sim_data = stitch_complex_data(fullsim_vis) + np.random.randn(len(data)) / Ni ** .5 # Full Simulated, being Normalized (abs calibration), Noise\n",
    "# \"data\" is Calibrated Full Simulated Visibilities\n",
    "\n",
    "#add additive term\n",
    "if fit_for_additive:\n",
    "\tsim_data.shape = (2, nUBL_used, 2, nt_used)\n",
    "\tsim_additive = np.random.randn(2, nUBL_used, 2) * np.median(np.abs(data)) / 2.\n",
    "\tsim_data = sim_data + np.array([np.outer(sim_additive[..., p], autocorr_vis_normalized[p]).reshape((2, nUBL_used, nt_used)) for p in range(2)]).transpose((1, 2, 0, 3))#sim_additive[..., None]\n",
    "\tsim_data = sim_data.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute AtNi.y\n",
    "AtNi_data = np.transpose(A).dot((data * Ni).astype(A.dtype))\n",
    "AtNi_sim_data = np.transpose(A).dot((sim_data * Ni).astype(A.dtype))\n",
    "AtNi_clean_sim_data = np.transpose(A).dot((clean_sim_data * Ni).astype(A.dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute S\n",
    "print \"computing S...\",\n",
    "sys.stdout.flush()\n",
    "timer = time.time()\n",
    "\n",
    "#diagonal of S consists of S_diag_I and S-diag_add\n",
    "if S_type == 'none':\n",
    "\tS_diag = np.ones(Ashape1) * np.max(equatorial_GSM_standard)**2 * 1.e12\n",
    "else:\n",
    "\tif 'lowI' in S_type:\n",
    "\t\tI_supress = 25.\n",
    "\telif 'minI' in S_type:\n",
    "\t\tI_supress = 250.\n",
    "\telif 'min2I' in S_type:\n",
    "\t\tI_supress = 2500\n",
    "\telif 'min3I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e4\n",
    "\telif 'min4I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e5\n",
    "\telif 'min5I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e6\n",
    "\telif 'min6I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e7\n",
    "\telif 'min7I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e8\n",
    "\telif 'min8I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e9\n",
    "\telif 'min9I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e10\n",
    "\telif 'min10I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e11\n",
    "\telif 'min11I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e12\n",
    "\telif 'min12I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e13\n",
    "\telif 'min13I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e14\n",
    "\telif 'min14I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e15\n",
    "\telif 'min15I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e16\n",
    "\telif 'min16I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e17\n",
    "\telif 'min17I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e18\n",
    "\telif 'min18I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e19\n",
    "\telif 'min19I' in S_type:\n",
    "\t\tI_supress = 2.5 * 1.e20\n",
    "\telif 'min20I' in S_type:\n",
    "\t\tI_supress = 2.5 * 1.e21\n",
    "\telif 'min21I' in S_type:\n",
    "\t\tI_supress = 2.5 * 1.e22\n",
    "\telif 'min22I' in S_type:\n",
    "\t\tI_supress = 2.5 * 1.e23\n",
    "\telif 'maxI' in S_type:\n",
    "\t\tI_supress = 2.5*1.e-1\n",
    "\telif 'ma2I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e-2\n",
    "\telif 'max3I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e-3\n",
    "\telif 'max4I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e-4\n",
    "\telif 'max5I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e-5\n",
    "\telif 'max6I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e-6\n",
    "\telif 'max7I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e-7\n",
    "\telif 'max8I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e-8\n",
    "\telif 'max9I' in S_type:\n",
    "\t\tI_supress = 2.5*1.e-9\n",
    "\telse:\n",
    "\t\tI_supress = 1.\n",
    "\t\t\n",
    "\tif 'Iuniform' in S_type:\n",
    "\t\tS_diag_I = (np.median(equatorial_GSM_standard) * sizes)**2 / I_supress\n",
    "\telse:\n",
    "\t\tS_diag_I = fake_solution_map ** 2 / I_supress  # np.array([[1+pol_frac,0,0,1-pol_frac],[0,pol_frac,pol_frac,0],[0,pol_frac,pol_frac,0],[1-pol_frac,0,0,1+pol_frac]]) / 4 * (2*sim_x_clean[i])**2\n",
    "\n",
    "\tdata_max = np.transpose(np.percentile(np.abs(data.reshape((2, nUBL_used, 2, nt_used))), 95, axis=-1), (1, 2, 0)).flatten()\n",
    "\tif 'min2add' in S_type:\n",
    "\t\tadd_supress = 1000000.\n",
    "\telif 'minadd' in S_type:\n",
    "\t\tadd_supress = 10000.\n",
    "\telif 'lowadd' in S_type:\n",
    "\t\tadd_supress = 100.\n",
    "\telse:\n",
    "\t\tadd_supress = 1\n",
    "\n",
    "\tif 'adduniform' in S_type:\n",
    "\t\tS_diag_add = np.ones(nUBL_used * 4) * np.median(data_max)**2 / add_supress\n",
    "\telse:\n",
    "\t\tS_diag_add = data_max**2 / add_supress\n",
    "\n",
    "\tif not fit_for_additive:\n",
    "\t\tS_diag = S_diag_I.astype('complex128')\n",
    "\telse:\n",
    "\t\tS_diag = np.concatenate((S_diag_I, S_diag_add)).astype('complex128')\n",
    "\tprint \"Done.\"\n",
    "\tprint \"%f minutes used\" % (float(time.time() - timer) / 60.)\n",
    "\tsys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute (AtNiA+Si)i\n",
    "precision = 'complex128'\n",
    "AtNiAi_tag = 'AtNiASii'\n",
    "if not fit_for_additive:\n",
    "\tAtNiAi_version = 0.3\n",
    "elif crosstalk_type == 'autocorr':\n",
    "\tAtNiAi_version = 0.2\n",
    "else:\n",
    "\tAtNiAi_version = 0.1\n",
    "if pre_ampcal:\n",
    "\tAtNiAi_version += 1.\n",
    "# rcond_list = 10.**np.arange(-3., -0., 1.)\n",
    "\n",
    "AtNiAi_candidate_files = glob.glob(datadir + tag + AtNiAi_tag + '_S%s_RE*_N%s_v%.1f'%(S_type, vartag, AtNiAi_version) + A_filename)\n",
    "if len(AtNiAi_candidate_files) > 0 and not force_recompute_AtNiAi and not force_recompute and not force_recompute_S and not AtNiA_only:\n",
    "\trcond = 10**min([float(fn.split('_RE')[1].split('_N')[0]) for fn in AtNiAi_candidate_files])\n",
    "\n",
    "\tAtNiAi_filename = AtNiAi_tag + '_S%s_RE%.1f_N%s_v%.1f'%(S_type, np.log10(rcond), vartag, AtNiAi_version) + A_filename\n",
    "\tAtNiAi_path = datadir + tag + AtNiAi_filename\n",
    "\n",
    "\tprint \"Reading Regularized AtNiAi...\",\n",
    "\tsys.stdout.flush()\n",
    "\tAtNiAi = sv.InverseCholeskyMatrix.fromfile(AtNiAi_path, len(S_diag), precision)\n",
    "else:\n",
    "\tif os.path.isfile(AtNiA_path) and not force_recompute:\n",
    "\t\tprint \"Reading AtNiA...\",\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tAtNiA = np.fromfile(AtNiA_path, dtype=precision).reshape((Ashape1, Ashape1))\n",
    "\telse:\n",
    "\t\tprint \"Allocating AtNiA...\"\n",
    "\t\tsys.stdout.flush()\n",
    "\t\ttimer = time.time()\n",
    "\t\tAtNiA = np.zeros((A.shape[1], A.shape[1]), dtype=precision)\n",
    "\t\tprint \"Computing AtNiA...\", datetime.datetime.now()\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tATNIA(A, Ni, AtNiA)\n",
    "\t\tprint \"%f minutes used\" % (float(time.time() - timer) / 60.)\n",
    "\t\tsys.stdout.flush()\n",
    "\t\tAtNiA.tofile(AtNiA_path)\n",
    "\tif AtNiA_only:\n",
    "\t\tsys.exit(0)\n",
    "\tdel (A)\n",
    "\tAtNiA_diag = np.diagonal(AtNiA)\n",
    "\tprint \"Computing Regularized AtNiAi, %s, expected time %.1f min\"%(datetime.datetime.now(), 88. * (len(S_diag) / 4.6e4)**3.),\n",
    "\tsys.stdout.flush()\n",
    "\ttimer = time.time()\n",
    "\t# if la.norm(S) != la.norm(np.diagonal(S)):\n",
    "\t#     raise Exception(\"Non-diagonal S not supported yet\")\n",
    "\n",
    "\tfor rcond in rcond_list:\n",
    "\t\t#add Si on top of AtNiA without renaming AtNiA to save memory\n",
    "\t\tmaxAtNiA = np.max(AtNiA)\n",
    "\t\tAtNiA.shape = (len(AtNiA) ** 2)\n",
    "\t\tif Add_S_diag:\n",
    "\t\t\tAtNiA[::len(S_diag) + 1] += 1./S_diag\n",
    "\n",
    "\t\tprint 'trying', rcond,\n",
    "\t\tsys.stdout.flush()\n",
    "\t\ttry:\n",
    "\t\t\tAtNiAi_filename = AtNiAi_tag + '_S%s_RE%.1f_N%s_v%.1f'%(S_type, np.log10(rcond), vartag, AtNiAi_version) + A_filename\n",
    "\t\t\tAtNiAi_path = datadir + tag + AtNiAi_filename\n",
    "\t\t\tif Add_Rcond:\n",
    "\t\t\t\tAtNiA[::len(S_diag) + 1] += maxAtNiA * rcond\n",
    "\t\t\tAtNiA.shape = (Ashape1, Ashape1)\n",
    "\t\t\tAtNiAi = sv.InverseCholeskyMatrix(AtNiA).astype(precision)\n",
    "\t\t\tdel(AtNiA)\n",
    "\t\t\tAtNiAi.tofile(AtNiAi_path, overwrite=True)\n",
    "\t\t\tprint \"%f minutes used\" % (float(time.time() - timer) / 60.)\n",
    "\t\t\tprint \"regularization stength\", (maxAtNiA * rcond)**-.5, \"median GSM ranges between\", np.median(equatorial_GSM_standard) * min(sizes), np.median(equatorial_GSM_standard) * max(sizes)\n",
    "\t\t\tbreak\n",
    "\t\texcept:\n",
    "\t\t\tAtNiA[::len(S_diag) + 1] -= maxAtNiA * rcond\n",
    "\t\t\tcontinue\n",
    "\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_type\n",
    "I_supress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####apply wiener filter##############\n",
    "print \"Applying Regularized AtNiAi...\",\n",
    "sys.stdout.flush()\n",
    "w_solution = AtNiAi.dotv(AtNi_data)\n",
    "w_GSM = AtNiAi.dotv(AtNi_clean_sim_data)\n",
    "w_sim_sol = AtNiAi.dotv(AtNi_sim_data)\n",
    "print \"Memory usage: %.3fMB\" % (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss / 1000)\n",
    "sys.stdout.flush()\n",
    "\n",
    "del (AtNiAi)\n",
    "\n",
    "if not fit_for_additive:\n",
    "\tA = get_A()\n",
    "else:\n",
    "\tA = get_A(additive_A)\n",
    "\t\n",
    "best_fit = A.dot(w_solution.astype(A.dtype)) # Reversely-Calculated-masked-GSM Dynamically simulated Visibilities.\n",
    "best_fit_no_additive = A[..., :valid_npix].dot(w_solution[:valid_npix].astype(A.dtype))\n",
    "\n",
    "sim_best_fit = A.dot(w_sim_sol.astype(A.dtype))\n",
    "sim_best_fit_no_additive = A[..., :valid_npix].dot(w_sim_sol[:valid_npix].astype(A.dtype))\n",
    "\n",
    "if plot_data_error:\n",
    "\tqaz_model = (clean_sim_data).reshape(2, data_shape['xx'][0], 2, data_shape['xx'][1]) # Dynamic Simulated, Clean, being Normalized    # * vis_normalization\n",
    "\tqaz_data = np.copy(data).reshape(2, data_shape['xx'][0], 2, data_shape['xx'][1]) # Full Simulated, Calibrated, reference for normalization\n",
    "\tif pre_calibrate:\n",
    "\t\tqaz_add = np.copy(additive_term).reshape(2, data_shape['xx'][0], 2, data_shape['xx'][1])\n",
    "\tpncol = min(int(60. / (srt[-1] - srt[0])), 12) if nt_used > 1 else (len(ubl_sort['x'])/2)\n",
    "\tus = ubl_sort['x'][::len(ubl_sort['x'])/pncol] if len(ubl_sort['x'])/pncol >=1 else ubl_sort['x'] #[::max(1, len(ubl_sort['x'])/70)]\n",
    "\tbest_fit.shape = (2, data_shape['xx'][0], 2, data_shape['xx'][1])\n",
    "\tbest_fit_no_additive.shape = (2, data_shape['xx'][0], 2, data_shape['xx'][1])\n",
    "\tsim_best_fit.shape = (2, data_shape['xx'][0], 2, data_shape['xx'][1])\n",
    "\tri = 1\n",
    "\t#plt.clf()\n",
    "\n",
    "\tfigure_W = {}\n",
    "\tfor p in range(2):\n",
    "\t\t\n",
    "\t\tfor nu, u in enumerate(us):\n",
    "\t\t\tplt.figure(8000 + 10*p + nu)\n",
    "\t\t\t#plt.subplot(6, (len(us) + 5) / 6, nu + 1)\n",
    "\t\t\t# plt.errorbar(range(nt_used), qaz_data[ri, u, p], yerr=Ni.reshape((2, nUBL_used, 2, nt_used))[ri, u, p]**-.5)\n",
    "\t\t\tfigure_W[1], = plt.plot(qaz_data[ri, u, p],'+')\n",
    "\t\t\tfigure_W[2], = plt.plot(qaz_model[ri, u, p],'-')\n",
    "\t\t\tfigure_W[3], = plt.plot(best_fit[ri, u, p],'.')\n",
    "\t\t\tfigure_W[4], = plt.plot(sim_best_fit[ri, u, p])\n",
    "\t\t\tif pre_calibrate:\n",
    "\t\t\t\tfigure_W[5], = plt.plot(qaz_add[ri, u, p],'x')\n",
    "\t\t\tif fit_for_additive:\n",
    "\t\t\t\tfigure_W[6], = plt.plot(autocorr_vis_normalized[p] * sol2additive(w_solution)[p, u, ri])\n",
    "\t\t\tfigure_W[7], = plt.plot(best_fit[ri, u, p] - qaz_data[ri, u, p])\n",
    "\t\t\tfigure_W[8], = plt.plot(Ni.reshape((2, nUBL_used, 2, nt_used))[ri, u, p]**-.5)\n",
    "\t\t\tif pre_calibrate:\n",
    "\t\t\t\tdata_range = np.max([np.max(np.abs(qaz_data[ri, u, p])), np.max(np.abs(qaz_model[ri, u, p])), np.max(np.abs(best_fit[ri, u, p])), np.max(np.abs(sim_best_fit[ri, u, p])), np.max(np.abs((best_fit[ri, u, p] - qaz_data[ri, u, p])))]) # np.max(np.abs(qaz_add[ri, u, p])), #, 5 * np.max(np.abs(fun(cNi[u, p])))\n",
    "\t\t\t\tplt.legend(handles=[figure_W[1], figure_W[2], figure_W[3], figure_W[4], figure_W[5], figure_W[7], figure_W[8]], labels=['qaz_data', 'qaz_model', 'best_fit', 'sim_best_fit', 'additive', 'best_fit - qaz_data', 'noise'], loc=0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tdata_range = np.max([np.max(np.abs(qaz_data[ri, u, p])), np.max(np.abs(qaz_model[ri, u, p])), np.max(np.abs(best_fit[ri, u, p])), np.max(np.abs(sim_best_fit[ri, u, p])), np.max(np.abs((best_fit[ri, u, p] - qaz_data[ri, u, p])))]) #, 5 * np.max(np.abs(fun(cNi[u, p])))\n",
    "\t\t\t\tplt.legend(handles=[figure_W[1], figure_W[2], figure_W[3], figure_W[4], figure_W[7], figure_W[8]], labels=['qaz_data', 'qaz_model', 'best_fit', 'sim_best_fit', 'best_fit - qaz_data', 'noise'], loc=0)\n",
    "\t\t\tplt.ylim([-1.05*data_range, 1.05*data_range])\n",
    "\t\t\t#plt.title(\"%.1f,%.1f,%.1e\"%(used_common_ubls[u, 0], used_common_ubls[u, 1], la.norm(best_fit[ri, u, p] - qaz_data[ri, u, p])))\n",
    "\t\t\tplt.title(\"Wiener Filter %s Baseline-%.1f_%.1f results on srtime\"%(['xx','yy'][p], used_common_ubls[u, 0], used_common_ubls[u, 1]))\n",
    "\t\t\tplt.savefig(script_dir + '/../Output/%s-Baseline-%.1f_%.1f-dipole-precal_data_error-WienerFilter_Vis-%s-%.2f-bnside-%s-nside_standard-%s.pdf'%(INSTRUMENT, used_common_ubls[u, 0], used_common_ubls[u, 1], ['xx','yy'][p], freq, bnside, nside_standard))\n",
    "\t\t\tplt.show(block=False)\n",
    "\t\t\t#plt.gcf().clear()\n",
    "\t\t\t#plt.close()\n",
    "\n",
    "# Del=True\n",
    "# if Del:\n",
    "# \ttry:\n",
    "# \t\t#del(additive_A)\n",
    "# \t\t#del(real_additive_A)\n",
    "# \texcept:\n",
    "# \t\tpass\n",
    "\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_IQU(solution, title, col, shape=(2,3), coord='C'):\n",
    "\t# Es=solution[np.array(final_index).tolist()].reshape((4, len(final_index)/4))\n",
    "\t# I = Es[0] + Es[3]\n",
    "\t# Q = Es[0] - Es[3]\n",
    "\t# U = Es[1] + Es[2]\n",
    "\tI = sol2map(solution)\n",
    "\tplotcoordtmp = coord\n",
    "\thpv.mollview(np.log10(I), min=0, max=4, coord=plotcoordtmp, title=title, nest=True, sub=(shape[0], shape[1], col))\n",
    "\t#if col == shape[0] * shape[1]:\n",
    "\t\t#plt.show(block=False)\n",
    "\n",
    "def plot_IQU_unlimit(solution, title, col, shape=(2,3), coord='C'):\n",
    "\t# Es=solution[np.array(final_index).tolist()].reshape((4, len(final_index)/4))\n",
    "\t# I = Es[0] + Es[3]\n",
    "\t# Q = Es[0] - Es[3]\n",
    "\t# U = Es[1] + Es[2]\n",
    "\tI = sol2map(solution)\n",
    "\tplotcoordtmp = coord\n",
    "\thpv.mollview(np.log10(I), coord=plotcoordtmp, title=title, nest=True, sub=(shape[0], shape[1], col))\n",
    "\t#if col == shape[0] * shape[1]:\n",
    "\t\t#plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rescale_factor = np.max(np.abs(fake_solution))/ np.max(np.abs(w_solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Positive w_solution Pixels: %s'%len(w_solution[w_solution>=0]))\n",
    "print('Number of Positive w_GSM Pixels: %s'%len(w_GSM[w_GSM>=0]))\n",
    "print('Number of Positive w_sim Pixels: %s'%len(w_sim_sol[w_sim_sol>=0]))\n",
    "print('Number of Positive GSM Pixels: %s'%len(fake_solution[fake_solution>=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd = 0\n",
    "for coord in ['C', 'CG']:\n",
    "\t#plt.clf()\n",
    "\tplt.figure(900 + crd)\n",
    "\tcrd += 10\n",
    "\tplot_IQU_unlimit(np.abs(w_GSM), 'wienered GSM', 1, coord=coord) # (clean dynamic_data)\n",
    "\tplot_IQU_unlimit(np.abs(w_sim_sol), 'wienered simulated solution', 2, coord=coord) # (~noise+data)\n",
    "\tplot_IQU_unlimit(np.abs(w_solution), 'wienered solution(data)', 3, coord=coord)\n",
    "\tplot_IQU_unlimit(np.abs(fake_solution), 'True GSM masked', 4, coord=coord)\n",
    "\tplot_IQU_unlimit(np.abs(w_sim_sol - w_GSM + fake_solution), 'combined sim solution', 5, coord=coord)\n",
    "\tplot_IQU_unlimit(np.abs(w_solution - w_GSM + fake_solution), 'combined solution', 6, coord=coord)\n",
    "\tplt.savefig(script_dir + '/../Output/results_wiener-%s-%s-%sMHz-dipole-bnside-%s-nside_standard-%s-rescale-none-unlimit-S-%s-recond-%s.png'%(coord, INSTRUMENT, freq, bnside, nside_standard, S_type, rcond if Add_Rcond else 'none'))\n",
    "\t#plt.show(block=False)\n",
    "\t#plt.gcf().clear()\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd = 0\n",
    "for coord in ['C', 'CG']:\n",
    "\t#plt.clf()\n",
    "\tplt.figure(9000000 + crd)\n",
    "\tcrd += 10\n",
    "\tplot_IQU_unlimit(np.abs(w_GSM) * rescale_factor, 'wienered GSM', 1, coord=coord) # (clean dynamic_data)\n",
    "\tplot_IQU_unlimit(np.abs(w_sim_sol) * rescale_factor, 'wienered simulated solution', 2, coord=coord) # (~noise+data)\n",
    "\tplot_IQU_unlimit(np.abs(w_solution) * rescale_factor, 'wienered solution(data)', 3, coord=coord)\n",
    "\tplot_IQU_unlimit(np.abs(fake_solution), 'True GSM masked', 4, coord=coord)\n",
    "\tplot_IQU_unlimit(np.abs((w_sim_sol - w_GSM) * rescale_factor + fake_solution), 'combined sim solution', 5, coord=coord)\n",
    "\tplot_IQU_unlimit(np.abs((w_solution - w_GSM) * rescale_factor + fake_solution), 'combined solution', 6, coord=coord)\n",
    "\tplt.savefig(script_dir + '/../Output/results_wiener-%s-%s-%sMHz-dipole-bnside-%s-nside_standard-%s-rescale-%s-unlimit-S-%s-recond-%s.png'%(coord, INSTRUMENT, freq, bnside, nside_standard, rescale_factor, S_type, rcond if Add_Rcond else 'none'))\n",
    "\tplt.show(block=False)\n",
    "\t#plt.gcf().clear()\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd = 0\n",
    "for coord in ['C', 'CG']:\n",
    "\t#plt.clf()\n",
    "\tplt.figure(9500000 + crd)\n",
    "\tcrd += 10\n",
    "\tplot_IQU(np.abs(w_GSM) * rescale_factor, 'wienered GSM', 1, coord=coord) # (clean dynamic_data)\n",
    "\tplot_IQU(np.abs(w_sim_sol) * rescale_factor, 'wienered simulated solution', 2, coord=coord) # (~noise+data)\n",
    "\tplot_IQU(np.abs(w_solution) * rescale_factor, 'wienered solution(data)', 3, coord=coord)\n",
    "\tplot_IQU(np.abs(fake_solution), 'True GSM masked', 4, coord=coord)\n",
    "\tplot_IQU(np.abs((w_sim_sol - w_GSM) * rescale_factor + fake_solution), 'combined sim solution', 5, coord=coord)\n",
    "\tplot_IQU(np.abs((w_solution - w_GSM) * rescale_factor + fake_solution), 'combined solution', 6, coord=coord)\n",
    "\tplt.savefig(script_dir + '/../Output/results_wiener-%s-%s-%sMHz-dipole-bnside-%s-nside_standard-%s-rescale-%s-limit-S-%s-recond-%s.png'%(coord, INSTRUMENT, freq, bnside, nside_standard, rescale_factor, S_type, rcond if Add_Rcond else 'none'))\n",
    "\tplt.show(block=False)\n",
    "\t#plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd = 0\n",
    "for coord in ['C', 'CG']:\n",
    "\t#plt.clf()\n",
    "\tplt.figure(950 + crd)\n",
    "\tcrd += 10\n",
    "\tplot_IQU_unlimit((w_GSM + np.abs(w_GSM))*0.5 * rescale_factor + 1.e-6, 'wienered GSM', 1, coord=coord) # (clean dynamic_data)\n",
    "\tplot_IQU_unlimit((w_sim_sol + np.abs(w_sim_sol))*0.5 * rescale_factor + 1.e-6, 'wienered simulated solution', 2, coord=coord) # (~noise+data)\n",
    "\tplot_IQU_unlimit((w_solution + np.abs(w_solution))*0.5 * rescale_factor + 1.e-6, 'wienered solution(data)', 3, coord=coord)\n",
    "\tplot_IQU_unlimit((fake_solution + np.abs(fake_solution))*0.5 + 1.e-6, 'True GSM masked', 4, coord=coord)\n",
    "\tplot_IQU_unlimit((((w_sim_sol - w_GSM) * rescale_factor + fake_solution) + np.abs((w_sim_sol - w_GSM) * rescale_factor + fake_solution))*0.5 + 1.e-6, 'combined sim solution', 5, coord=coord)\n",
    "\tplot_IQU_unlimit((((w_solution - w_GSM) * rescale_factor + fake_solution) + np.abs((w_solution - w_GSM) * rescale_factor + fake_solution))*0.5 + 1.e-6, 'combined solution', 6, coord=coord)\n",
    "\tplt.savefig(script_dir + '/../Output/results_wiener-%s-%s-%sMHz-dipole-bnside-%s-nside_standard-%s-rescale-%s-denegative-unlimit-S-%s-recond-%s.png'%(coord, INSTRUMENT, freq, bnside, nside_standard, rescale_factor, S_type, rcond if Add_Rcond else 'none'))\n",
    "\tplt.show(block=False)\n",
    "\t#plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd = 0\n",
    "for coord in ['C', 'CG']:\n",
    "\t#plt.clf()\n",
    "\tplt.figure(90000 + crd)\n",
    "\tcrd += 10\n",
    "\tplot_IQU(np.abs(w_GSM), 'wienered GSM', 1, coord=coord) # (clean dynamic_data)\n",
    "\tplot_IQU(np.abs(w_sim_sol), 'wienered simulated solution', 2, coord=coord) # (~noise+data)\n",
    "\tplot_IQU(np.abs(w_solution), 'wienered solution(data)', 3, coord=coord)\n",
    "\tplot_IQU(np.abs(fake_solution), 'True GSM masked', 4, coord=coord)\n",
    "\tplot_IQU(np.abs(w_sim_sol - w_GSM + fake_solution), 'combined sim solution', 5, coord=coord)\n",
    "\tplot_IQU(np.abs(w_solution - w_GSM + fake_solution), 'combined solution', 6, coord=coord)\n",
    "\tplt.savefig(script_dir + '/../Output/results_wiener-%s-%s-%sMHz-dipole-bnside-%s-nside_standard-%s-rescale-none-limit-S-%s-recond-%s.png'%(coord, INSTRUMENT, freq, bnside, nside_standard, S_type, rcond if Add_Rcond else 'none'))\n",
    "\tplt.show(block=False)\n",
    "\t#plt.gcf().clear()\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd = 0\n",
    "for coord in ['C', 'CG']:\n",
    "\t#plt.clf()\n",
    "\tplt.figure(9000 + crd)\n",
    "\tcrd += 10\n",
    "\tplot_IQU(np.abs(w_GSM/vis_normalization), 'wienered GSM', 1, coord=coord) # (clean dynamic_data)\n",
    "\tplot_IQU(np.abs(w_sim_sol/vis_normalization), 'wienered simulated solution', 2, coord=coord) # (~noise+data)\n",
    "\tplot_IQU(np.abs(w_solution), 'wienered solution(data)', 3, coord=coord)\n",
    "\tplot_IQU(np.abs(fake_solution/vis_normalization), 'True GSM masked', 4, coord=coord)\n",
    "\tplot_IQU(np.abs((w_sim_sol - w_GSM + fake_solution)/vis_normalization), 'combined sim solution', 5, coord=coord)\n",
    "\tplot_IQU(np.abs((w_solution - w_GSM + fake_solution)/vis_normalization), 'combined solution', 6, coord=coord)\n",
    "\tplt.savefig(script_dir + '/../Output/results_wiener_renormalized-%s-%s-%sMHz-dipole-bnside-%s-nside_standard-%s-rescale-none-limit-S-%s-recond-%s.png'%(coord, INSTRUMENT, freq, bnside, nside_standard, S_type, rcond if Add_Rcond else 'none'))\n",
    "\tplt.show(block=False)\n",
    "\t#plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = data.reshape((2, data_shape['xx'][0], 2, data_shape['xx'][1])) - best_fit\n",
    "chi = error * (Ni.reshape((2, data_shape['xx'][0], 2, data_shape['xx'][1])))**.5\n",
    "print \"chi^2 = %.3e, data points %i, pixels %i\"%(la.norm(chi)**2, len(data), valid_npix)\n",
    "print \"re/im chi2 %.3e, %.3e\"%(la.norm(chi[0])**2, la.norm(chi[1])**2)\n",
    "print \"xx/yy chi2 %.3e, %.3e\"%(la.norm(chi[:, :, 0])**2, la.norm(chi[:, :, 1])**2)\n",
    "#plt.clf()\n",
    "plt.figure(120)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot([la.norm(error[:, u]) for u in ubl_sort['x']])\n",
    "plt.title('Error Norm-bsl')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot([la.norm(chi[:, u]) for u in ubl_sort['x']])\n",
    "plt.title('Chi Norm-bsl')\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(lsts, [la.norm(error[..., t]) for t in range(error.shape[-1])])\n",
    "plt.title('Error Norm-t')\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(lsts, [la.norm(chi[..., t]) for t in range(error.shape[-1])])\n",
    "plt.title('Chi Norm-bsl')\n",
    "plt.savefig(script_dir + '/../Output/chi-%s-%s-dipole-bnside-%s-nside_standard-%s.png'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "plt.show(block=False)\n",
    "#plt.gcf().clear()\n",
    "\n",
    "try:\n",
    "\tprint('Additive_sol: %s' %additive_sol[:2])\n",
    "\tprint (\"regularization stength\", (maxAtNiA * rcond)**-.5, \"median GSM ranges between\", np.median(equatorial_GSM_standard) * min(sizes), np.median(equatorial_GSM_standard) * max(sizes))\n",
    "\tprint('Rescale_factor: %s'%rescale_factor)\n",
    "except:\n",
    "\tpass\t\n",
    "\n",
    "\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#S_type = 'none'\n",
    "#point spread function:\n",
    "if True and S_type == 'none':\n",
    "\tprint \"Reading Regularized AtNiAi...\",\n",
    "\tsys.stdout.flush()\n",
    "\tAtNiAi = sv.InverseCholeskyMatrix.fromfile(AtNiAi_path, len(S_diag), precision)\n",
    "\n",
    "\tAtNiA_tag = 'AtNiA_N%s'%vartag\n",
    "\tif not fit_for_additive:\n",
    "\t\tAtNiA_tag += \"_noadd\"\n",
    "\telif crosstalk_type == 'autocorr':\n",
    "\t\tAtNiA_tag += \"_autocorr\"\n",
    "\tif pre_ampcal:\n",
    "\t\tAtNiA_tag += \"_ampcal\"\n",
    "\tAtNiA_filename = AtNiA_tag + A_filename\n",
    "\tAtNiA_path = datadir + tag + AtNiA_filename\n",
    "\tprint \"Reading AtNiA...\",\n",
    "\tsys.stdout.flush()\n",
    "\tAtNiA = np.fromfile(AtNiA_path, dtype=precision).reshape((Ashape1, Ashape1))\n",
    "\n",
    "\tiplot = 0\n",
    "\tvalid_thetas_phis = np.array(zip(thetas, phis))\n",
    "\tfull_thetas, full_phis = hpf.pix2ang(nside_standard, range(hpf.nside2npix(nside_standard)), nest=True)\n",
    "\t#plt.clf()\n",
    "\tplt.figure(130)\n",
    "\tfor theta in np.arange(0, PI*.9, PI/6.):\n",
    "\t\tfor phi in np.arange(0, TPI, PI/3.):\n",
    "\t\t\tiplot += 1\n",
    "\t\t\tchoose_plots = [1, 12, 24]\n",
    "\t\t\tif iplot in choose_plots:\n",
    "\t\t\t\tnp.argmin(la.norm(valid_thetas_phis - [theta, phi], axis=-1))\n",
    "\t\t\t\tpoint_vec = np.zeros_like(fake_solution).astype('complex128')\n",
    "\n",
    "\t\t\t\tpoint_vec[np.argmin(la.norm(valid_thetas_phis - [theta, phi], axis=-1))] = 1\n",
    "\t\t\t\tspreaded = sol2map(AtNiAi.dotv(AtNiA.dot(point_vec)))\n",
    "\t\t\t\tspreaded /= np.max(spreaded)\n",
    "\t\t\t\tfwhm_mask = np.abs(spreaded) >= .5\n",
    "\t\t\t\tmasked_max_ind = np.argmax(spreaded[fwhm_mask])\n",
    "\t\t\t\tfwhm_thetas = full_thetas[fwhm_mask]\n",
    "\t\t\t\tfwhm_phis = full_phis[fwhm_mask]\n",
    "\t\t\t\t#rotate angles to center around PI/2 0\n",
    "\t\t\t\tfwhm_thetas, fwhm_phis = hpr.Rotator(rot=[fwhm_phis[masked_max_ind], PI/2-fwhm_thetas[masked_max_ind], 0], deg=False)(fwhm_thetas, fwhm_phis)\n",
    "\t\t\t\tif np.array(fwhm_thetas).shape is (): \n",
    "\t\t\t\t\tfwhm_thetas = np.array([fwhm_thetas])\n",
    "\t\t\t\t\tfwhm_phis = np.array([fwhm_phis])\n",
    "\t\t\t\tprint fwhm_thetas[masked_max_ind], fwhm_phis[masked_max_ind]#should print 1.57079632679 0.0 if rotation is working correctly\n",
    "\n",
    "\n",
    "\t\t\t\tfwhm_theta = max(fwhm_thetas) - min(fwhm_thetas)\n",
    "\t\t\t\tphi_offset = fwhm_phis[masked_max_ind] - PI\n",
    "\t\t\t\tfwhm_phis = (fwhm_phis - phi_offset)%TPI + phi_offset\n",
    "\t\t\t\tfwhm_phi = max(fwhm_phis) - min(fwhm_phis) \n",
    "\t\t\t\thpv.mollview(np.log10(np.abs(spreaded)), min=-3, max=0, nest=True, coord='CG', title='FWHM = %.3f'%((fwhm_theta*fwhm_phi)**.5*180./PI), sub=(len(choose_plots), 1, choose_plots.index(iplot)+1))\n",
    "\tplt.savefig(script_dir + '/../Output/spreaded_function-CG-%s-%s-dipole-bnside-%s-nside_standard-%s.png'%(INSTRUMENT, freq, bnside, nside_standard))\n",
    "\tplt.show(block=False)\n",
    "\t#plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print AtNiA_filename\n",
    "print A_filename\n",
    "print AtNiA_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S_type = 'none'\n",
    "#point spread function:\n",
    "if True:# and S_type == 'none':\n",
    "\tprint \"Reading Regularized AtNiAi...\",\n",
    "\tsys.stdout.flush()\n",
    "\tAtNiAi = sv.InverseCholeskyMatrix.fromfile(AtNiAi_path, len(S_diag), precision)\n",
    "\n",
    "\tAtNiA_tag = 'AtNiA_N%s'%vartag\n",
    "\tif not fit_for_additive:\n",
    "\t\tAtNiA_tag += \"_noadd\"\n",
    "\telif crosstalk_type == 'autocorr':\n",
    "\t\tAtNiA_tag += \"_autocorr\"\n",
    "\tif pre_ampcal:\n",
    "\t\tAtNiA_tag += \"_ampcal\"\n",
    "\tAtNiA_filename = AtNiA_tag + A_filename\n",
    "\tAtNiA_path = datadir + tag + AtNiA_filename\n",
    "\tprint \"Reading AtNiA...\",\n",
    "\tsys.stdout.flush()\n",
    "\tAtNiA = np.fromfile(AtNiA_path, dtype=precision).reshape((Ashape1, Ashape1))\n",
    "\n",
    "\tiplot = 0\n",
    "\tvalid_thetas_phis = np.array(zip(thetas, phis))\n",
    "\tfull_thetas, full_phis = hpf.pix2ang(nside_standard, range(hpf.nside2npix(nside_standard)), nest=True)\n",
    "\t#plt.clf()\n",
    "\t\n",
    "\tfor theta in np.arange(0, PI*.9, PI/6.):\n",
    "\t\tfor phi in np.arange(0, TPI, PI/3.):\n",
    "\t\t\t\n",
    "\t\t\t#choose_plots = [1, 6, 12, 18, 24, 30]\n",
    "\t\t\tchoose_plots = [0, 1, 4, 6, 8, 12, 16, 20, 24, 28, 30, 32, 33, 35]\n",
    "\t\t\t\n",
    "\t\t\tif iplot in choose_plots:\n",
    "\t\t\t\tnp.argmin(la.norm(valid_thetas_phis - [theta, phi], axis=-1))\n",
    "\t\t\t\tpoint_vec = np.zeros_like(fake_solution).astype('complex128')\n",
    "\n",
    "\t\t\t\tpoint_vec[np.argmin(la.norm(valid_thetas_phis - [theta, phi], axis=-1))] = 1\n",
    "\t\t\t\tspreaded = sol2map(AtNiAi.dotv(AtNiA.dot(point_vec)))\n",
    "\t\t\t\tspreaded /= np.max(spreaded)\n",
    "\t\t\t\tfwhm_mask = np.abs(spreaded) >= .5\n",
    "\t\t\t\tmasked_max_ind = np.argmax(spreaded[fwhm_mask])\n",
    "\t\t\t\tfwhm_thetas = full_thetas[fwhm_mask]\n",
    "\t\t\t\tfwhm_phis = full_phis[fwhm_mask]\n",
    "\t\t\t\t#rotate angles to center around PI/2 0\n",
    "\t\t\t\tfwhm_thetas, fwhm_phis = hpr.Rotator(rot=[fwhm_phis[masked_max_ind], PI/2-fwhm_thetas[masked_max_ind], 0], deg=False)(fwhm_thetas, fwhm_phis)\n",
    "\t\t\t\tif np.array(fwhm_thetas).shape is (): \n",
    "\t\t\t\t\tfwhm_thetas = np.array([fwhm_thetas])\n",
    "\t\t\t\t\tfwhm_phis = np.array([fwhm_phis])\n",
    "\t\t\t\tprint fwhm_thetas[masked_max_ind], fwhm_phis[masked_max_ind]#should print 1.57079632679 0.0 if rotation is working correctly\n",
    "\n",
    "\n",
    "\t\t\t\tfwhm_theta = max(fwhm_thetas) - min(fwhm_thetas)\n",
    "\t\t\t\tphi_offset = fwhm_phis[masked_max_ind] - PI\n",
    "\t\t\t\tfwhm_phis = (fwhm_phis - phi_offset)%TPI + phi_offset\n",
    "\t\t\t\tfwhm_phi = max(fwhm_phis) - min(fwhm_phis)\n",
    "\t\t\t\tplt.figure(1300+iplot) \n",
    "\t\t\t\t#hpv.mollview(np.log10(np.abs(spreaded)), min=-3, max=0, nest=True, coord='CG', title='FWHM = %.3f'%((fwhm_theta*fwhm_phi)**.5*180./PI), sub=(len(choose_plots), 1, choose_plots.index(iplot)+1))\n",
    "\t\t\t\thpv.mollview(np.log10(np.abs(spreaded)), min=-4, nest=True, coord='C', title='FWHM = %.3f'%((fwhm_theta*fwhm_phi)**.5*180./PI))\n",
    "\t\t\t\tplt.savefig(script_dir + '/../Output/spreaded_function-CG-%s-%s-%s-dipole-bnside-%s-nside_standard-%s-%s-recond-%s.png'%(INSTRUMENT, iplot, freq, bnside, nside_standard, S_type, rcond if Add_Rcond else 'none'))\n",
    "\t\t\t\tplt.show(block=False)\n",
    "\t\t\t\t#plt.gcf().clear()\n",
    "\t\t\tiplot += 1\n",
    "\n",
    "\n",
    "sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additive_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time()/60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data_dred_abscal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_supress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cosmology-2.7",
   "language": "python",
   "name": "cosmology-2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
